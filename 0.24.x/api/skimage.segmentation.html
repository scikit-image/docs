
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>skimage.segmentation &#8212; skimage 0.24.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=4340df76" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=a9084e48"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-image.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/skimage.segmentation';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.3';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-image.org/docs/dev/_static/version_switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.24.0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="skimage.transform" href="skimage.transform.html" />
    <link rel="prev" title="skimage.restoration" href="skimage.restoration.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

   

<a class="navbar-brand logo" href="https://scikit-image.org">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="scikit-image's logo, showing a snake's head overlayed with green and orange"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="scikit-image's logo, showing a snake's head overlayed with green and orange"/>`);</script>
  
  
    <p class="title logo__title">scikit-image</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav class="navbar-nav">
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User guide
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item pst-header-nav-item current active">
  <a class="nav-link nav-internal" href="api.html">
    API reference
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../release_notes/index.html">
    Release notes
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-image/scikit-image" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-image/" title="PyPI" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-solid fa-box fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav class="navbar-nav">
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User guide
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item pst-header-nav-item current active">
  <a class="nav-link nav-internal" href="api.html">
    API reference
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../release_notes/index.html">
    Release notes
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>


<li class="nav-item pst-header-nav-item">
  <a class="nav-link nav-internal" href="../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-image/scikit-image" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-image/" title="PyPI" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-solid fa-box fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="skimage.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.color.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.color</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.draw.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.draw</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.exposure.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.exposure</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.feature.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.feature</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.filters.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.filters.rank.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters.rank</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.future.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.future</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.graph.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.graph</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.io.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.io</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.measure.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.measure</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.metrics.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.metrics</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.morphology.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.morphology</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.registration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.registration</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.restoration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.restoration</span></code></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.segmentation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.transform.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.transform</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.util.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.util</span></code></a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="api.html" class="nav-link">API reference</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><code...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-skimage.segmentation">
<span id="skimage-segmentation"></span><h1><a class="reference internal" href="#module-skimage.segmentation" title="skimage.segmentation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.segmentation</span></code></a><a class="headerlink" href="#module-skimage.segmentation" title="Link to this heading">#</a></h1>
<p>Algorithms to partition images into meaningful regions or boundaries.</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.active_contour" title="skimage.segmentation.active_contour"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.active_contour</span></code></a></p></td>
<td><p>Active contour model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.chan_vese" title="skimage.segmentation.chan_vese"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.chan_vese</span></code></a></p></td>
<td><p>Chan-Vese segmentation algorithm.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.checkerboard_level_set" title="skimage.segmentation.checkerboard_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.checkerboard_level_set</span></code></a></p></td>
<td><p>Create a checkerboard level set with binary values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.clear_border" title="skimage.segmentation.clear_border"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.clear_border</span></code></a></p></td>
<td><p>Clear objects connected to the label image border.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.disk_level_set" title="skimage.segmentation.disk_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.disk_level_set</span></code></a></p></td>
<td><p>Create a disk level set with binary values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.expand_labels" title="skimage.segmentation.expand_labels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.expand_labels</span></code></a></p></td>
<td><p>Expand labels in label image by <code class="docutils literal notranslate"><span class="pre">distance</span></code> pixels without overlapping.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.felzenszwalb" title="skimage.segmentation.felzenszwalb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.felzenszwalb</span></code></a></p></td>
<td><p>Computes Felsenszwalb's efficient graph based image segmentation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.find_boundaries" title="skimage.segmentation.find_boundaries"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.find_boundaries</span></code></a></p></td>
<td><p>Return bool array where boundaries between labeled regions are True.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.flood" title="skimage.segmentation.flood"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.flood</span></code></a></p></td>
<td><p>Mask corresponding to a flood fill.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.flood_fill" title="skimage.segmentation.flood_fill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.flood_fill</span></code></a></p></td>
<td><p>Perform flood filling on an image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.inverse_gaussian_gradient" title="skimage.segmentation.inverse_gaussian_gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.inverse_gaussian_gradient</span></code></a></p></td>
<td><p>Inverse of gradient magnitude.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.join_segmentations" title="skimage.segmentation.join_segmentations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.join_segmentations</span></code></a></p></td>
<td><p>Return the join of the two input segmentations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.mark_boundaries" title="skimage.segmentation.mark_boundaries"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.mark_boundaries</span></code></a></p></td>
<td><p>Return image with boundaries between labeled regions highlighted.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.morphological_chan_vese" title="skimage.segmentation.morphological_chan_vese"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.morphological_chan_vese</span></code></a></p></td>
<td><p>Morphological Active Contours without Edges (MorphACWE)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.morphological_geodesic_active_contour" title="skimage.segmentation.morphological_geodesic_active_contour"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.morphological_geodesic_active_contour</span></code></a></p></td>
<td><p>Morphological Geodesic Active Contours (MorphGAC).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.quickshift" title="skimage.segmentation.quickshift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.quickshift</span></code></a></p></td>
<td><p>Segment image using quickshift clustering in Color-(x,y) space.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.random_walker" title="skimage.segmentation.random_walker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.random_walker</span></code></a></p></td>
<td><p>Random walker algorithm for segmentation from markers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.relabel_sequential" title="skimage.segmentation.relabel_sequential"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.relabel_sequential</span></code></a></p></td>
<td><p>Relabel arbitrary labels to {<em class="xref py py-obj">offset</em>, .</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.segmentation.slic" title="skimage.segmentation.slic"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.slic</span></code></a></p></td>
<td><p>Segments image using k-means clustering in Color-(x,y,z) space.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.segmentation.watershed" title="skimage.segmentation.watershed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.watershed</span></code></a></p></td>
<td><p>Find watershed basins in an image flooded from given markers.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.active_contour">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">active_contour</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">snake</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_line</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_edge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_px_move</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convergence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boundary_condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'periodic'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/active_contour_model.py#L9-L250"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.active_contour" title="Link to this definition">#</a></dt>
<dd><p>Active contour model.</p>
<p>Active contours by fitting snakes to features of images. Supports single
and multichannel 2D images. Snakes can be periodic (for segmentation) or
have fixed and/or free ends.
The output snake has the same length as the input boundary.
As the number of points is constant, make sure that the initial snake
has enough points to capture the details of the final contour.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N) or (M, N, 3) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>snake</strong><span class="classifier">(K, 2) ndarray</span></dt><dd><p>Initial snake coordinates. For periodic boundary conditions, endpoints
must not be duplicated.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Snake length shape parameter. Higher values makes snake contract
faster.</p>
</dd>
<dt><strong>beta</strong><span class="classifier">float, optional</span></dt><dd><p>Snake smoothness shape parameter. Higher values makes snake smoother.</p>
</dd>
<dt><strong>w_line</strong><span class="classifier">float, optional</span></dt><dd><p>Controls attraction to brightness. Use negative values to attract
toward dark regions.</p>
</dd>
<dt><strong>w_edge</strong><span class="classifier">float, optional</span></dt><dd><p>Controls attraction to edges. Use negative values to repel snake from
edges.</p>
</dd>
<dt><strong>gamma</strong><span class="classifier">float, optional</span></dt><dd><p>Explicit time stepping parameter.</p>
</dd>
<dt><strong>max_px_move</strong><span class="classifier">float, optional</span></dt><dd><p>Maximum pixel distance to move per iteration.</p>
</dd>
<dt><strong>max_num_iter</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum iterations to optimize snake shape.</p>
</dd>
<dt><strong>convergence</strong><span class="classifier">float, optional</span></dt><dd><p>Convergence criteria.</p>
</dd>
<dt><strong>boundary_condition</strong><span class="classifier">string, optional</span></dt><dd><p>Boundary conditions for the contour. Can be one of ‘periodic’,
‘free’, ‘fixed’, ‘free-fixed’, or ‘fixed-free’. ‘periodic’ attaches
the two ends of the snake, ‘fixed’ holds the end-points in place,
and ‘free’ allows free movement of the ends. ‘fixed’ and ‘free’ can
be combined by parsing ‘fixed-free’, ‘free-fixed’. Parsing
‘fixed-fixed’ or ‘free-free’ yields same behaviour as ‘fixed’ and
‘free’, respectively.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>snake</strong><span class="classifier">(K, 2) ndarray</span></dt><dd><p>Optimised snake, same shape as input parameter.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r094916d7e45d-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Kass, M.; Witkin, A.; Terzopoulos, D. “Snakes: Active contour
models”. International Journal of Computer Vision 1 (4): 321
(1988). <a class="reference external" href="https://doi.org/10.1007/BF00133570">DOI:10.1007/BF00133570</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.draw</span> <span class="kn">import</span> <span class="n">circle_perimeter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">gaussian</span>
</pre></div>
</div>
<p>Create and smooth image:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span> <span class="o">=</span> <span class="n">circle_perimeter</span><span class="p">(</span><span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="p">[</span><span class="n">rr</span><span class="p">,</span> <span class="n">cc</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">preserve_range</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize spline:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">init</span> <span class="o">=</span> <span class="mi">50</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">s</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="mi">50</span>
</pre></div>
</div>
<p>Fit spline to image:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">snake</span> <span class="o">=</span> <span class="n">active_contour</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="n">w_edge</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">w_line</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">45</span><span class="o">-</span><span class="n">snake</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">35</span><span class="o">-</span><span class="n">snake</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dist</span><span class="p">))</span>  
<span class="go">25</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The active contour model is a method to fit open or closed splines to lines or edges in an imag..."><img alt="" src="../_images/sphx_glr_plot_active_contours_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_active_contours.html#sphx-glr-auto-examples-edges-plot-active-contours-py"><span class="std std-ref">Active Contour Model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Active Contour Model</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.chan_vese">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">chan_vese</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_level_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'checkerboard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extended_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_chan_vese.py#L185-L365"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.chan_vese" title="Link to this definition">#</a></dt>
<dd><p>Chan-Vese segmentation algorithm.</p>
<p>Active contour model by evolving a level set. Can be used to
segment objects without clearly defined boundaries.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Grayscale image to be segmented.</p>
</dd>
<dt><strong>mu</strong><span class="classifier">float, optional</span></dt><dd><p>‘edge length’ weight parameter. Higher <em class="xref py py-obj">mu</em> values will
produce a ‘round’ edge, while values closer to zero will
detect smaller objects.</p>
</dd>
<dt><strong>lambda1</strong><span class="classifier">float, optional</span></dt><dd><p>‘difference from average’ weight parameter for the output
region with value ‘True’. If it is lower than <em class="xref py py-obj">lambda2</em>, this
region will have a larger range of values than the other.</p>
</dd>
<dt><strong>lambda2</strong><span class="classifier">float, optional</span></dt><dd><p>‘difference from average’ weight parameter for the output
region with value ‘False’. If it is lower than <em class="xref py py-obj">lambda1</em>, this
region will have a larger range of values than the other.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, positive, optional</span></dt><dd><p>Level set variation tolerance between iterations. If the
L2 norm difference between the level sets of successive
iterations normalized by the area of the image is below this
value, the algorithm will assume that the solution was
reached.</p>
</dd>
<dt><strong>max_num_iter</strong><span class="classifier">uint, optional</span></dt><dd><p>Maximum number of iterations allowed before the algorithm
interrupts itself.</p>
</dd>
<dt><strong>dt</strong><span class="classifier">float, optional</span></dt><dd><p>A multiplication factor applied at calculations for each step,
serves to accelerate the algorithm. While higher values may
speed up the algorithm, they may also lead to convergence
problems.</p>
</dd>
<dt><strong>init_level_set</strong><span class="classifier">str or (M, N) ndarray, optional</span></dt><dd><p>Defines the starting level set used by the algorithm.
If a string is inputted, a level set that matches the image
size will automatically be generated. Alternatively, it is
possible to define a custom level set, which should be an
array of float values, with the same shape as ‘image’.
Accepted string values are as follows.</p>
<dl class="simple">
<dt>‘checkerboard’</dt><dd><p>the starting level set is defined as
sin(x/5*pi)*sin(y/5*pi), where x and y are pixel
coordinates. This level set has fast convergence, but may
fail to detect implicit edges.</p>
</dd>
<dt>‘disk’</dt><dd><p>the starting level set is defined as the opposite
of the distance from the center of the image minus half of
the minimum value between image width and image height.
This is somewhat slower, but is more likely to properly
detect implicit edges.</p>
</dd>
<dt>‘small disk’</dt><dd><p>the starting level set is defined as the
opposite of the distance from the center of the image
minus a quarter of the minimum value between image width
and image height.</p>
</dd>
</dl>
</dd>
<dt><strong>extended_output</strong><span class="classifier">bool, optional</span></dt><dd><p>If set to True, the return value will be a tuple containing
the three return values (see below). If set to False which
is the default value, only the ‘segmentation’ array will be
returned.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>segmentation</strong><span class="classifier">(M, N) ndarray, bool</span></dt><dd><p>Segmentation produced by the algorithm.</p>
</dd>
<dt><strong>phi</strong><span class="classifier">(M, N) ndarray of floats</span></dt><dd><p>Final level set computed by the algorithm.</p>
</dd>
<dt><strong>energies</strong><span class="classifier">list of floats</span></dt><dd><p>Shows the evolution of the ‘energy’ for each step of the
algorithm. This should allow to check whether the algorithm
converged.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The Chan-Vese Algorithm is designed to segment objects without
clearly defined boundaries. This algorithm is based on level sets
that are evolved iteratively to minimize an energy, which is
defined by weighted values corresponding to the sum of differences
intensity from the average value outside the segmented region, the
sum of differences from the average value inside the segmented
region, and a term which is dependent on the length of the
boundary of the segmented region.</p>
<p>This algorithm was first proposed by Tony Chan and Luminita Vese,
in a publication entitled “An Active Contour Model Without Edges”
<a class="reference internal" href="#rb5da2c114fc8-1" id="id2">[1]</a>.</p>
<p>This implementation of the algorithm is somewhat simplified in the
sense that the area factor ‘nu’ described in the original paper is
not implemented, and is only suitable for grayscale images.</p>
<p>Typical values for <em class="xref py py-obj">lambda1</em> and <em class="xref py py-obj">lambda2</em> are 1. If the
‘background’ is very different from the segmented object in terms
of distribution (for example, a uniform black image with figures
of varying intensity), then these values should be different from
each other.</p>
<p>Typical values for mu are between 0 and 1, though higher values
can be used when dealing with shapes with very ill-defined
contours.</p>
<p>The ‘energy’ which this algorithm tries to minimize is defined
as the sum of the differences from the average within the region
squared and weighed by the ‘lambda’ factors to which is added the
length of the contour multiplied by the ‘mu’ factor.</p>
<p>Supports 2D grayscale images only, and does not implement the area
term described in the original article.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rb5da2c114fc8-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">1</a><span class="fn-bracket">]</span></span>
<p>An Active Contour Model without Edges, Tony Chan and
Luminita Vese, Scale-Space Theories in Computer Vision,
1999, <a class="reference external" href="https://doi.org/10.1007/3-540-48236-9_13">DOI:10.1007/3-540-48236-9_13</a></p>
</div>
<div class="citation" id="rb5da2c114fc8-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Chan-Vese Segmentation, Pascal Getreuer Image Processing On
Line, 2 (2012), pp. 214-224,
<a class="reference external" href="https://doi.org/10.5201/ipol.2012.g-cv">DOI:10.5201/ipol.2012.g-cv</a></p>
</div>
<div class="citation" id="rb5da2c114fc8-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>The Chan-Vese Algorithm - Project Report, Rami Cohen, 2011
<a class="reference external" href="https://arxiv.org/abs/1107.2782">arXiv:1107.2782</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The Chan-Vese segmentation algorithm is designed to segment objects without clearly defined bou..."><img alt="" src="../_images/sphx_glr_plot_chan_vese_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_chan_vese.html#sphx-glr-auto-examples-segmentation-plot-chan-vese-py"><span class="std std-ref">Chan-Vese Segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Chan-Vese Segmentation</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.checkerboard_level_set">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">checkerboard_level_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">square_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/morphsnakes.py#L151-L179"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.checkerboard_level_set" title="Link to this definition">#</a></dt>
<dd><p>Create a checkerboard level set with binary values.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image_shape</strong><span class="classifier">tuple of positive integers</span></dt><dd><p>Shape of the image.</p>
</dd>
<dt><strong>square_size</strong><span class="classifier">int, optional</span></dt><dd><p>Size of the squares of the checkerboard. It defaults to 5.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>out</strong><span class="classifier">array with shape <em class="xref py py-obj">image_shape</em></span></dt><dd><p>Binary level set of the checkerboard.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.disk_level_set" title="skimage.segmentation.disk_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">disk_level_set</span></code></a></dt><dd></dd>
</dl>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Morphological Snakes [1]_ are a family of methods for image segmentation. Their behavior is sim..."><img alt="" src="../_images/sphx_glr_plot_morphsnakes_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_morphsnakes.html#sphx-glr-auto-examples-segmentation-plot-morphsnakes-py"><span class="std std-ref">Morphological Snakes</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Snakes</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.clear_border">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">clear_border</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bgval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_clear_border.py#L6-L109"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.clear_border" title="Link to this definition">#</a></dt>
<dd><p>Clear objects connected to the label image border.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>labels</strong><span class="classifier">(M[, N[, …, P]]) array of int or bool</span></dt><dd><p>Imaging data labels.</p>
</dd>
<dt><strong>buffer_size</strong><span class="classifier">int, optional</span></dt><dd><p>The width of the border examined.  By default, only objects
that touch the outside of the image are removed.</p>
</dd>
<dt><strong>bgval</strong><span class="classifier">float or int, optional</span></dt><dd><p>Cleared objects are set to this value.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">ndarray of bool, same shape as <em class="xref py py-obj">image</em>, optional.</span></dt><dd><p>Image data mask. Objects in labels image overlapping with
False pixels of mask will be removed. If defined, the
argument buffer_size will be ignored.</p>
</dd>
<dt><strong>out</strong><span class="classifier">ndarray</span></dt><dd><p>Array of the same shape as <em class="xref py py-obj">labels</em>, into which the
output is placed. By default, a new array is created.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M[, N[, …, P]]) array</span></dt><dd><p>Imaging data labels with cleared borders</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">clear_border</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clear_border</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 1, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 0, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 1, 1, 1, 1, 1, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                 <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clear_border</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 1, 0],</span>
<span class="go">       [0, 0, 0, 0, 1, 0, 0, 1, 0],</span>
<span class="go">       [0, 0, 0, 1, 0, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 1, 1, 1, 1, 1, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to segment an image with image labelling. The following steps are applie..."><img alt="" src="../_images/sphx_glr_plot_label_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_label.html#sphx-glr-auto-examples-segmentation-plot-label-py"><span class="std std-ref">Label image regions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Label image regions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate the use of different metrics to assess the colocalization of tw..."><img alt="" src="../_images/sphx_glr_plot_colocalization_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_colocalization_metrics.html#sphx-glr-auto-examples-applications-plot-colocalization-metrics-py"><span class="std std-ref">Colocalization metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Colocalization metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example reproduces a well-established workflow in bioimage data analysis for measuring the..."><img alt="" src="../_images/sphx_glr_plot_fluorescence_nuclear_envelope_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_fluorescence_nuclear_envelope.html#sphx-glr-auto-examples-applications-plot-fluorescence-nuclear-envelope-py"><span class="std std-ref">Measure fluorescence intensity at the nuclear envelope</span></a></p>
  <div class="sphx-glr-thumbnail-title">Measure fluorescence intensity at the nuclear envelope</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.disk_level_set">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">disk_level_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/morphsnakes.py#L114-L148"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.disk_level_set" title="Link to this definition">#</a></dt>
<dd><p>Create a disk level set with binary values.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image_shape</strong><span class="classifier">tuple of positive integers</span></dt><dd><p>Shape of the image</p>
</dd>
<dt><strong>center</strong><span class="classifier">tuple of positive integers, optional</span></dt><dd><p>Coordinates of the center of the disk given in (row, column). If not
given, it defaults to the center of the image.</p>
</dd>
<dt><strong>radius</strong><span class="classifier">float, optional</span></dt><dd><p>Radius of the disk. If not given, it is set to the 75% of the
smallest image dimension.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>out</strong><span class="classifier">array with shape <em class="xref py py-obj">image_shape</em></span></dt><dd><p>Binary level set of the disk with the given <em class="xref py py-obj">radius</em> and <em class="xref py py-obj">center</em>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.checkerboard_level_set" title="skimage.segmentation.checkerboard_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">checkerboard_level_set</span></code></a></dt><dd></dd>
</dl>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.expand_labels">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">expand_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spacing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_expand_labels.py#L5-L104"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.expand_labels" title="Link to this definition">#</a></dt>
<dd><p>Expand labels in label image by <code class="docutils literal notranslate"><span class="pre">distance</span></code> pixels without overlapping.</p>
<p>Given a label image, <code class="docutils literal notranslate"><span class="pre">expand_labels</span></code> grows label regions (connected components)
outwards by up to <code class="docutils literal notranslate"><span class="pre">distance</span></code> units without overflowing into neighboring regions.
More specifically, each background pixel that is within Euclidean distance
of &lt;= <code class="docutils literal notranslate"><span class="pre">distance</span></code> pixels of a connected component is assigned the label of that
connected component. The <em class="xref py py-obj">spacing</em> parameter can be used to specify the spacing
rate of the distance transform used to calculate the Euclidean distance for anisotropic
images.
Where multiple connected components are within <code class="docutils literal notranslate"><span class="pre">distance</span></code> pixels of a background
pixel, the label value of the closest connected component will be assigned (see
Notes for the case of multiple labels at equal distance).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_image</strong><span class="classifier">ndarray of dtype int</span></dt><dd><p>label image</p>
</dd>
<dt><strong>distance</strong><span class="classifier">float</span></dt><dd><p>Euclidean distance in pixels by which to grow the labels. Default is one.</p>
</dd>
<dt><strong>spacing</strong><span class="classifier">float, or sequence of float, optional</span></dt><dd><p>Spacing of elements along each dimension. If a sequence, must be of length
equal to the input rank; if a single number, this is used for all axes. If
not specified, a grid spacing of unity is implied.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>enlarged_labels</strong><span class="classifier">ndarray of dtype int</span></dt><dd><p>Labeled array, where all connected regions have been enlarged</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="skimage.measure.html#skimage.measure.label" title="skimage.measure.label"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.measure.label()</span></code></a>, <a class="reference internal" href="#skimage.segmentation.watershed" title="skimage.segmentation.watershed"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.segmentation.watershed()</span></code></a>, <a class="reference internal" href="skimage.morphology.html#skimage.morphology.dilation" title="skimage.morphology.dilation"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.morphology.dilation()</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Where labels are spaced more than <code class="docutils literal notranslate"><span class="pre">distance</span></code> pixels are apart, this is
equivalent to a morphological dilation with a disc or hyperball of radius <code class="docutils literal notranslate"><span class="pre">distance</span></code>.
However, in contrast to a morphological dilation, <code class="docutils literal notranslate"><span class="pre">expand_labels</span></code> will
not expand a label region into a neighboring region.</p>
<p>This implementation of <code class="docutils literal notranslate"><span class="pre">expand_labels</span></code> is derived from CellProfiler <a class="reference internal" href="#r700ff08b53f4-1" id="id6">[1]</a>, where
it is known as module “IdentifySecondaryObjects (Distance-N)” <a class="reference internal" href="#r700ff08b53f4-2" id="id7">[2]</a>.</p>
<p>There is an important edge case when a pixel has the same distance to
multiple regions, as it is not defined which region expands into that
space. Here, the exact behavior depends on the upstream implementation
of <code class="docutils literal notranslate"><span class="pre">scipy.ndimage.distance_transform_edt</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r700ff08b53f4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://cellprofiler.org">https://cellprofiler.org</a></p>
</div>
<div class="citation" id="r700ff08b53f4-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">2</a><span class="fn-bracket">]</span></span>
<p><a class="github reference external" href="https://github.com/CellProfiler/CellProfiler/blob/082930ea95add7b72243a4fa3d39ae5145995e9c/cellprofiler/modules/identifysecondaryobjects.py#L559">CellProfiler/CellProfiler</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expand_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([1, 1, 1, 0, 0, 2, 2])</span>
</pre></div>
</div>
<p>Labels will not overwrite each other:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">expand_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="go">array([1, 1, 1, 1, 2, 2, 2])</span>
</pre></div>
</div>
<p>In case of ties, behavior is undefined, but currently resolves to the
label closest to <code class="docutils literal notranslate"><span class="pre">(0,)</span> <span class="pre">*</span> <span class="pre">ndim</span></code> in lexicographical order.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_tied</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expand_labels</span><span class="p">(</span><span class="n">labels_tied</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([1, 1, 1, 2, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expand_labels</span><span class="p">(</span><span class="n">labels2d</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 1, 1, 0],</span>
<span class="go">       [2, 2, 0, 0],</span>
<span class="go">       [2, 3, 3, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expand_labels</span><span class="p">(</span><span class="n">labels2d</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">spacing</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="go">array([[1, 1, 1, 1],</span>
<span class="go">       [2, 2, 2, 0],</span>
<span class="go">       [3, 3, 3, 3]])</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Given several connected components represented by a label image, these connected components can..."><img alt="" src="../_images/sphx_glr_plot_expand_labels_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_expand_labels.html#sphx-glr-auto-examples-segmentation-plot-expand-labels-py"><span class="std std-ref">Expand segmentation labels without overlap</span></a></p>
  <div class="sphx-glr-thumbnail-title">Expand segmentation labels without overlap</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.felzenszwalb">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">felzenszwalb</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_felzenszwalb.py#L7-L69"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.felzenszwalb" title="Link to this definition">#</a></dt>
<dd><p>Computes Felsenszwalb’s efficient graph based image segmentation.</p>
<p>Produces an oversegmentation of a multichannel (i.e. RGB) image
using a fast, minimum spanning tree based clustering on the image grid.
The parameter <code class="docutils literal notranslate"><span class="pre">scale</span></code> sets an observation level. Higher scale means
less and larger segments. <code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the diameter of a Gaussian kernel,
used for smoothing the image prior to segmentation.</p>
<p>The number of produced segments as well as their size can only be
controlled indirectly through <code class="docutils literal notranslate"><span class="pre">scale</span></code>. Segment size within an image can
vary greatly depending on local contrast.</p>
<p>For RGB images, the algorithm uses the euclidean distance between pixels in
color space.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N[, 3]) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>scale</strong><span class="classifier">float</span></dt><dd><p>Free parameter. Higher means larger clusters.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float</span></dt><dd><p>Width (standard deviation) of Gaussian kernel used in preprocessing.</p>
</dd>
<dt><strong>min_size</strong><span class="classifier">int</span></dt><dd><p>Minimum component size. Enforced using postprocessing.</p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><code class="docutils literal notranslate"><span class="pre">channel_axis</span></code> was added in 0.19.</p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>segment_mask</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Integer mask indicating segment labels.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <em class="xref py py-obj">k</em> parameter used in the original paper renamed to <em class="xref py py-obj">scale</em> here.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r89864356f083-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Efficient graph-based image segmentation, Felzenszwalb, P.F. and
Huttenlocher, D.P.  International Journal of Computer Vision, 2004</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">felzenszwalb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">coffee</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">coffee</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">segments</span> <span class="o">=</span> <span class="n">felzenszwalb</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">min_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to..."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.find_boundaries">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">find_boundaries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">connectivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'thick'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/boundaries.py#L48-L182"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.find_boundaries" title="Link to this definition">#</a></dt>
<dd><p>Return bool array where boundaries between labeled regions are True.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>label_img</strong><span class="classifier">array of int or bool</span></dt><dd><p>An array in which different regions are labeled with either different
integers or boolean values.</p>
</dd>
<dt><strong>connectivity</strong><span class="classifier">int in {1, …, <em class="xref py py-obj">label_img.ndim</em>}, optional</span></dt><dd><p>A pixel is considered a boundary pixel if any of its neighbors
has a different label. <em class="xref py py-obj">connectivity</em> controls which pixels are
considered neighbors. A connectivity of 1 (default) means
pixels sharing an edge (in 2D) or a face (in 3D) will be
considered neighbors. A connectivity of <em class="xref py py-obj">label_img.ndim</em> means
pixels sharing a corner will be considered neighbors.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">string in {‘thick’, ‘inner’, ‘outer’, ‘subpixel’}</span></dt><dd><p>How to mark the boundaries:</p>
<ul class="simple">
<li><p>thick: any pixel not completely surrounded by pixels of the
same label (defined by <em class="xref py py-obj">connectivity</em>) is marked as a boundary.
This results in boundaries that are 2 pixels thick.</p></li>
<li><p>inner: outline the pixels <em>just inside</em> of objects, leaving
background pixels untouched.</p></li>
<li><p>outer: outline pixels in the background around object
boundaries. When two objects touch, their boundary is also
marked.</p></li>
<li><p>subpixel: return a doubled image, with pixels <em>between</em> the
original pixels marked as boundary where appropriate.</p></li>
</ul>
</dd>
<dt><strong>background</strong><span class="classifier">int, optional</span></dt><dd><p>For modes ‘inner’ and ‘outer’, a definition of a background
label is required. See <em class="xref py py-obj">mode</em> for descriptions of these two.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>boundaries</strong><span class="classifier">array of bool, same shape as <em class="xref py py-obj">label_img</em></span></dt><dd><p>A bool image where <code class="docutils literal notranslate"><span class="pre">True</span></code> represents a boundary pixel. For
<em class="xref py py-obj">mode</em> equal to ‘subpixel’, <code class="docutils literal notranslate"><span class="pre">boundaries.shape[i]</span></code> is equal
to <code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">label_img.shape[i]</span> <span class="pre">-</span> <span class="pre">1</span></code> for all <code class="docutils literal notranslate"><span class="pre">i</span></code> (a pixel is
inserted in between all other pairs of pixels).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">find_boundaries</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;thick&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 1, 0],</span>
<span class="go">       [0, 1, 1, 1, 1, 1, 0, 1, 1, 0],</span>
<span class="go">       [0, 1, 1, 0, 1, 1, 0, 1, 1, 0],</span>
<span class="go">       [0, 1, 1, 1, 1, 1, 0, 1, 1, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">find_boundaries</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;inner&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 0, 1, 1, 0, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">find_boundaries</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;outer&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0, 1, 0],</span>
<span class="go">       [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],</span>
<span class="go">       [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],</span>
<span class="go">       [0, 1, 0, 0, 1, 1, 0, 0, 1, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0, 1, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_small</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">::</span><span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_small</span>
<span class="go">array([[0, 0, 0, 0],</span>
<span class="go">       [0, 0, 5, 0],</span>
<span class="go">       [0, 1, 5, 0],</span>
<span class="go">       [0, 0, 5, 0],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">find_boundaries</span><span class="p">(</span><span class="n">labels_small</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;subpixel&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 1, 0, 1, 0],</span>
<span class="go">       [0, 1, 1, 1, 0, 1, 0],</span>
<span class="go">       [0, 1, 0, 1, 0, 1, 0],</span>
<span class="go">       [0, 1, 1, 1, 0, 1, 0],</span>
<span class="go">       [0, 0, 0, 1, 0, 1, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0]], dtype=uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bool_image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="gp">... </span>                       <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="gp">... </span>                       <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
<span class="gp">... </span>                       <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
<span class="gp">... </span>                       <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">]],</span>
<span class="gp">... </span>                      <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">find_boundaries</span><span class="p">(</span><span class="n">bool_image</span><span class="p">)</span>
<span class="go">array([[False, False, False, False, False],</span>
<span class="go">       [False, False,  True,  True,  True],</span>
<span class="go">       [False,  True,  True,  True,  True],</span>
<span class="go">       [False,  True,  True, False, False],</span>
<span class="go">       [False,  True,  True, False, False]])</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.flood">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">flood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed_point</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">footprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">connectivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/morphology/_flood_fill.py#L129-L310"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.flood" title="Link to this definition">#</a></dt>
<dd><p>Mask corresponding to a flood fill.</p>
<p>Starting at a specific <em class="xref py py-obj">seed_point</em>, connected points equal or within
<em class="xref py py-obj">tolerance</em> of the seed value are found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>An n-dimensional array.</p>
</dd>
<dt><strong>seed_point</strong><span class="classifier">tuple or int</span></dt><dd><p>The point in <em class="xref py py-obj">image</em> used as the starting point for the flood fill.  If
the image is 1D, this point may be given as an integer.</p>
</dd>
<dt><strong>footprint</strong><span class="classifier">ndarray, optional</span></dt><dd><p>The footprint (structuring element) used to determine the neighborhood
of each evaluated pixel. It must contain only 1’s and 0’s, have the
same number of dimensions as <em class="xref py py-obj">image</em>. If not given, all adjacent pixels
are considered as part of the neighborhood (fully connected).</p>
</dd>
<dt><strong>connectivity</strong><span class="classifier">int, optional</span></dt><dd><p>A number used to determine the neighborhood of each evaluated pixel.
Adjacent pixels whose squared distance from the center is less than or
equal to <em class="xref py py-obj">connectivity</em> are considered neighbors. Ignored if
<em class="xref py py-obj">footprint</em> is not None.</p>
</dd>
<dt><strong>tolerance</strong><span class="classifier">float or int, optional</span></dt><dd><p>If None (default), adjacent values must be strictly equal to the
initial value of <em class="xref py py-obj">image</em> at <em class="xref py py-obj">seed_point</em>.  This is fastest.  If a value
is given, a comparison will be done at every point and if within
tolerance of the initial value will also be filled (inclusive).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>mask</strong><span class="classifier">ndarray</span></dt><dd><p>A Boolean array with the same shape as <em class="xref py py-obj">image</em> is returned, with True
values for areas connected to and equal (or within tolerance of) the
seed point.  All other values are False.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The conceptual analogy of this operation is the ‘paint bucket’ tool in many
raster graphics programs.  This function returns just the mask
representing the fill.</p>
<p>If indices are desired rather than masks for memory reasons, the user can
simply run <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy.nonzero" title="(in NumPy v2.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.nonzero</span></code></a> on the result, save the indices, and discard
this mask.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.morphology</span> <span class="kn">import</span> <span class="n">flood</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 1, 1, 0, 2, 2, 0],</span>
<span class="go">       [0, 1, 1, 0, 2, 2, 0],</span>
<span class="go">       [1, 0, 0, 0, 0, 0, 3]])</span>
</pre></div>
</div>
<p>Fill connected ones with 5, with full connectivity (diagonals included):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">flood</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [5, 0, 0, 0, 0, 0, 3]])</span>
</pre></div>
</div>
<p>Fill connected ones with 5, excluding diagonal points (connectivity 1):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">flood</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">connectivity</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [1, 0, 0, 0, 0, 0, 3]])</span>
</pre></div>
</div>
<p>Fill with a tolerance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">flood</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image_flooded</span>
<span class="go">array([[5, 5, 5, 5, 5, 5, 5],</span>
<span class="go">       [5, 5, 5, 5, 2, 2, 5],</span>
<span class="go">       [5, 5, 5, 5, 2, 2, 5],</span>
<span class="go">       [5, 5, 5, 5, 5, 5, 3]])</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their..."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.flood_fill">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">flood_fill</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed_point</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_value</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">footprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">connectivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_place</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/morphology/_flood_fill.py#L19-L126"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.flood_fill" title="Link to this definition">#</a></dt>
<dd><p>Perform flood filling on an image.</p>
<p>Starting at a specific <em class="xref py py-obj">seed_point</em>, connected points equal or within
<em class="xref py py-obj">tolerance</em> of the seed value are found, then set to <em class="xref py py-obj">new_value</em>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>An n-dimensional array.</p>
</dd>
<dt><strong>seed_point</strong><span class="classifier">tuple or int</span></dt><dd><p>The point in <em class="xref py py-obj">image</em> used as the starting point for the flood fill.  If
the image is 1D, this point may be given as an integer.</p>
</dd>
<dt><strong>new_value</strong><span class="classifier"><em class="xref py py-obj">image</em> type</span></dt><dd><p>New value to set the entire fill.  This must be chosen in agreement
with the dtype of <em class="xref py py-obj">image</em>.</p>
</dd>
<dt><strong>footprint</strong><span class="classifier">ndarray, optional</span></dt><dd><p>The footprint (structuring element) used to determine the neighborhood
of each evaluated pixel. It must contain only 1’s and 0’s, have the
same number of dimensions as <em class="xref py py-obj">image</em>. If not given, all adjacent pixels
are considered as part of the neighborhood (fully connected).</p>
</dd>
<dt><strong>connectivity</strong><span class="classifier">int, optional</span></dt><dd><p>A number used to determine the neighborhood of each evaluated pixel.
Adjacent pixels whose squared distance from the center is less than or
equal to <em class="xref py py-obj">connectivity</em> are considered neighbors. Ignored if
<em class="xref py py-obj">footprint</em> is not None.</p>
</dd>
<dt><strong>tolerance</strong><span class="classifier">float or int, optional</span></dt><dd><p>If None (default), adjacent values must be strictly equal to the
value of <em class="xref py py-obj">image</em> at <em class="xref py py-obj">seed_point</em> to be filled.  This is fastest.
If a tolerance is provided, adjacent points with values within plus or
minus tolerance from the seed point are filled (inclusive).</p>
</dd>
<dt><strong>in_place</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, flood filling is applied to <em class="xref py py-obj">image</em> in place.  If False, the
flood filled result is returned without modifying the input <em class="xref py py-obj">image</em>
(default).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>filled</strong><span class="classifier">ndarray</span></dt><dd><p>An array with the same shape as <em class="xref py py-obj">image</em> is returned, with values in
areas connected to and equal (or within tolerance of) the seed point
replaced with <em class="xref py py-obj">new_value</em>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The conceptual analogy of this operation is the ‘paint bucket’ tool in many
raster graphics programs.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.morphology</span> <span class="kn">import</span> <span class="n">flood_fill</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 1, 1, 0, 2, 2, 0],</span>
<span class="go">       [0, 1, 1, 0, 2, 2, 0],</span>
<span class="go">       [1, 0, 0, 0, 0, 0, 3]])</span>
</pre></div>
</div>
<p>Fill connected ones with 5, with full connectivity (diagonals included):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">flood_fill</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [5, 0, 0, 0, 0, 0, 3]])</span>
</pre></div>
</div>
<p>Fill connected ones with 5, excluding diagonal points (connectivity 1):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">flood_fill</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">5</span><span class="p">,</span> <span class="n">connectivity</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [0, 5, 5, 0, 2, 2, 0],</span>
<span class="go">       [1, 0, 0, 0, 0, 0, 3]])</span>
</pre></div>
</div>
<p>Fill with a tolerance:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">flood_fill</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">5</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[5, 5, 5, 5, 5, 5, 5],</span>
<span class="go">       [5, 5, 5, 5, 2, 2, 5],</span>
<span class="go">       [5, 5, 5, 5, 2, 2, 5],</span>
<span class="go">       [5, 5, 5, 5, 5, 5, 3]])</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their..."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.inverse_gaussian_gradient">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">inverse_gaussian_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5.0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/morphsnakes.py#L182-L211"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.inverse_gaussian_gradient" title="Link to this definition">#</a></dt>
<dd><p>Inverse of gradient magnitude.</p>
<p>Compute the magnitude of the gradients in the image and then inverts the
result in the range [0, 1]. Flat areas are assigned values close to 1,
while areas close to borders are assigned values close to 0.</p>
<p>This function or a similar one defined by the user should be applied over
the image as a preprocessing step before calling
<a class="reference internal" href="#skimage.segmentation.morphological_geodesic_active_contour" title="skimage.segmentation.morphological_geodesic_active_contour"><code class="xref py py-obj docutils literal notranslate"><span class="pre">morphological_geodesic_active_contour</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N) or (L, M, N) array</span></dt><dd><p>Grayscale image or volume.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Controls the steepness of the inversion. A larger value will make the
transition between the flat areas and border areas steeper in the
resulting array.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation of the Gaussian filter applied over the image.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>gimage</strong><span class="classifier">(M, N) or (L, M, N) array</span></dt><dd><p>Preprocessed image (or volume) suitable for
<a class="reference internal" href="#skimage.segmentation.morphological_geodesic_active_contour" title="skimage.segmentation.morphological_geodesic_active_contour"><code class="xref py py-obj docutils literal notranslate"><span class="pre">morphological_geodesic_active_contour</span></code></a>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Morphological Snakes [1]_ are a family of methods for image segmentation. Their behavior is sim..."><img alt="" src="../_images/sphx_glr_plot_morphsnakes_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_morphsnakes.html#sphx-glr-auto-examples-segmentation-plot-morphsnakes-py"><span class="std std-ref">Morphological Snakes</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Snakes</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When trying out different segmentation methods, how do you know which one is best? If you have ..."><img alt="" src="../_images/sphx_glr_plot_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_metrics.html#sphx-glr-auto-examples-segmentation-plot-metrics-py"><span class="std std-ref">Evaluating segmentation metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluating segmentation metrics</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.join_segmentations">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">join_segmentations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_mapping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_join.py#L6-L73"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.join_segmentations" title="Link to this definition">#</a></dt>
<dd><p>Return the join of the two input segmentations.</p>
<p>The join J of S1 and S2 is defined as the segmentation in which two
voxels are in the same segment if and only if they are in the same
segment in <em>both</em> S1 and S2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>s1, s2</strong><span class="classifier">numpy arrays</span></dt><dd><p>s1 and s2 are label fields of the same shape.</p>
</dd>
<dt><strong>return_mapping</strong><span class="classifier">bool, optional</span></dt><dd><p>If true, return mappings for joined segmentation labels to the original labels.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>j</strong><span class="classifier">numpy array</span></dt><dd><p>The join segmentation of s1 and s2.</p>
</dd>
<dt><strong>map_j_to_s1</strong><span class="classifier">ArrayMap, optional</span></dt><dd><p>Mapping from labels of the joined segmentation j to labels of s1.</p>
</dd>
<dt><strong>map_j_to_s2</strong><span class="classifier">ArrayMap, optional</span></dt><dd><p>Mapping from labels of the joined segmentation j to labels of s2.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">join_segmentations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>               <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>               <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>               <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>               <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">join_segmentations</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">)</span>
<span class="go">array([[0, 1, 3, 2],</span>
<span class="go">       [0, 5, 3, 2],</span>
<span class="go">       [4, 5, 5, 3]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">j</span><span class="p">,</span> <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">join_segmentations</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">return_mapping</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m1</span>
<span class="go">ArrayMap(array([0, 1, 2, 3, 4, 5]), array([0, 0, 1, 1, 2, 2]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">m1</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">s1</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">m2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">s2</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="When segmenting an image, you may want to combine multiple alternative segmentations. The :pysk..."><img alt="" src="../_images/sphx_glr_plot_join_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_join_segmentations.html#sphx-glr-auto-examples-segmentation-plot-join-segmentations-py"><span class="std std-ref">Find the intersection of two segmentations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find the intersection of two segmentations</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.mark_boundaries">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">mark_boundaries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1,</span> <span class="pre">1,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outline_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'outer'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/boundaries.py#L185-L240"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.mark_boundaries" title="Link to this definition">#</a></dt>
<dd><p>Return image with boundaries between labeled regions highlighted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, 3]) array</span></dt><dd><p>Grayscale or RGB image.</p>
</dd>
<dt><strong>label_img</strong><span class="classifier">(M, N) array of int</span></dt><dd><p>Label array where regions are marked by different integer values.</p>
</dd>
<dt><strong>color</strong><span class="classifier">length-3 sequence, optional</span></dt><dd><p>RGB color of boundaries in the output image.</p>
</dd>
<dt><strong>outline_color</strong><span class="classifier">length-3 sequence, optional</span></dt><dd><p>RGB color surrounding boundaries in the output image. If None, no
outline is drawn.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">string in {‘thick’, ‘inner’, ‘outer’, ‘subpixel’}, optional</span></dt><dd><p>The mode for finding boundaries.</p>
</dd>
<dt><strong>background_label</strong><span class="classifier">int, optional</span></dt><dd><p>Which label to consider background (this is only useful for
modes <code class="docutils literal notranslate"><span class="pre">inner</span></code> and <code class="docutils literal notranslate"><span class="pre">outer</span></code>).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>marked</strong><span class="classifier">(M, N, 3) array of float</span></dt><dd><p>An image in which the boundaries between labels are
superimposed on the original image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.find_boundaries" title="skimage.segmentation.find_boundaries"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_boundaries</span></code></a></dt><dd></dd>
</dl>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example is about comparing the segmentations obtained using the plain SLIC method [1]_ and..."><img alt="" src="../_images/sphx_glr_plot_mask_slic_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_mask_slic.html#sphx-glr-auto-examples-segmentation-plot-mask-slic-py"><span class="std std-ref">Apply maskSLIC vs SLIC</span></a></p>
  <div class="sphx-glr-thumbnail-title">Apply maskSLIC vs SLIC</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to..."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and progressively merges regions that ar..."><img alt="" src="../_images/sphx_glr_plot_rag_merge_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_merge.html#sphx-glr-auto-examples-segmentation-plot-rag-merge-py"><span class="std std-ref">Region adjacency graph (RAG) Merging</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region adjacency graph (RAG) Merging</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A pixel-based segmentation is computed here using local features based on local intensity, edge..."><img alt="" src="../_images/sphx_glr_plot_trainable_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_trainable_segmentation.html#sphx-glr-auto-examples-segmentation-plot-trainable-segmentation-py"><span class="std std-ref">Trainable segmentation using local features and random forests</span></a></p>
  <div class="sphx-glr-thumbnail-title">Trainable segmentation using local features and random forests</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When trying out different segmentation methods, how do you know which one is best? If you have ..."><img alt="" src="../_images/sphx_glr_plot_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_metrics.html#sphx-glr-auto-examples-segmentation-plot-metrics-py"><span class="std std-ref">Evaluating segmentation metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluating segmentation metrics</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.morphological_chan_vese">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">morphological_chan_vese</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_level_set='checkerboard'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda1=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda2=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter_callback=&lt;function</span> <span class="pre">&lt;lambda&gt;&gt;</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/morphsnakes.py#L214-L319"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.morphological_chan_vese" title="Link to this definition">#</a></dt>
<dd><p>Morphological Active Contours without Edges (MorphACWE)</p>
<p>Active contours without edges implemented with morphological operators. It
can be used to segment objects in images and volumes without well defined
borders. It is required that the inside of the object looks different on
average than the outside (i.e., the inner area of the object should be
darker or lighter than the outer area on average).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N) or (L, M, N) array</span></dt><dd><p>Grayscale image or volume to be segmented.</p>
</dd>
<dt><strong>num_iter</strong><span class="classifier">uint</span></dt><dd><p>Number of num_iter to run</p>
</dd>
<dt><strong>init_level_set</strong><span class="classifier">str, (M, N) array, or (L, M, N) array</span></dt><dd><p>Initial level set. If an array is given, it will be binarized and used
as the initial level set. If a string is given, it defines the method
to generate a reasonable initial level set with the shape of the
<em class="xref py py-obj">image</em>. Accepted values are ‘checkerboard’ and ‘disk’. See the
documentation of <a class="reference internal" href="#skimage.segmentation.checkerboard_level_set" title="skimage.segmentation.checkerboard_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">checkerboard_level_set</span></code></a> and <a class="reference internal" href="#skimage.segmentation.disk_level_set" title="skimage.segmentation.disk_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">disk_level_set</span></code></a>
respectively for details about how these level sets are created.</p>
</dd>
<dt><strong>smoothing</strong><span class="classifier">uint, optional</span></dt><dd><p>Number of times the smoothing operator is applied per iteration.
Reasonable values are around 1-4. Larger values lead to smoother
segmentations.</p>
</dd>
<dt><strong>lambda1</strong><span class="classifier">float, optional</span></dt><dd><p>Weight parameter for the outer region. If <em class="xref py py-obj">lambda1</em> is larger than
<em class="xref py py-obj">lambda2</em>, the outer region will contain a larger range of values than
the inner region.</p>
</dd>
<dt><strong>lambda2</strong><span class="classifier">float, optional</span></dt><dd><p>Weight parameter for the inner region. If <em class="xref py py-obj">lambda2</em> is larger than
<em class="xref py py-obj">lambda1</em>, the inner region will contain a larger range of values than
the outer region.</p>
</dd>
<dt><strong>iter_callback</strong><span class="classifier">function, optional</span></dt><dd><p>If given, this function is called once per iteration with the current
level set as the only argument. This is useful for debugging or for
plotting intermediate results during the evolution.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M, N) or (L, M, N) array</span></dt><dd><p>Final segmentation (i.e., the final level set)</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.disk_level_set" title="skimage.segmentation.disk_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">disk_level_set</span></code></a>, <a class="reference internal" href="#skimage.segmentation.checkerboard_level_set" title="skimage.segmentation.checkerboard_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">checkerboard_level_set</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This is a version of the Chan-Vese algorithm that uses morphological
operators instead of solving a partial differential equation (PDE) for the
evolution of the contour. The set of morphological operators used in this
algorithm are proved to be infinitesimally equivalent to the Chan-Vese PDE
(see <a class="reference internal" href="#r81c856a3d0d3-1" id="id11">[1]</a>). However, morphological operators are do not suffer from the
numerical stability issues typically found in PDEs (it is not necessary to
find the right time step for the evolution), and are computationally
faster.</p>
<p>The algorithm and its theoretical derivation are described in <a class="reference internal" href="#r81c856a3d0d3-1" id="id12">[1]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r81c856a3d0d3-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id11">1</a>,<a role="doc-backlink" href="#id12">2</a>)</span>
<p>A Morphological Approach to Curvature-based Evolution of Curves and
Surfaces, Pablo Márquez-Neila, Luis Baumela, Luis Álvarez. In IEEE
Transactions on Pattern Analysis and Machine Intelligence (PAMI),
2014, <a class="reference external" href="https://doi.org/10.1109/TPAMI.2013.106">DOI:10.1109/TPAMI.2013.106</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Morphological Snakes [1]_ are a family of methods for image segmentation. Their behavior is sim..."><img alt="" src="../_images/sphx_glr_plot_morphsnakes_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_morphsnakes.html#sphx-glr-auto-examples-segmentation-plot-morphsnakes-py"><span class="std std-ref">Morphological Snakes</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Snakes</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.morphological_geodesic_active_contour">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">morphological_geodesic_active_contour</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gimage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_level_set='disk'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold='auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balloon=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter_callback=&lt;function</span> <span class="pre">&lt;lambda&gt;&gt;</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/morphsnakes.py#L322-L449"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.morphological_geodesic_active_contour" title="Link to this definition">#</a></dt>
<dd><p>Morphological Geodesic Active Contours (MorphGAC).</p>
<p>Geodesic active contours implemented with morphological operators. It can
be used to segment objects with visible but noisy, cluttered, broken
borders.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>gimage</strong><span class="classifier">(M, N) or (L, M, N) array</span></dt><dd><p>Preprocessed image or volume to be segmented. This is very rarely the
original image. Instead, this is usually a preprocessed version of the
original image that enhances and highlights the borders (or other
structures) of the object to segment.
<a class="reference internal" href="#skimage.segmentation.morphological_geodesic_active_contour" title="skimage.segmentation.morphological_geodesic_active_contour"><code class="xref py py-func docutils literal notranslate"><span class="pre">morphological_geodesic_active_contour()</span></code></a> will try to stop the contour
evolution in areas where <em class="xref py py-obj">gimage</em> is small. See
<a class="reference internal" href="#skimage.segmentation.inverse_gaussian_gradient" title="skimage.segmentation.inverse_gaussian_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">inverse_gaussian_gradient()</span></code></a> as an example function to
perform this preprocessing. Note that the quality of
<a class="reference internal" href="#skimage.segmentation.morphological_geodesic_active_contour" title="skimage.segmentation.morphological_geodesic_active_contour"><code class="xref py py-func docutils literal notranslate"><span class="pre">morphological_geodesic_active_contour()</span></code></a> might greatly depend on this
preprocessing.</p>
</dd>
<dt><strong>num_iter</strong><span class="classifier">uint</span></dt><dd><p>Number of num_iter to run.</p>
</dd>
<dt><strong>init_level_set</strong><span class="classifier">str, (M, N) array, or (L, M, N) array</span></dt><dd><p>Initial level set. If an array is given, it will be binarized and used
as the initial level set. If a string is given, it defines the method
to generate a reasonable initial level set with the shape of the
<em class="xref py py-obj">image</em>. Accepted values are ‘checkerboard’ and ‘disk’. See the
documentation of <a class="reference internal" href="#skimage.segmentation.checkerboard_level_set" title="skimage.segmentation.checkerboard_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">checkerboard_level_set</span></code></a> and <a class="reference internal" href="#skimage.segmentation.disk_level_set" title="skimage.segmentation.disk_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">disk_level_set</span></code></a>
respectively for details about how these level sets are created.</p>
</dd>
<dt><strong>smoothing</strong><span class="classifier">uint, optional</span></dt><dd><p>Number of times the smoothing operator is applied per iteration.
Reasonable values are around 1-4. Larger values lead to smoother
segmentations.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional</span></dt><dd><p>Areas of the image with a value smaller than this threshold will be
considered borders. The evolution of the contour will stop in these
areas.</p>
</dd>
<dt><strong>balloon</strong><span class="classifier">float, optional</span></dt><dd><p>Balloon force to guide the contour in non-informative areas of the
image, i.e., areas where the gradient of the image is too small to push
the contour towards a border. A negative value will shrink the contour,
while a positive value will expand the contour in these areas. Setting
this to zero will disable the balloon force.</p>
</dd>
<dt><strong>iter_callback</strong><span class="classifier">function, optional</span></dt><dd><p>If given, this function is called once per iteration with the current
level set as the only argument. This is useful for debugging or for
plotting intermediate results during the evolution.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M, N) or (L, M, N) array</span></dt><dd><p>Final segmentation (i.e., the final level set)</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.inverse_gaussian_gradient" title="skimage.segmentation.inverse_gaussian_gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inverse_gaussian_gradient</span></code></a>, <a class="reference internal" href="#skimage.segmentation.disk_level_set" title="skimage.segmentation.disk_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">disk_level_set</span></code></a>, <a class="reference internal" href="#skimage.segmentation.checkerboard_level_set" title="skimage.segmentation.checkerboard_level_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">checkerboard_level_set</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This is a version of the Geodesic Active Contours (GAC) algorithm that uses
morphological operators instead of solving partial differential equations
(PDEs) for the evolution of the contour. The set of morphological operators
used in this algorithm are proved to be infinitesimally equivalent to the
GAC PDEs (see <a class="reference internal" href="#rb6daaf5d7730-1" id="id14">[1]</a>). However, morphological operators are do not suffer
from the numerical stability issues typically found in PDEs (e.g., it is
not necessary to find the right time step for the evolution), and are
computationally faster.</p>
<p>The algorithm and its theoretical derivation are described in <a class="reference internal" href="#rb6daaf5d7730-1" id="id15">[1]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rb6daaf5d7730-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id14">1</a>,<a role="doc-backlink" href="#id15">2</a>)</span>
<p>A Morphological Approach to Curvature-based Evolution of Curves and
Surfaces, Pablo Márquez-Neila, Luis Baumela, Luis Álvarez. In IEEE
Transactions on Pattern Analysis and Machine Intelligence (PAMI),
2014, <a class="reference external" href="https://doi.org/10.1109/TPAMI.2013.106">DOI:10.1109/TPAMI.2013.106</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Morphological Snakes [1]_ are a family of methods for image segmentation. Their behavior is sim..."><img alt="" src="../_images/sphx_glr_plot_morphsnakes_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_morphsnakes.html#sphx-glr-auto-examples-segmentation-plot-morphsnakes-py"><span class="std std-ref">Morphological Snakes</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Snakes</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When trying out different segmentation methods, how do you know which one is best? If you have ..."><img alt="" src="../_images/sphx_glr_plot_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_metrics.html#sphx-glr-auto-examples-segmentation-plot-metrics-py"><span class="std std-ref">Evaluating segmentation metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluating segmentation metrics</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.quickshift">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">quickshift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert2lab</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_quickshift.py#L10-L104"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.quickshift" title="Link to this definition">#</a></dt>
<dd><p>Segment image using quickshift clustering in Color-(x,y) space.</p>
<p>Produces an oversegmentation of the image using the quickshift mode-seeking
algorithm.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N, C) ndarray</span></dt><dd><p>Input image. The axis corresponding to color channels can be specified
via the <em class="xref py py-obj">channel_axis</em> argument.</p>
</dd>
<dt><strong>ratio</strong><span class="classifier">float, optional, between 0 and 1</span></dt><dd><p>Balances color-space proximity and image-space proximity.
Higher values give more weight to color-space.</p>
</dd>
<dt><strong>kernel_size</strong><span class="classifier">float, optional</span></dt><dd><p>Width of Gaussian kernel used in smoothing the
sample density. Higher means fewer clusters.</p>
</dd>
<dt><strong>max_dist</strong><span class="classifier">float, optional</span></dt><dd><p>Cut-off point for data distances.
Higher means fewer clusters.</p>
</dd>
<dt><strong>return_tree</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to return the full segmentation hierarchy tree and distances.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Width for Gaussian smoothing as preprocessing. Zero means no smoothing.</p>
</dd>
<dt><strong>convert2lab</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether the input should be converted to Lab colorspace prior to
segmentation. For this purpose, the input is assumed to be RGB.</p>
</dd>
<dt><strong>rng</strong><span class="classifier">{<a class="reference external" href="https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.Generator" title="(in NumPy v2.0)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.random.Generator</span></code></a>, int}, optional</span></dt><dd><p>Pseudo-random number generator.
By default, a PCG64 generator is used (see <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng" title="(in NumPy v2.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.random.default_rng()</span></code></a>).
If <em class="xref py py-obj">rng</em> is an int, it is used to seed the generator.</p>
<p>The PRNG is used to break ties, and is seeded with 42 by default.</p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int, optional</span></dt><dd><p>The axis of <em class="xref py py-obj">image</em> corresponding to color channels. Defaults to the
last axis.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>segment_mask</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Integer mask indicating segment labels.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The authors advocate to convert the image to Lab color space prior to
segmentation, though this is not strictly necessary. For this to work, the
image must be given in RGB format.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r7604e01a2c85-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Quick shift and kernel methods for mode seeking,
Vedaldi, A. and Soatto, S.
European Conference on Computer Vision, 2008</p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to..."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.random_walker">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">random_walker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">130</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cg_j'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spacing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/random_walker_segmentation.py#L308-L580"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.random_walker" title="Link to this definition">#</a></dt>
<dd><p>Random walker algorithm for segmentation from markers.</p>
<p>Random walker algorithm is implemented for gray-level or multichannel
images.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>data</strong><span class="classifier">(M, N[, P][, C]) ndarray</span></dt><dd><p>Image to be segmented in phases. Gray-level <em class="xref py py-obj">data</em> can be two- or
three-dimensional; multichannel data can be three- or four-
dimensional with <em class="xref py py-obj">channel_axis</em> specifying the dimension containing
channels. Data spacing is assumed isotropic unless the <em class="xref py py-obj">spacing</em>
keyword argument is used.</p>
</dd>
<dt><strong>labels</strong><span class="classifier">(M, N[, P]) array of ints</span></dt><dd><p>Array of seed markers labeled with different positive integers
for different phases. Zero-labeled pixels are unlabeled pixels.
Negative labels correspond to inactive pixels that are not taken
into account (they are removed from the graph). If labels are not
consecutive integers, the labels array will be transformed so that
labels are consecutive. In the multichannel case, <em class="xref py py-obj">labels</em> should have
the same shape as a single channel of <em class="xref py py-obj">data</em>, i.e. without the final
dimension denoting channels.</p>
</dd>
<dt><strong>beta</strong><span class="classifier">float, optional</span></dt><dd><p>Penalization coefficient for the random walker motion
(the greater <em class="xref py py-obj">beta</em>, the more difficult the diffusion).</p>
</dd>
<dt><strong>mode</strong><span class="classifier">string, available options {‘cg’, ‘cg_j’, ‘cg_mg’, ‘bf’}</span></dt><dd><p>Mode for solving the linear system in the random walker algorithm.</p>
<ul class="simple">
<li><p>‘bf’ (brute force): an LU factorization of the Laplacian is
computed. This is fast for small images (&lt;1024x1024), but very slow
and memory-intensive for large images (e.g., 3-D volumes).</p></li>
<li><p>‘cg’ (conjugate gradient): the linear system is solved iteratively
using the Conjugate Gradient method from scipy.sparse.linalg. This is
less memory-consuming than the brute force method for large images,
but it is quite slow.</p></li>
<li><p>‘cg_j’ (conjugate gradient with Jacobi preconditionner): the
Jacobi preconditionner is applied during the Conjugate
gradient method iterations. This may accelerate the
convergence of the ‘cg’ method.</p></li>
<li><p>‘cg_mg’ (conjugate gradient with multigrid preconditioner): a
preconditioner is computed using a multigrid solver, then the
solution is computed with the Conjugate Gradient method. This mode
requires that the pyamg module is installed.</p></li>
</ul>
</dd>
<dt><strong>tol</strong><span class="classifier">float, optional</span></dt><dd><p>Tolerance to achieve when solving the linear system using
the conjugate gradient based modes (‘cg’, ‘cg_j’ and ‘cg_mg’).</p>
</dd>
<dt><strong>copy</strong><span class="classifier">bool, optional</span></dt><dd><p>If copy is False, the <em class="xref py py-obj">labels</em> array will be overwritten with
the result of the segmentation. Use copy=False if you want to
save on memory.</p>
</dd>
<dt><strong>return_full_prob</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, the probability that a pixel belongs to each of the
labels will be returned, instead of only the most likely
label.</p>
</dd>
<dt><strong>spacing</strong><span class="classifier">iterable of floats, optional</span></dt><dd><p>Spacing between voxels in each spatial dimension. If <em class="xref py py-obj">None</em>, then
the spacing between pixels/voxels in each dimension is assumed 1.</p>
</dd>
<dt><strong>prob_tol</strong><span class="classifier">float, optional</span></dt><dd><p>Tolerance on the resulting probability to be in the interval [0, 1].
If the tolerance is not satisfied, a warning is displayed.</p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><code class="docutils literal notranslate"><span class="pre">channel_axis</span></code> was added in 0.19.</p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">ndarray</span></dt><dd><ul class="simple">
<li><p>If <em class="xref py py-obj">return_full_prob</em> is False, array of ints of same shape
and data type as <em class="xref py py-obj">labels</em>, in which each pixel has been
labeled according to the marker that reached the pixel first
by anisotropic diffusion.</p></li>
<li><p>If <em class="xref py py-obj">return_full_prob</em> is True, array of floats of shape
<em class="xref py py-obj">(nlabels, labels.shape)</em>. <em class="xref py py-obj">output[label_nb, i, j]</em> is the
probability that label <em class="xref py py-obj">label_nb</em> reaches the pixel <em class="xref py py-obj">(i, j)</em>
first.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.watershed" title="skimage.segmentation.watershed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.watershed</span></code></a></dt><dd><p>A segmentation algorithm based on mathematical morphology and “flooding” of regions from markers.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Multichannel inputs are scaled with all channel data combined. Ensure all
channels are separately normalized prior to running this algorithm.</p>
<p>The <em class="xref py py-obj">spacing</em> argument is specifically for anisotropic datasets, where
data points are spaced differently in one or more spatial dimensions.
Anisotropic data is commonly encountered in medical imaging.</p>
<p>The algorithm was first proposed in <a class="reference internal" href="#raf7f6bdcab09-1" id="id18">[1]</a>.</p>
<p>The algorithm solves the diffusion equation at infinite times for
sources placed on markers of each phase in turn. A pixel is labeled with
the phase that has the greatest probability to diffuse first to the pixel.</p>
<p>The diffusion equation is solved by minimizing x.T L x for each phase,
where L is the Laplacian of the weighted graph of the image, and x is
the probability that a marker of the given phase arrives first at a pixel
by diffusion (x=1 on markers of the phase, x=0 on the other markers, and
the other coefficients are looked for). Each pixel is attributed the label
for which it has a maximal value of x. The Laplacian L of the image
is defined as:</p>
<blockquote>
<div><ul class="simple">
<li><p>L_ii = d_i, the number of neighbors of pixel i (the degree of i)</p></li>
<li><p>L_ij = -w_ij if i and j are adjacent pixels</p></li>
</ul>
</div></blockquote>
<p>The weight w_ij is a decreasing function of the norm of the local gradient.
This ensures that diffusion is easier between pixels of similar values.</p>
<p>When the Laplacian is decomposed into blocks of marked and unmarked
pixels:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">L</span> <span class="o">=</span> <span class="n">M</span> <span class="n">B</span><span class="o">.</span><span class="n">T</span>
    <span class="n">B</span> <span class="n">A</span>
</pre></div>
</div>
<p>with first indices corresponding to marked pixels, and then to unmarked
pixels, minimizing x.T L x for one phase amount to solving:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="n">x</span> <span class="o">=</span> <span class="o">-</span> <span class="n">B</span> <span class="n">x_m</span>
</pre></div>
</div>
<p>where x_m = 1 on markers of the given phase, and 0 on other markers.
This linear system is solved in the algorithm using a direct method for
small images, and an iterative method for larger images.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="raf7f6bdcab09-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">1</a><span class="fn-bracket">]</span></span>
<p>Leo Grady, Random walks for image segmentation, IEEE Trans Pattern
Anal Mach Intell. 2006 Nov;28(11):1768-83.
<a class="reference external" href="https://doi.org/10.1109/TPAMI.2006.233">DOI:10.1109/TPAMI.2006.233</a>.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Marker for first phase</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Marker for second phase</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random_walker</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>  
<span class="go">array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 2, 2, 2, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 2, 2, 2, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 2, 2, 2, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The random walker algorithm [1]_  determines the segmentation of an image from a set of markers..."><img alt="" src="../_images/sphx_glr_plot_random_walker_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_random_walker_segmentation.html#sphx-glr-auto-examples-segmentation-plot-random-walker-segmentation-py"><span class="std std-ref">Random walker segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Random walker segmentation</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.relabel_sequential">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">relabel_sequential</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_field</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_join.py#L76-L184"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.relabel_sequential" title="Link to this definition">#</a></dt>
<dd><p>Relabel arbitrary labels to {<em class="xref py py-obj">offset</em>, … <em class="xref py py-obj">offset</em> + number_of_labels}.</p>
<p>This function also returns the forward map (mapping the original labels to
the reduced labels) and the inverse map (mapping the reduced labels back
to the original ones).</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_field</strong><span class="classifier">numpy array of int, arbitrary shape</span></dt><dd><p>An array of labels, which must be non-negative integers.</p>
</dd>
<dt><strong>offset</strong><span class="classifier">int, optional</span></dt><dd><p>The return labels will start at <em class="xref py py-obj">offset</em>, which should be
strictly positive.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>relabeled</strong><span class="classifier">numpy array of int, same shape as <em class="xref py py-obj">label_field</em></span></dt><dd><p>The input label field with labels mapped to
{offset, …, number_of_labels + offset - 1}.
The data type will be the same as <em class="xref py py-obj">label_field</em>, except when
offset + number_of_labels causes overflow of the current data type.</p>
</dd>
<dt><strong>forward_map</strong><span class="classifier">ArrayMap</span></dt><dd><p>The map from the original label space to the returned label
space. Can be used to re-apply the same mapping. See examples
for usage. The output data type will be the same as <em class="xref py py-obj">relabeled</em>.</p>
</dd>
<dt><strong>inverse_map</strong><span class="classifier">ArrayMap</span></dt><dd><p>The map from the new label space to the original space. This
can be used to reconstruct the original label field from the
relabeled one. The output data type will be the same as <em class="xref py py-obj">label_field</em>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The label 0 is assumed to denote the background and is never remapped.</p>
<p>The forward map can be extremely big for some inputs, since its
length is given by the maximum of the label field. However, in most
situations, <code class="docutils literal notranslate"><span class="pre">label_field.max()</span></code> is much smaller than
<code class="docutils literal notranslate"><span class="pre">label_field.size</span></code>, and in these cases the forward map is
guaranteed to be smaller than either the input or output images.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">relabel_sequential</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_field</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">99</span><span class="p">,</span> <span class="mi">42</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relab</span><span class="p">,</span> <span class="n">fw</span><span class="p">,</span> <span class="n">inv</span> <span class="o">=</span> <span class="n">relabel_sequential</span><span class="p">(</span><span class="n">label_field</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relab</span>
<span class="go">array([1, 1, 2, 2, 3, 5, 4])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">fw</span><span class="p">)</span>
<span class="go">ArrayMap:</span>
<span class="go">  1 → 1</span>
<span class="go">  5 → 2</span>
<span class="go">  8 → 3</span>
<span class="go">  42 → 4</span>
<span class="go">  99 → 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">fw</span><span class="p">)</span>
<span class="go">array([0, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0,</span>
<span class="go">       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,</span>
<span class="go">       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inv</span><span class="p">)</span>
<span class="go">array([ 0,  1,  5,  8, 42, 99])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">fw</span><span class="p">[</span><span class="n">label_field</span><span class="p">]</span> <span class="o">==</span> <span class="n">relab</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">inv</span><span class="p">[</span><span class="n">relab</span><span class="p">]</span> <span class="o">==</span> <span class="n">label_field</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relab</span><span class="p">,</span> <span class="n">fw</span><span class="p">,</span> <span class="n">inv</span> <span class="o">=</span> <span class="n">relabel_sequential</span><span class="p">(</span><span class="n">label_field</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">relab</span>
<span class="go">array([5, 5, 6, 6, 7, 9, 8])</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.slic">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">slic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_segments</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compactness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spacing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert2lab</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enforce_connectivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_size_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slic_zero</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/slic_superpixels.py#L105-L449"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.slic" title="Link to this definition">#</a></dt>
<dd><p>Segments image using k-means clustering in Color-(x,y,z) space.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N[, P][, C]) ndarray</span></dt><dd><p>Input image. Can be 2D or 3D, and grayscale or multichannel
(see <em class="xref py py-obj">channel_axis</em> parameter).
Input image must either be NaN-free or the NaN’s must be masked out.</p>
</dd>
<dt><strong>n_segments</strong><span class="classifier">int, optional</span></dt><dd><p>The (approximate) number of labels in the segmented output image.</p>
</dd>
<dt><strong>compactness</strong><span class="classifier">float, optional</span></dt><dd><p>Balances color proximity and space proximity. Higher values give
more weight to space proximity, making superpixel shapes more
square/cubic. In SLICO mode, this is the initial compactness.
This parameter depends strongly on image contrast and on the
shapes of objects in the image. We recommend exploring possible
values on a log scale, e.g., 0.01, 0.1, 1, 10, 100, before
refining around a chosen value.</p>
</dd>
<dt><strong>max_num_iter</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of iterations of k-means.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float or array-like of floats, optional</span></dt><dd><p>Width of Gaussian smoothing kernel for pre-processing for each
dimension of the image. The same sigma is applied to each dimension in
case of a scalar value. Zero means no smoothing.
Note that <em class="xref py py-obj">sigma</em> is automatically scaled if it is scalar and
if a manual voxel spacing is provided (see Notes section). If
sigma is array-like, its size must match <code class="docutils literal notranslate"><span class="pre">image</span></code>’s number
of spatial dimensions.</p>
</dd>
<dt><strong>spacing</strong><span class="classifier">array-like of floats, optional</span></dt><dd><p>The voxel spacing along each spatial dimension. By default,
<a class="reference internal" href="#skimage.segmentation.slic" title="skimage.segmentation.slic"><code class="xref py py-obj docutils literal notranslate"><span class="pre">slic</span></code></a> assumes uniform spacing (same voxel resolution along
each spatial dimension).
This parameter controls the weights of the distances along the
spatial dimensions during k-means clustering.</p>
</dd>
<dt><strong>convert2lab</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether the input should be converted to Lab colorspace prior to
segmentation. The input image <em>must</em> be RGB. Highly recommended.
This option defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code> when <code class="docutils literal notranslate"><span class="pre">channel_axis`</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">None</span> <span class="pre">*and*</span>
<span class="pre">``image.shape[-1]</span> <span class="pre">==</span> <span class="pre">3</span></code>.</p>
</dd>
<dt><strong>enforce_connectivity</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether the generated segments are connected or not</p>
</dd>
<dt><strong>min_size_factor</strong><span class="classifier">float, optional</span></dt><dd><p>Proportion of the minimum segment size to be removed with respect
to the supposed segment size <code class="docutils literal notranslate"><span class="pre">`depth*width*height/n_segments`</span></code></p>
</dd>
<dt><strong>max_size_factor</strong><span class="classifier">float, optional</span></dt><dd><p>Proportion of the maximum connected segment size. A value of 3 works
in most of the cases.</p>
</dd>
<dt><strong>slic_zero</strong><span class="classifier">bool, optional</span></dt><dd><p>Run SLIC-zero, the zero-parameter mode of SLIC. <a class="reference internal" href="#rbeb231216055-2" id="id20">[2]</a></p>
</dd>
<dt><strong>start_label</strong><span class="classifier">int, optional</span></dt><dd><p>The labels’ index start. Should be 0 or 1.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.17: </span><code class="docutils literal notranslate"><span class="pre">start_label</span></code> was introduced in 0.17</p>
</div>
</dd>
<dt><strong>mask</strong><span class="classifier">ndarray, optional</span></dt><dd><p>If provided, superpixels are computed only where mask is True,
and seed points are homogeneously distributed over the mask
using a k-means clustering strategy. Mask number of dimensions
must be equal to image number of spatial dimensions.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.17: </span><code class="docutils literal notranslate"><span class="pre">mask</span></code> was introduced in 0.17</p>
</div>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><code class="docutils literal notranslate"><span class="pre">channel_axis</span></code> was added in 0.19.</p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">2D or 3D array</span></dt><dd><p>Integer mask indicating segment labels.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">convert2lab</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> but the last array
dimension is not of length 3.</p>
</dd>
<dt>ValueError</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">start_label</span></code> is not 0 or 1.</p>
</dd>
<dt>ValueError</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">image</span></code> contains unmasked NaN values.</p>
</dd>
<dt>ValueError</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">image</span></code> contains unmasked infinite values.</p>
</dd>
<dt>ValueError</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">image</span></code> is 2D but <code class="docutils literal notranslate"><span class="pre">channel_axis</span></code> is -1 (the default).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>If <em class="xref py py-obj">sigma &gt; 0</em>, the image is smoothed using a Gaussian kernel prior to
segmentation.</p></li>
<li><p>If <em class="xref py py-obj">sigma</em> is scalar and <em class="xref py py-obj">spacing</em> is provided, the kernel width is
divided along each dimension by the spacing. For example, if <code class="docutils literal notranslate"><span class="pre">sigma=1</span></code>
and <code class="docutils literal notranslate"><span class="pre">spacing=[5,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>, the effective <em class="xref py py-obj">sigma</em> is <code class="docutils literal notranslate"><span class="pre">[0.2,</span> <span class="pre">1,</span> <span class="pre">1]</span></code>. This
ensures sensible smoothing for anisotropic images.</p></li>
<li><p>The image is rescaled to be in [0, 1] prior to processing (masked
values are ignored).</p></li>
<li><p>Images of shape (M, N, 3) are interpreted as 2D RGB images by default. To
interpret them as 3D with the last dimension having length 3, use
<em class="xref py py-obj">channel_axis=None</em>.</p></li>
<li><p><em class="xref py py-obj">start_label</em> is introduced to handle the issue <a class="reference internal" href="#rbeb231216055-4" id="id21">[4]</a>. Label indexing
starts at 1 by default.</p></li>
</ul>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rbeb231216055-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi,
Pascal Fua, and Sabine Süsstrunk, SLIC Superpixels Compared to
State-of-the-art Superpixel Methods, TPAMI, May 2012.
<a class="reference external" href="https://doi.org/10.1109/TPAMI.2012.120">DOI:10.1109/TPAMI.2012.120</a></p>
</div>
<div class="citation" id="rbeb231216055-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.epfl.ch/labs/ivrl/research/slic-superpixels/#SLICO">https://www.epfl.ch/labs/ivrl/research/slic-superpixels/#SLICO</a></p>
</div>
<div class="citation" id="rbeb231216055-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Irving, Benjamin. “maskSLIC: regional superpixel generation with
application to local pathology characterisation in medical images.”,
2016, <a class="reference external" href="https://arxiv.org/abs/1606.09518">arXiv:1606.09518</a></p>
</div>
<div class="citation" id="rbeb231216055-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id21">4</a><span class="fn-bracket">]</span></span>
<p><a class="github reference external" href="https://github.com/scikit-image/scikit-image/issues/3722">scikit-image/scikit-image#3722</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">slic</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">astronaut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">astronaut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">segments</span> <span class="o">=</span> <span class="n">slic</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">n_segments</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">compactness</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Increasing the compactness parameter yields more square regions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">segments</span> <span class="o">=</span> <span class="n">slic</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">n_segments</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">compactness</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Construct a region boundary RAG with the rag_boundary function. The function  :pyskimage.graph...."><img alt="" src="../_images/sphx_glr_plot_rag_boundary_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_boundary.html#sphx-glr-auto-examples-segmentation-plot-rag-boundary-py"><span class="std std-ref">Region Boundary based Region adjacency graphs (RAGs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region Boundary based Region adjacency graphs (RAGs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and merges regions which are similar in ..."><img alt="" src="../_images/sphx_glr_plot_rag_mean_color_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_mean_color.html#sphx-glr-auto-examples-segmentation-plot-rag-mean-color-py"><span class="std std-ref">Region adjacency graph (RAG) Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region adjacency graph (RAG) Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and recursively performs a Normalized Cu..."><img alt="" src="../_images/sphx_glr_plot_ncut_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_ncut.html#sphx-glr-auto-examples-segmentation-plot-ncut-py"><span class="std std-ref">Normalized Cut</span></a></p>
  <div class="sphx-glr-thumbnail-title">Normalized Cut</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and draws it with the rag_draw method."><img alt="" src="../_images/sphx_glr_plot_rag_draw_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_draw.html#sphx-glr-auto-examples-segmentation-plot-rag-draw-py"><span class="std std-ref">Drawing Region Adjacency Graphs (RAGs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Drawing Region Adjacency Graphs (RAGs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example is about comparing the segmentations obtained using the plain SLIC method [1]_ and..."><img alt="" src="../_images/sphx_glr_plot_mask_slic_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_mask_slic.html#sphx-glr-auto-examples-segmentation-plot-mask-slic-py"><span class="std std-ref">Apply maskSLIC vs SLIC</span></a></p>
  <div class="sphx-glr-thumbnail-title">Apply maskSLIC vs SLIC</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to..."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When segmenting an image, you may want to combine multiple alternative segmentations. The :pysk..."><img alt="" src="../_images/sphx_glr_plot_join_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_join_segmentations.html#sphx-glr-auto-examples-segmentation-plot-join-segmentations-py"><span class="std std-ref">Find the intersection of two segmentations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find the intersection of two segmentations</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and progressively merges regions that ar..."><img alt="" src="../_images/sphx_glr_plot_rag_merge_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_merge.html#sphx-glr-auto-examples-segmentation-plot-rag-merge-py"><span class="std std-ref">Region adjacency graph (RAG) Merging</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region adjacency graph (RAG) Merging</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to perform hierarchical merging on region boundary Region Adjacen..."><img alt="" src="../_images/sphx_glr_plot_boundary_merge_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_boundary_merge.html#sphx-glr-auto-examples-segmentation-plot-boundary-merge-py"><span class="std std-ref">Hierarchical Merging of Region Boundary RAGs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Hierarchical Merging of Region Boundary RAGs</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.segmentation.watershed">
<span class="sig-prename descclassname"><span class="pre">skimage.segmentation.</span></span><span class="sig-name descname"><span class="pre">watershed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">markers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">connectivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compactness</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">watershed_line</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.24.0/skimage/segmentation/_watershed.py#L86-L242"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.segmentation.watershed" title="Link to this definition">#</a></dt>
<dd><p>Find watershed basins in an image flooded from given markers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Data array where the lowest value points are labeled first.</p>
</dd>
<dt><strong>markers</strong><span class="classifier">int, or (M, N[, …]) ndarray of int, optional</span></dt><dd><p>The desired number of basins, or an array marking the basins with the
values to be assigned in the label matrix. Zero means not a marker. If
None, the (default) markers are determined as the local minima of
<em class="xref py py-obj">image</em>. Specifically, the computation is equivalent to applying
<a class="reference internal" href="skimage.morphology.html#skimage.morphology.local_minima" title="skimage.morphology.local_minima"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.morphology.local_minima()</span></code></a> onto <em class="xref py py-obj">image</em>, followed by
<a class="reference internal" href="skimage.measure.html#skimage.measure.label" title="skimage.measure.label"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.measure.label()</span></code></a> onto the result (with the same given
<em class="xref py py-obj">connectivity</em>). Generally speaking, users are encouraged to pass
markers explicitly.</p>
</dd>
<dt><strong>connectivity</strong><span class="classifier">int or ndarray, optional</span></dt><dd><p>The neighborhood connectivity. An integer is interpreted as in
<code class="docutils literal notranslate"><span class="pre">scipy.ndimage.generate_binary_structure</span></code>, as the maximum number
of orthogonal steps to reach a neighbor. An array is directly
interpreted as a footprint (structuring element). Default value is 1.
In 2D, 1 gives a 4-neighborhood while 2 gives an 8-neighborhood.</p>
</dd>
<dt><strong>offset</strong><span class="classifier">array_like of shape image.ndim, optional</span></dt><dd><p>The coordinates of the center of the footprint.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">(M, N[, …]) ndarray of bools or 0’s and 1’s, optional</span></dt><dd><p>Array of same shape as <em class="xref py py-obj">image</em>. Only points at which mask == True
will be labeled.</p>
</dd>
<dt><strong>compactness</strong><span class="classifier">float, optional</span></dt><dd><p>Use compact watershed <a class="reference internal" href="#rc8002e235889-1" id="id26">[1]</a> with given compactness parameter.
Higher values result in more regularly-shaped watershed basins.</p>
</dd>
<dt><strong>watershed_line</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, a one-pixel wide line separates the regions
obtained by the watershed algorithm. The line has the label 0.
Note that the method used for adding this line expects that
marker regions are not adjacent; the watershed line may not catch
borders between adjacent marker regions.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">ndarray</span></dt><dd><p>A labeled matrix of the same type and shape as <em class="xref py py-obj">markers</em>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.segmentation.random_walker" title="skimage.segmentation.random_walker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.segmentation.random_walker</span></code></a></dt><dd><p>A segmentation algorithm based on anisotropic diffusion, usually slower than the watershed but with good results on noisy data and boundaries with holes.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This function implements a watershed algorithm <a class="reference internal" href="#rc8002e235889-2" id="id27">[2]</a> <a class="reference internal" href="#rc8002e235889-3" id="id28">[3]</a> that apportions
pixels into marked basins. The algorithm uses a priority queue to hold
the pixels with the metric for the priority queue being pixel value, then
the time of entry into the queue – this settles ties in favor of the
closest marker.</p>
<p>Some ideas are taken from <a class="reference internal" href="#rc8002e235889-4" id="id29">[4]</a>.
The most important insight in the paper is that entry time onto the queue
solves two problems: a pixel should be assigned to the neighbor with the
largest gradient or, if there is no gradient, pixels on a plateau should
be split between markers on opposite sides.</p>
<p>This implementation converts all arguments to specific, lowest common
denominator types, then passes these to a C algorithm.</p>
<p>Markers can be determined manually, or automatically using for example
the local minima of the gradient of the image, or the local maxima of the
distance function to the background for separating overlapping objects
(see example).</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rc8002e235889-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id26">1</a><span class="fn-bracket">]</span></span>
<p>P. Neubert and P. Protzel, “Compact Watershed and Preemptive SLIC:
On Improving Trade-offs of Superpixel Segmentation Algorithms,”
2014 22nd International Conference on Pattern Recognition,
Stockholm, Sweden, 2014, pp. 996-1001, <a class="reference external" href="https://doi.org/10.1109/ICPR.2014.181">DOI:10.1109/ICPR.2014.181</a>
<a class="reference external" href="https://www.tu-chemnitz.de/etit/proaut/publications/cws_pSLIC_ICPR.pdf">https://www.tu-chemnitz.de/etit/proaut/publications/cws_pSLIC_ICPR.pdf</a></p>
</div>
<div class="citation" id="rc8002e235889-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id27">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Watershed_%28image_processing%29">https://en.wikipedia.org/wiki/Watershed_%28image_processing%29</a></p>
</div>
<div class="citation" id="rc8002e235889-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id28">3</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://cmm.ensmp.fr/~beucher/wtshed.html">http://cmm.ensmp.fr/~beucher/wtshed.html</a></p>
</div>
<div class="citation" id="rc8002e235889-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">4</a><span class="fn-bracket">]</span></span>
<p>P. J. Soille and M. M. Ansoult, “Automated basin delineation from
digital elevation models using mathematical morphology,” Signal
Processing, 20(2):171-182, <a class="reference external" href="https://doi.org/10.1016/0165-1684(90)90127-K">DOI:10.1016/0165-1684(90)90127-K</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>The watershed algorithm is useful to separate overlapping objects.</p>
<p>We first generate an initial image with two overlapping circles:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">indices</span><span class="p">((</span><span class="mi">80</span><span class="p">,</span> <span class="mi">80</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">52</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r1</span><span class="p">,</span> <span class="n">r2</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask_circle1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;</span> <span class="n">r1</span><span class="o">**</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask_circle2</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;</span> <span class="n">r2</span><span class="o">**</span><span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">mask_circle1</span><span class="p">,</span> <span class="n">mask_circle2</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, we want to separate the two circles. We generate markers at the
maxima of the distance to the background:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span> <span class="k">as</span> <span class="n">ndi</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">distance</span> <span class="o">=</span> <span class="n">ndi</span><span class="o">.</span><span class="n">distance_transform_edt</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="kn">import</span> <span class="n">peak_local_max</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_coords</span> <span class="o">=</span> <span class="n">peak_local_max</span><span class="p">(</span><span class="n">distance</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">footprint</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">local_maxima</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">local_maxima</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">max_coords</span><span class="o">.</span><span class="n">T</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">markers</span> <span class="o">=</span> <span class="n">ndi</span><span class="o">.</span><span class="n">label</span><span class="p">(</span><span class="n">local_maxima</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Finally, we run the watershed on the image and markers:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">watershed</span><span class="p">(</span><span class="o">-</span><span class="n">distance</span><span class="p">,</span> <span class="n">markers</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<p>The algorithm works also for 3D images, and can be used for example to
separate overlapping spheres.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The watershed transform is commonly used as a starting point for many segmentation algorithms. ..."><img alt="" src="../_images/sphx_glr_plot_compact_watershed_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_compact_watershed.html#sphx-glr-auto-examples-segmentation-plot-compact-watershed-py"><span class="std std-ref">Find Regular Segments Using Compact Watershed</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find Regular Segments Using Compact Watershed</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Given several connected components represented by a label image, these connected components can..."><img alt="" src="../_images/sphx_glr_plot_expand_labels_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_expand_labels.html#sphx-glr-auto-examples-segmentation-plot-expand-labels-py"><span class="std std-ref">Expand segmentation labels without overlap</span></a></p>
  <div class="sphx-glr-thumbnail-title">Expand segmentation labels without overlap</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The watershed is a classical algorithm used for segmentation, that is, for separating different..."><img alt="" src="../_images/sphx_glr_plot_watershed_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_watershed.html#sphx-glr-auto-examples-segmentation-plot-watershed-py"><span class="std std-ref">Watershed segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Watershed segmentation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The watershed is a classical algorithm used for segmentation, that is, for separating different..."><img alt="" src="../_images/sphx_glr_plot_marked_watershed_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_marked_watershed.html#sphx-glr-auto-examples-segmentation-plot-marked-watershed-py"><span class="std std-ref">Markers for watershed transform</span></a></p>
  <div class="sphx-glr-thumbnail-title">Markers for watershed transform</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to..."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When segmenting an image, you may want to combine multiple alternative segmentations. The :pysk..."><img alt="" src="../_images/sphx_glr_plot_join_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_join_segmentations.html#sphx-glr-auto-examples-segmentation-plot-join-segmentations-py"><span class="std std-ref">Find the intersection of two segmentations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find the intersection of two segmentations</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When trying out different segmentation methods, how do you know which one is best? If you have ..."><img alt="" src="../_images/sphx_glr_plot_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_metrics.html#sphx-glr-auto-examples-segmentation-plot-metrics-py"><span class="std std-ref">Evaluating segmentation metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluating segmentation metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to segment objects from a background. We use the coins image f..."><img alt="" src="../_images/sphx_glr_plot_coins_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_coins_segmentation.html#sphx-glr-auto-examples-applications-plot-coins-segmentation-py"><span class="std std-ref">Comparing edge-based and region-based segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing edge-based and region-based segmentation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we analyze a microscopy image of human cells. We use data provided by Jason Mo..."><img alt="" src="../_images/sphx_glr_plot_human_mitosis_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_human_mitosis.html#sphx-glr-auto-examples-applications-plot-human-mitosis-py"><span class="std std-ref">Segment human cells (in mitosis)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Segment human cells (in mitosis)</div>
</div></div></dd></dl>

</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.active_contour"><code class="docutils literal notranslate"><span class="pre">active_contour()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.chan_vese"><code class="docutils literal notranslate"><span class="pre">chan_vese()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.checkerboard_level_set"><code class="docutils literal notranslate"><span class="pre">checkerboard_level_set()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.clear_border"><code class="docutils literal notranslate"><span class="pre">clear_border()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.disk_level_set"><code class="docutils literal notranslate"><span class="pre">disk_level_set()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.expand_labels"><code class="docutils literal notranslate"><span class="pre">expand_labels()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.felzenszwalb"><code class="docutils literal notranslate"><span class="pre">felzenszwalb()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.find_boundaries"><code class="docutils literal notranslate"><span class="pre">find_boundaries()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.flood"><code class="docutils literal notranslate"><span class="pre">flood()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.flood_fill"><code class="docutils literal notranslate"><span class="pre">flood_fill()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.inverse_gaussian_gradient"><code class="docutils literal notranslate"><span class="pre">inverse_gaussian_gradient()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.join_segmentations"><code class="docutils literal notranslate"><span class="pre">join_segmentations()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.mark_boundaries"><code class="docutils literal notranslate"><span class="pre">mark_boundaries()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.morphological_chan_vese"><code class="docutils literal notranslate"><span class="pre">morphological_chan_vese()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.morphological_geodesic_active_contour"><code class="docutils literal notranslate"><span class="pre">morphological_geodesic_active_contour()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.quickshift"><code class="docutils literal notranslate"><span class="pre">quickshift()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.random_walker"><code class="docutils literal notranslate"><span class="pre">random_walker()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.relabel_sequential"><code class="docutils literal notranslate"><span class="pre">relabel_sequential()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.slic"><code class="docutils literal notranslate"><span class="pre">slic()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.segmentation.watershed"><code class="docutils literal notranslate"><span class="pre">watershed()</span></code></a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/api/skimage.segmentation.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2013-2024, the scikit-image team.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    <br/>
  </p>
</div>
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>