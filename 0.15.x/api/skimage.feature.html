


<!DOCTYPE html>
<html lang="en">
<head>
        <title>Module: feature &mdash; skimage v0.15.0 docs</title>
    
    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link href="../_static/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="../_static/css/custom.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
        <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    
    <script src="http://code.jquery.com/jquery-latest.js"></script>
    <script src="../_static/js/bootstrap.min.js"></script>
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.15.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
        <script type="text/javascript" src="../_static/copybutton.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <link rel="index" title="Index" href="../genindex.html" />
        <link rel="search" title="Search" href="../search.html" />
        <link rel="top" title="skimage v0.15.0 docs" href="../index.html" />
        <link rel="up" title="API Reference for skimage 0.15.0" href="api.html" />
        <link rel="next" title="Module: filters" href="skimage.filters.html" />
        <link rel="prev" title="Module: external.tifffile" href="skimage.external.tifffile.html" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
    <link rel="shortcut icon" href="../_static/favicon.ico">
</head>
<body class="container">
    <a href="https://scikit-image.org" class="logo"><img src="../_static/img/logo.png" alt=""></a>
    <div class="clearfix"></div>
    <div class="navbar">
        <div class="navbar-inner">
            <ul class="nav">
                <li><a href="/docs/stable/install.html">Download</a></li>
<li><a href="../auto_examples/index.html">Gallery</a></li>
<li><a href="../index.html">Documentation</a></li>
<li><a href="/community_guidelines.html">Community Guidelines</a></li>

<li><a href="https://github.com/scikit-image/scikit-image">
    <img src="../_static/GitHub-Mark-32px.png"
        style="height: 15px; width: 15px;
               display: inline; float: none;
               padding-bottom: 3px;">
    Source</a>
</li>
            </ul>
        </div>
    </div>
    <div class="row">
        <div class="span3"><div style="padding-bottom: 3em">
  <form class="navbar-form pull-right" action="../search.html" method="get">
    <input type="text" class="search span3" name="q" placeholder="Search documentation ...">
    <input type="hidden" name="check_keywords" value="yes" >
    <input type="hidden" name="area" value="default" >
  </form>
</div><!-- 
        <h4 class="sidebar-box-heading">Contents</h4>
        <div class="well sidebar-box toc">
            <ul class="nav nav-list">
<li><a class="reference internal" href="#">Module: <code class="docutils literal notranslate"><span class="pre">feature</span></code></a><ul class="nav nav-list">
<li><a class="reference internal" href="#canny">canny</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-canny">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#daisy">daisy</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-daisy">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.daisy</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#hog">hog</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-hog">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.hog</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#greycomatrix">greycomatrix</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-greycomatrix">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycomatrix</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#greycoprops">greycoprops</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-greycoprops">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycoprops</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#local-binary-pattern">local_binary_pattern</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-local-binary-pattern">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.local_binary_pattern</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiblock-lbp">multiblock_lbp</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-multiblock-lbp">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.multiblock_lbp</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#draw-multiblock-lbp">draw_multiblock_lbp</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-draw-multiblock-lbp">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_multiblock_lbp</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#peak-local-max">peak_local_max</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-peak-local-max">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#structure-tensor">structure_tensor</a></li>
<li><a class="reference internal" href="#structure-tensor-eigvals">structure_tensor_eigvals</a></li>
<li><a class="reference internal" href="#hessian-matrix">hessian_matrix</a></li>
<li><a class="reference internal" href="#hessian-matrix-det">hessian_matrix_det</a></li>
<li><a class="reference internal" href="#hessian-matrix-eigvals">hessian_matrix_eigvals</a></li>
<li><a class="reference internal" href="#shape-index">shape_index</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-shape-index">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.shape_index</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-kitchen-rosenfeld">corner_kitchen_rosenfeld</a></li>
<li><a class="reference internal" href="#corner-harris">corner_harris</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-corner-harris">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_harris</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-shi-tomasi">corner_shi_tomasi</a></li>
<li><a class="reference internal" href="#corner-foerstner">corner_foerstner</a></li>
<li><a class="reference internal" href="#corner-subpix">corner_subpix</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-corner-subpix">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_subpix</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-peaks">corner_peaks</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-corner-peaks">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_peaks</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-moravec">corner_moravec</a></li>
<li><a class="reference internal" href="#corner-fast">corner_fast</a></li>
<li><a class="reference internal" href="#corner-orientations">corner_orientations</a></li>
<li><a class="reference internal" href="#match-template">match_template</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-match-template">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_template</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#register-translation">register_translation</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-register-translation">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.register_translation</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#masked-register-translation">masked_register_translation</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-masked-register-translation">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.masked_register_translation</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#match-descriptors">match_descriptors</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-match-descriptors">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_descriptors</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#plot-matches">plot_matches</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-plot-matches">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.plot_matches</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#blob-dog">blob_dog</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-blob-dog">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#blob-doh">blob_doh</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-blob-doh">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_doh</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#blob-log">blob_log</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-blob-log">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_log</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#haar-like-feature">haar_like_feature</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-haar-like-feature">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#haar-like-feature-coord">haar_like_feature_coord</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-haar-like-feature-coord">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature_coord</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#draw-haar-like-feature">draw_haar_like_feature</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-draw-haar-like-feature">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_haar_like_feature</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#cascade"><code class="docutils literal notranslate"><span class="pre">Cascade</span></code></a></li>
<li><a class="reference internal" href="#brief"><code class="docutils literal notranslate"><span class="pre">BRIEF</span></code></a></li>
<li><a class="reference internal" href="#censure"><code class="docutils literal notranslate"><span class="pre">CENSURE</span></code></a></li>
<li><a class="reference internal" href="#orb"><code class="docutils literal notranslate"><span class="pre">ORB</span></code></a></li>
</ul>
</li>
</ul>

        </div>


 --><div class="well">
    <strong>Docs for 0.15.0<br></strong>

    <a id="other">All versions</a>

    <ul id="versionList" style="display: none;">
        <script src="../../dev/_static/docversions.js"></script>
        <script type="text/javascript">
            insert_version_links();
        </script>
    </ul>

 </div>

<script type="text/javascript">
	$("#other").click(function() {
		$("#versionList").toggle();
	});
</script>
        </div>
        <div class="span9">
            
  <div class="section" id="module-skimage.feature">
<span id="module-feature"></span><h1>Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">feature</span></code><a class="headerlink" href="#module-skimage.feature" title="Permalink to this headline">¶</a></h1>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a>(image[,&nbsp;sigma,&nbsp;…])</td>
<td>Edge filter an image using the Canny algorithm.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.daisy" title="skimage.feature.daisy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.daisy</span></code></a>(image[,&nbsp;step,&nbsp;radius,&nbsp;…])</td>
<td>Extract DAISY feature descriptors densely for the given image.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.hog" title="skimage.feature.hog"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hog</span></code></a>(image[,&nbsp;orientations,&nbsp;…])</td>
<td>Extract Histogram of Oriented Gradients (HOG) for a given image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.greycomatrix" title="skimage.feature.greycomatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.greycomatrix</span></code></a>(image,&nbsp;…[,&nbsp;…])</td>
<td>Calculate the grey-level co-occurrence matrix.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.greycoprops" title="skimage.feature.greycoprops"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.greycoprops</span></code></a>(P[,&nbsp;prop])</td>
<td>Calculate texture properties of a GLCM.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.local_binary_pattern" title="skimage.feature.local_binary_pattern"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.local_binary_pattern</span></code></a>(image,&nbsp;P,&nbsp;R)</td>
<td>Gray scale and rotation invariant LBP (Local Binary Patterns).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.multiblock_lbp" title="skimage.feature.multiblock_lbp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.multiblock_lbp</span></code></a>(int_image,&nbsp;r,&nbsp;…)</td>
<td>Multi-block local binary pattern (MB-LBP).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.draw_multiblock_lbp" title="skimage.feature.draw_multiblock_lbp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.draw_multiblock_lbp</span></code></a>(image,&nbsp;…)</td>
<td>Multi-block local binary pattern visualization.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max</span></code></a>(image[,&nbsp;…])</td>
<td>Find peaks in an image as coordinate list or boolean mask.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.structure_tensor" title="skimage.feature.structure_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.structure_tensor</span></code></a>(image[,&nbsp;…])</td>
<td>Compute structure tensor using sum of squared differences.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.structure_tensor_eigvals" title="skimage.feature.structure_tensor_eigvals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.structure_tensor_eigvals</span></code></a>(…)</td>
<td>Compute Eigen values of structure tensor.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.hessian_matrix" title="skimage.feature.hessian_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hessian_matrix</span></code></a>(image[,&nbsp;…])</td>
<td>Compute Hessian matrix.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.hessian_matrix_det" title="skimage.feature.hessian_matrix_det"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hessian_matrix_det</span></code></a>(image[,&nbsp;…])</td>
<td>Compute the approximate Hessian Determinant over an image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.hessian_matrix_eigvals" title="skimage.feature.hessian_matrix_eigvals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hessian_matrix_eigvals</span></code></a>(H_elems)</td>
<td>Compute Eigenvalues of Hessian matrix.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.shape_index" title="skimage.feature.shape_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.shape_index</span></code></a>(image[,&nbsp;sigma,&nbsp;…])</td>
<td>Compute the shape index.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.corner_kitchen_rosenfeld" title="skimage.feature.corner_kitchen_rosenfeld"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_kitchen_rosenfeld</span></code></a>(image)</td>
<td>Compute Kitchen and Rosenfeld corner measure response image.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.corner_harris" title="skimage.feature.corner_harris"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_harris</span></code></a>(image[,&nbsp;…])</td>
<td>Compute Harris corner measure response image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.corner_shi_tomasi" title="skimage.feature.corner_shi_tomasi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_shi_tomasi</span></code></a>(image[,&nbsp;sigma])</td>
<td>Compute Shi-Tomasi (Kanade-Tomasi) corner measure response image.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.corner_foerstner" title="skimage.feature.corner_foerstner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_foerstner</span></code></a>(image[,&nbsp;sigma])</td>
<td>Compute Foerstner corner measure response image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.corner_subpix" title="skimage.feature.corner_subpix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_subpix</span></code></a>(image,&nbsp;corners)</td>
<td>Determine subpixel position of corners.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.corner_peaks" title="skimage.feature.corner_peaks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_peaks</span></code></a>(image[,&nbsp;…])</td>
<td>Find corners in corner measure response image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.corner_moravec" title="skimage.feature.corner_moravec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_moravec</span></code></a>(image[,&nbsp;…])</td>
<td>Compute Moravec corner measure response image.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.corner_fast" title="skimage.feature.corner_fast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_fast</span></code></a>(image[,&nbsp;n,&nbsp;…])</td>
<td>Extract FAST corners for a given image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.corner_orientations" title="skimage.feature.corner_orientations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_orientations</span></code></a>(image,&nbsp;…)</td>
<td>Compute the orientation of corners.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.match_template" title="skimage.feature.match_template"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.match_template</span></code></a>(image,&nbsp;template)</td>
<td>Match a template to a 2-D or 3-D image using normalized correlation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.register_translation" title="skimage.feature.register_translation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.register_translation</span></code></a>(…[,&nbsp;…])</td>
<td>Efficient subpixel image translation registration by cross-correlation.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.masked_register_translation" title="skimage.feature.masked_register_translation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.masked_register_translation</span></code></a>(…)</td>
<td>Masked image translation registration by masked normalized cross-correlation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.match_descriptors" title="skimage.feature.match_descriptors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.match_descriptors</span></code></a>(…[,&nbsp;…])</td>
<td>Brute-force matching of descriptors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.plot_matches" title="skimage.feature.plot_matches"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.plot_matches</span></code></a>(ax,&nbsp;image1,&nbsp;…)</td>
<td>Plot matched features.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code></a>(image[,&nbsp;min_sigma,&nbsp;…])</td>
<td>Finds blobs in the given grayscale image.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.blob_doh" title="skimage.feature.blob_doh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_doh</span></code></a>(image[,&nbsp;min_sigma,&nbsp;…])</td>
<td>Finds blobs in the given grayscale image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.blob_log" title="skimage.feature.blob_log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_log</span></code></a>(image[,&nbsp;min_sigma,&nbsp;…])</td>
<td>Finds blobs in the given grayscale image.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.haar_like_feature" title="skimage.feature.haar_like_feature"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature</span></code></a>(int_image,&nbsp;…)</td>
<td>Compute the Haar-like features for a region of interest (ROI) of an integral image.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature_coord</span></code></a>(…)</td>
<td>Compute the coordinates of Haar-like features.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.draw_haar_like_feature" title="skimage.feature.draw_haar_like_feature"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.draw_haar_like_feature</span></code></a>(…)</td>
<td>Visualization of Haar-like features.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.Cascade" title="skimage.feature.Cascade"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.Cascade</span></code></a></td>
<td>Class for cascade of classifiers that is used for object detection.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.BRIEF" title="skimage.feature.BRIEF"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.BRIEF</span></code></a>([descriptor_size,&nbsp;…])</td>
<td>BRIEF binary descriptor extractor.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#skimage.feature.CENSURE" title="skimage.feature.CENSURE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.CENSURE</span></code></a>([min_scale,&nbsp;…])</td>
<td>CENSURE keypoint detector.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#skimage.feature.ORB" title="skimage.feature.ORB"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.ORB</span></code></a>([downscale,&nbsp;n_scales,&nbsp;…])</td>
<td>Oriented FAST and rotated BRIEF feature detector and binary descriptor extractor.</td>
</tr>
</tbody>
</table>
<div class="section" id="canny">
<h2>canny<a class="headerlink" href="#canny" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.canny">
<code class="descclassname">skimage.feature.</code><code class="descname">canny</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1.0</em>, <em>low_threshold=None</em>, <em>high_threshold=None</em>, <em>mask=None</em>, <em>use_quantiles=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/_canny.py#L53"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.canny" title="Permalink to this definition">¶</a></dt>
<dd><p>Edge filter an image using the Canny algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Grayscale input image to detect edges on; can be of any dtype.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Standard deviation of the Gaussian filter.</p>
</dd>
<dt><strong>low_threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Lower bound for hysteresis thresholding (linking edges).
If None, low_threshold is set to 10% of dtype’s max.</p>
</dd>
<dt><strong>high_threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Upper bound for hysteresis thresholding (linking edges).
If None, high_threshold is set to 20% of dtype’s max.</p>
</dd>
<dt><strong>mask</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, dtype=bool, optional</span></dt>
<dd><p class="first last">Mask to limit the application of Canny to a certain area.</p>
</dd>
<dt><strong>use_quantiles</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True then treat low_threshold and high_threshold as quantiles of the
edge magnitude image, rather than absolute edge magnitude values. If True
then the thresholds must be in the range [0, 1].</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array (image)</span></dt>
<dd><p class="first last">The binary edge map.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.sobel</span></code></p>
</div>
<p class="rubric">Notes</p>
<p>The steps of the algorithm are as follows:</p>
<ul class="simple">
<li>Smooth the image using a Gaussian with <code class="docutils literal notranslate"><span class="pre">sigma</span></code> width.</li>
<li>Apply the horizontal and vertical Sobel operators to get the gradients
within the image. The edge strength is the norm of the gradient.</li>
<li>Thin potential edges to 1-pixel wide curves. First, find the normal
to the edge at each point. This is done by looking at the
signs and the relative magnitude of the X-Sobel and Y-Sobel
to sort the points into 4 categories: horizontal, vertical,
diagonal and antidiagonal. Then look in the normal and reverse
directions to see if the values in either of those directions are
greater than the point in question. Use interpolation to get a mix of
points instead of picking the one that’s the closest to the normal.</li>
<li>Perform a hysteresis thresholding: first label all points above the
high threshold as edges. Then recursively label any point above the
low threshold that is 8-connected to a labeled point as an edge.</li>
</ul>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r5f5bcbc11495-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Canny, J., A Computational Approach To Edge Detection, IEEE Trans.
Pattern Analysis and Machine Intelligence, 8:679-714, 1986</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r5f5bcbc11495-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>William Green’s Canny tutorial
<a class="reference external" href="http://dasl.unlv.edu/daslDrexel/alumni/bGreen/www.pages.drexel.edu/_weg22/can_tut.html">http://dasl.unlv.edu/daslDrexel/alumni/bGreen/www.pages.drexel.edu/_weg22/can_tut.html</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate noisy image of a square</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">im</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="o">-</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">:</span><span class="o">-</span><span class="mi">64</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">+=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># First trial with the Canny filter, with the default smoothing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges1</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">canny</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Increase the smoothing for better results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges2</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">canny</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-canny">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code><a class="headerlink" href="#examples-using-skimage-feature-canny" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The Canny filter is a multi-stage edge detector. It uses a filter based on the derivative of a ..."><div class="figure" id="id63">
<img alt="../_images/sphx_glr_plot_canny_thumb.png" src="../_images/sphx_glr_plot_canny_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/edges/plot_canny.html#sphx-glr-auto-examples-edges-plot-canny-py"><span class="std std-ref">Canny edge detector</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a method to detect straight lines [1]_."><div class="figure" id="id64">
<img alt="../_images/sphx_glr_plot_line_hough_transform_thumb.png" src="../_images/sphx_glr_plot_line_hough_transform_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/edges/plot_line_hough_transform.html#sphx-glr-auto-examples-edges-plot-line-hough-transform-py"><span class="std std-ref">Straight line Hough transform</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a `method to detect straight lines &lt;https://en.wiki..."><div class="figure" id="id65">
<img alt="../_images/sphx_glr_plot_circular_elliptical_hough_transform_thumb.png" src="../_images/sphx_glr_plot_circular_elliptical_hough_transform_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/edges/plot_circular_elliptical_hough_transform.html#sphx-glr-auto-examples-edges-plot-circular-elliptical-hough-transform-py"><span class="std std-ref">Circular and Elliptical Hough Transforms</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to segment objects from a background. We use the ``coins`` ima..."><div class="figure" id="id66">
<img alt="../_images/sphx_glr_plot_coins_segmentation_thumb.png" src="../_images/sphx_glr_plot_coins_segmentation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/applications/plot_coins_segmentation.html#sphx-glr-auto-examples-applications-plot-coins-segmentation-py"><span class="std std-ref">Comparing edge-based and region-based segmentation</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="daisy">
<h2>daisy<a class="headerlink" href="#daisy" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.daisy">
<code class="descclassname">skimage.feature.</code><code class="descname">daisy</code><span class="sig-paren">(</span><em>image</em>, <em>step=4</em>, <em>radius=15</em>, <em>rings=3</em>, <em>histograms=8</em>, <em>orientations=8</em>, <em>normalization='l1'</em>, <em>sigmas=None</em>, <em>ring_radii=None</em>, <em>visualize=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/_daisy.py#L9"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.daisy" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract DAISY feature descriptors densely for the given image.</p>
<p>DAISY is a feature descriptor similar to SIFT formulated in a way that
allows for fast dense extraction. Typically, this is practical for
bag-of-features image representations.</p>
<p>The implementation follows Tola et al. <a class="reference internal" href="#r3f18658b3c6d-1" id="id3">[1]</a> but deviate on the following
points:</p>
<blockquote>
<div><ul class="simple">
<li>Histogram bin contribution are smoothed with a circular Gaussian
window over the tonal range (the angular range).</li>
<li>The sigma values of the spatial Gaussian smoothing in this code do not
match the sigma values in the original code by Tola et al. <a class="reference internal" href="#r3f18658b3c6d-2" id="id4">[2]</a>. In
their code, spatial smoothing is applied to both the input image and
the center histogram. However, this smoothing is not documented in <a class="reference internal" href="#r3f18658b3c6d-1" id="id5">[1]</a>
and, therefore, it is omitted.</li>
</ul>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N) array</span></dt>
<dd><p class="first last">Input image (grayscale).</p>
</dd>
<dt><strong>step</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Distance between descriptor sampling points.</p>
</dd>
<dt><strong>radius</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Radius (in pixels) of the outermost ring.</p>
</dd>
<dt><strong>rings</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of rings.</p>
</dd>
<dt><strong>histograms</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of histograms sampled per ring.</p>
</dd>
<dt><strong>orientations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of orientations (bins) per histogram.</p>
</dd>
<dt><strong>normalization</strong> <span class="classifier-delimiter">:</span> <span class="classifier">[ ‘l1’ | ‘l2’ | ‘daisy’ | ‘off’ ], optional</span></dt>
<dd><p class="first">How to normalize the descriptors</p>
<blockquote class="last">
<div><ul class="simple">
<li>‘l1’: L1-normalization of each descriptor.</li>
<li>‘l2’: L2-normalization of each descriptor.</li>
<li>‘daisy’: L2-normalization of individual histograms.</li>
<li>‘off’: Disable normalization.</li>
</ul>
</div></blockquote>
</dd>
<dt><strong>sigmas</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D array of float, optional</span></dt>
<dd><p class="first">Standard deviation of spatial Gaussian smoothing for the center
histogram and for each ring of histograms. The array of sigmas should
be sorted from the center and out. I.e. the first sigma value defines
the spatial smoothing of the center histogram and the last sigma value
defines the spatial smoothing of the outermost ring. Specifying sigmas
overrides the following parameter.</p>
<blockquote class="last">
<div><p><code class="docutils literal notranslate"><span class="pre">rings</span> <span class="pre">=</span> <span class="pre">len(sigmas)</span> <span class="pre">-</span> <span class="pre">1</span></code></p>
</div></blockquote>
</dd>
<dt><strong>ring_radii</strong> <span class="classifier-delimiter">:</span> <span class="classifier">1D array of int, optional</span></dt>
<dd><p class="first">Radius (in pixels) for each ring. Specifying ring_radii overrides the
following two parameters.</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">rings</span> <span class="pre">=</span> <span class="pre">len(ring_radii)</span></code>
<code class="docutils literal notranslate"><span class="pre">radius</span> <span class="pre">=</span> <span class="pre">ring_radii[-1]</span></code></p>
</div></blockquote>
<p>If both sigmas and ring_radii are given, they must satisfy the
following predicate since no radius is needed for the center
histogram.</p>
<blockquote class="last">
<div><p><code class="docutils literal notranslate"><span class="pre">len(ring_radii)</span> <span class="pre">==</span> <span class="pre">len(sigmas)</span> <span class="pre">+</span> <span class="pre">1</span></code></p>
</div></blockquote>
</dd>
<dt><strong>visualize</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Generate a visualization of the DAISY descriptors</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>descs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first">Grid of DAISY descriptors for the given image as an array
dimensionality  (P, Q, R) where</p>
<blockquote class="last">
<div><p><code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">=</span> <span class="pre">ceil((M</span> <span class="pre">-</span> <span class="pre">radius*2)</span> <span class="pre">/</span> <span class="pre">step)</span></code>
<code class="docutils literal notranslate"><span class="pre">Q</span> <span class="pre">=</span> <span class="pre">ceil((N</span> <span class="pre">-</span> <span class="pre">radius*2)</span> <span class="pre">/</span> <span class="pre">step)</span></code>
<code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">=</span> <span class="pre">(rings</span> <span class="pre">*</span> <span class="pre">histograms</span> <span class="pre">+</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">orientations</span></code></p>
</div></blockquote>
</dd>
<dt><strong>descs_img</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N, 3) array (only if visualize==True)</span></dt>
<dd><p class="first last">Visualization of the DAISY descriptors.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r3f18658b3c6d-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id3">1</a>, <a class="fn-backref" href="#id5">2</a>, <a class="fn-backref" href="#id6">3</a>)</em> Tola et al. “Daisy: An efficient dense descriptor applied to wide-
baseline stereo.” Pattern Analysis and Machine Intelligence, IEEE
Transactions on 32.5 (2010): 815-830.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r3f18658b3c6d-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id7">2</a>)</em> <a class="reference external" href="http://cvlab.epfl.ch/software/daisy">http://cvlab.epfl.ch/software/daisy</a></td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-daisy">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.daisy</span></code><a class="headerlink" href="#examples-using-skimage-feature-daisy" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The DAISY local image descriptor is based on gradient orientation histograms similar to the SIF..."><div class="figure" id="id67">
<img alt="../_images/sphx_glr_plot_daisy_thumb.png" src="../_images/sphx_glr_plot_daisy_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_daisy.html#sphx-glr-auto-examples-features-detection-plot-daisy-py"><span class="std std-ref">Dense DAISY feature description</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="hog">
<h2>hog<a class="headerlink" href="#hog" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hog">
<code class="descclassname">skimage.feature.</code><code class="descname">hog</code><span class="sig-paren">(</span><em>image</em>, <em>orientations=9</em>, <em>pixels_per_cell=(8</em>, <em>8)</em>, <em>cells_per_block=(3</em>, <em>3)</em>, <em>block_norm='L2-Hys'</em>, <em>visualize=False</em>, <em>visualise=None</em>, <em>transform_sqrt=False</em>, <em>feature_vector=True</em>, <em>multichannel=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/_hog.py#L47"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hog" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract Histogram of Oriented Gradients (HOG) for a given image.</p>
<p>Compute a Histogram of Oriented Gradients (HOG) by</p>
<blockquote>
<div><ol class="arabic simple">
<li>(optional) global image normalization</li>
<li>computing the gradient image in <cite>row</cite> and <cite>col</cite></li>
<li>computing gradient histograms</li>
<li>normalizing across blocks</li>
<li>flattening into a feature vector</li>
</ol>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N[, C]) ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>orientations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of orientation bins.</p>
</dd>
<dt><strong>pixels_per_cell</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2-tuple (int, int), optional</span></dt>
<dd><p class="first last">Size (in pixels) of a cell.</p>
</dd>
<dt><strong>cells_per_block</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2-tuple (int, int), optional</span></dt>
<dd><p class="first last">Number of cells in each block.</p>
</dd>
<dt><strong>block_norm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str {‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’}, optional</span></dt>
<dd><p class="first">Block normalization method:</p>
<dl class="last docutils">
<dt><code class="docutils literal notranslate"><span class="pre">L1</span></code></dt>
<dd><p class="first last">Normalization using L1-norm.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L1-sqrt</span></code></dt>
<dd><p class="first last">Normalization using L1-norm, followed by square root.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L2</span></code></dt>
<dd><p class="first last">Normalization using L2-norm.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L2-Hys</span></code></dt>
<dd><p class="first last">Normalization using L2-norm, followed by limiting the
maximum values to 0.2 (<cite>Hys</cite> stands for <cite>hysteresis</cite>) and
renormalization using L2-norm. (default)
For details, see <a class="reference internal" href="#ra159ccd8c91f-3" id="id8">[3]</a>, <a class="reference internal" href="#ra159ccd8c91f-4" id="id9">[4]</a>.</p>
</dd>
</dl>
</dd>
<dt><strong>visualize</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Also return an image of the HOG.  For each cell and orientation bin,
the image contains a line segment that is centered at the cell center,
is perpendicular to the midpoint of the range of angles spanned by the
orientation bin, and has intensity proportional to the corresponding
histogram value.</p>
</dd>
<dt><strong>transform_sqrt</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Apply power law compression to normalize the image before
processing. DO NOT use this if the image contains negative
values. Also see <cite>notes</cite> section below.</p>
</dd>
<dt><strong>feature_vector</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Return the data as a feature vector by calling .ravel() on the result
just before returning.</p>
</dd>
<dt><strong>multichannel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean, optional</span></dt>
<dd><p class="first last">If True, the last <cite>image</cite> dimension is considered as a color channel,
otherwise as spatial.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n_blocks_row, n_blocks_col, n_cells_row, n_cells_col, n_orient) ndarray</span></dt>
<dd><p class="first last">HOG descriptor for the image. If <cite>feature_vector</cite> is True, a 1D
(flattened) array is returned.</p>
</dd>
<dt><strong>hog_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N) ndarray, optional</span></dt>
<dd><p class="first last">A visualisation of the HOG image. Only provided if <cite>visualize</cite> is True.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The presented code implements the HOG extraction method from <a class="reference internal" href="#ra159ccd8c91f-2" id="id10">[2]</a> with
the following changes: (I) blocks of (3, 3) cells are used ((2, 2) in the
paper; (II) no smoothing within cells (Gaussian spatial window with sigma=8pix
in the paper); (III) L1 block normalization is used (L2-Hys in the paper).</p>
<p>Power law compression, also known as Gamma correction, is used to reduce
the effects of shadowing and illumination variations. The compression makes
the dark regions lighter. When the kwarg <cite>transform_sqrt</cite> is set to
<code class="docutils literal notranslate"><span class="pre">True</span></code>, the function computes the square root of each color channel
and then applies the hog algorithm to the image.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="ra159ccd8c91f-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id11">[1]</a></td><td><a class="reference external" href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ra159ccd8c91f-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id10">1</a>, <a class="fn-backref" href="#id12">2</a>)</em> Dalal, N and Triggs, B, Histograms of Oriented Gradients for
Human Detection, IEEE Computer Society Conference on Computer
Vision and Pattern Recognition 2005 San Diego, CA, USA,
<a class="reference external" href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf">https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf</a>,
<a class="reference external" href="https://doi.org/10.1109/CVPR.2005.177">DOI:10.1109/CVPR.2005.177</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ra159ccd8c91f-3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td><em>(<a class="fn-backref" href="#id8">1</a>, <a class="fn-backref" href="#id13">2</a>)</em> Lowe, D.G., Distinctive image features from scale-invatiant
keypoints, International Journal of Computer Vision (2004) 60: 91,
<a class="reference external" href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf</a>,
<a class="reference external" href="https://doi.org/10.1023/B:VISI.0000029664.99615.94">DOI:10.1023/B:VISI.0000029664.99615.94</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ra159ccd8c91f-4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[4]</td><td><em>(<a class="fn-backref" href="#id9">1</a>, <a class="fn-backref" href="#id14">2</a>)</em> Dalal, N, Finding People in Images and Videos,
Human-Computer Interaction [cs.HC], Institut National Polytechnique
de Grenoble - INPG, 2006,
<a class="reference external" href="https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf">https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf</a></td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-hog">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.hog</span></code><a class="headerlink" href="#examples-using-skimage-feature-hog" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The Histogram of Oriented Gradient (HOG) feature descriptor is popular for object detection [1]..."><div class="figure" id="id68">
<img alt="../_images/sphx_glr_plot_hog_thumb.png" src="../_images/sphx_glr_plot_hog_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py"><span class="std std-ref">Histogram of Oriented Gradients</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="greycomatrix">
<h2>greycomatrix<a class="headerlink" href="#greycomatrix" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.greycomatrix">
<code class="descclassname">skimage.feature.</code><code class="descname">greycomatrix</code><span class="sig-paren">(</span><em>image</em>, <em>distances</em>, <em>angles</em>, <em>levels=None</em>, <em>symmetric=False</em>, <em>normed=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/texture.py#L15"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.greycomatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the grey-level co-occurrence matrix.</p>
<p>A grey level co-occurrence matrix is a histogram of co-occurring
greyscale values at a given offset over an image.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">Integer typed input image. Only positive valued images are supported.
If type is other than uint8, the argument <cite>levels</cite> needs to be set.</p>
</dd>
<dt><strong>distances</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">List of pixel pair distance offsets.</p>
</dd>
<dt><strong>angles</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array_like</span></dt>
<dd><p class="first last">List of pixel pair angles in radians.</p>
</dd>
<dt><strong>levels</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">The input image should contain integers in [0, <cite>levels</cite>-1],
where levels indicate the number of grey-levels counted
(typically 256 for an 8-bit image). This argument is required for
16-bit images or higher and is typically the maximum of the image.
As the output matrix is at least <cite>levels</cite> x <cite>levels</cite>, it might
be preferable to use binning of the input image rather than
large values for <cite>levels</cite>.</p>
</dd>
<dt><strong>symmetric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, the output matrix <cite>P[:, :, d, theta]</cite> is symmetric. This
is accomplished by ignoring the order of value pairs, so both
(i, j) and (j, i) are accumulated when (i, j) is encountered
for a given offset. The default is False.</p>
</dd>
<dt><strong>normed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, normalize each matrix <cite>P[:, :, d, theta]</cite> by dividing
by the total number of accumulated co-occurrences for the given
offset. The elements of the resulting matrix sum to 1. The
default is False.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>P</strong> <span class="classifier-delimiter">:</span> <span class="classifier">4-D ndarray</span></dt>
<dd><p class="first last">The grey-level co-occurrence histogram. The value
<cite>P[i,j,d,theta]</cite> is the number of times that grey-level <cite>j</cite>
occurs at a distance <cite>d</cite> and at an angle <cite>theta</cite> from
grey-level <cite>i</cite>. If <cite>normed</cite> is <cite>False</cite>, the output is of
type uint32, otherwise it is float64. The dimensions are:
levels x levels x number of distances x number of angles.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r4810813e96aa-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id15">[1]</a></td><td>The GLCM Tutorial Home Page,
<a class="reference external" href="http://www.fp.ucalgary.ca/mhallbey/tutorial.htm">http://www.fp.ucalgary.ca/mhallbey/tutorial.htm</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4810813e96aa-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id16">[2]</a></td><td>Pattern Recognition Engineering, Morton Nadler &amp; Eric P.
Smith</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4810813e96aa-3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id17">[3]</a></td><td>Wikipedia, <a class="reference external" href="https://en.wikipedia.org/wiki/Co-occurrence_matrix">https://en.wikipedia.org/wiki/Co-occurrence_matrix</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Compute 2 GLCMs: One for a 1-pixel offset to the right, and one
for a 1-pixel offset upwards.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">greycomatrix</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="n">levels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="go">array([[2, 2, 1, 0],</span>
<span class="go">       [0, 2, 0, 0],</span>
<span class="go">       [0, 0, 3, 1],</span>
<span class="go">       [0, 0, 0, 1]], dtype=uint32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="go">array([[1, 1, 3, 0],</span>
<span class="go">       [0, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 2],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="go">array([[3, 0, 2, 0],</span>
<span class="go">       [0, 2, 2, 0],</span>
<span class="go">       [0, 0, 1, 2],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="go">array([[2, 0, 0, 0],</span>
<span class="go">       [1, 1, 2, 0],</span>
<span class="go">       [0, 0, 2, 1],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint32)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-greycomatrix">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycomatrix</span></code><a class="headerlink" href="#examples-using-skimage-feature-greycomatrix" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using grey level co-occurrence matrices (GLCMs)..."><div class="figure" id="id69">
<img alt="../_images/sphx_glr_plot_glcm_thumb.png" src="../_images/sphx_glr_plot_glcm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="greycoprops">
<h2>greycoprops<a class="headerlink" href="#greycoprops" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.greycoprops">
<code class="descclassname">skimage.feature.</code><code class="descname">greycoprops</code><span class="sig-paren">(</span><em>P</em>, <em>prop='contrast'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/texture.py#L154"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.greycoprops" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate texture properties of a GLCM.</p>
<p>Compute a feature of a grey level co-occurrence matrix to serve as
a compact summary of the matrix. The properties are computed as
follows:</p>
<ul>
<li><p class="first">‘contrast’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1} P_{i,j}(i-j)^2\)</span></p>
</li>
<li><p class="first">‘dissimilarity’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1}P_{i,j}|i-j|\)</span></p>
</li>
<li><p class="first">‘homogeneity’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1}\frac{P_{i,j}}{1+(i-j)^2}\)</span></p>
</li>
<li><p class="first">‘ASM’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1} P_{i,j}^2\)</span></p>
</li>
<li><p class="first">‘energy’: <span class="math notranslate nohighlight">\(\sqrt{ASM}\)</span></p>
</li>
<li><dl class="first docutils">
<dt>‘correlation’:</dt>
<dd><div class="first last math notranslate nohighlight">
\[\sum_{i,j=0}^{levels-1} P_{i,j}\left[\frac{(i-\mu_i) \
(j-\mu_j)}{\sqrt{(\sigma_i^2)(\sigma_j^2)}}\right]\]</div>
</dd>
</dl>
</li>
</ul>
<p>Each GLCM is normalized to have a sum of 1 before the computation of texture
properties.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>P</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input array. <cite>P</cite> is the grey-level co-occurrence histogram
for which to compute the specified property. The value
<cite>P[i,j,d,theta]</cite> is the number of times that grey-level j
occurs at a distance d and at an angle theta from
grey-level i.</p>
</dd>
<dt><strong>prop</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘contrast’, ‘dissimilarity’, ‘homogeneity’, ‘energy’,             ‘correlation’, ‘ASM’}, optional</span></dt>
<dd><p class="first last">The property of the GLCM to compute. The default is ‘contrast’.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>results</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2-D ndarray</span></dt>
<dd><p class="first last">2-dimensional array. <cite>results[d, a]</cite> is the property ‘prop’ for
the d’th distance and the a’th angle.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="ra999ee4f1c5d-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id18">[1]</a></td><td>The GLCM Tutorial Home Page,
<a class="reference external" href="http://www.fp.ucalgary.ca/mhallbey/tutorial.htm">http://www.fp.ucalgary.ca/mhallbey/tutorial.htm</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Compute the contrast for GLCMs with distances [1, 2] and angles
[0 degrees, 90 degrees]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">greycomatrix</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">],</span> <span class="n">levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">symmetric</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrast</span> <span class="o">=</span> <span class="n">greycoprops</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="s1">&#39;contrast&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrast</span>
<span class="go">array([[ 0.58333333,  1.        ],</span>
<span class="go">       [ 1.25      ,  2.75      ]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-greycoprops">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycoprops</span></code><a class="headerlink" href="#examples-using-skimage-feature-greycoprops" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using grey level co-occurrence matrices (GLCMs)..."><div class="figure" id="id70">
<img alt="../_images/sphx_glr_plot_glcm_thumb.png" src="../_images/sphx_glr_plot_glcm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="local-binary-pattern">
<h2>local_binary_pattern<a class="headerlink" href="#local-binary-pattern" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.local_binary_pattern">
<code class="descclassname">skimage.feature.</code><code class="descname">local_binary_pattern</code><span class="sig-paren">(</span><em>image</em>, <em>P</em>, <em>R</em>, <em>method='default'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/texture.py#L274"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.local_binary_pattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Gray scale and rotation invariant LBP (Local Binary Patterns).</p>
<p>LBP is an invariant descriptor that can be used for texture classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, M) array</span></dt>
<dd><p class="first last">Graylevel image.</p>
</dd>
<dt><strong>P</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number of circularly symmetric neighbour set points (quantization of
the angular space).</p>
</dd>
<dt><strong>R</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Radius of circle (spatial resolution of the operator).</p>
</dd>
<dt><strong>method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘default’, ‘ror’, ‘uniform’, ‘var’}</span></dt>
<dd><p class="first">Method to determine the pattern.</p>
<ul class="last simple">
<li><dl class="first docutils">
<dt>‘default’: original local binary pattern which is gray scale but not</dt>
<dd>rotation invariant.</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘ror’: extension of default implementation which is gray scale and</dt>
<dd>rotation invariant.</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘uniform’: improved rotation invariance with uniform patterns and</dt>
<dd>finer quantization of the angular space which is gray scale and
rotation invariant.</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘nri_uniform’: non rotation-invariant uniform patterns variant</dt>
<dd>which is only gray scale invariant <a class="reference internal" href="#r648eb9e75080-2" id="id19">[2]</a>.</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>‘var’: rotation invariant variance measures of the contrast of local</dt>
<dd>image texture which is rotation but not gray scale invariant.</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, M) array</span></dt>
<dd><p class="first last">LBP image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r648eb9e75080-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id20">[1]</a></td><td>Multiresolution Gray-Scale and Rotation Invariant Texture
Classification with Local Binary Patterns.
Timo Ojala, Matti Pietikainen, Topi Maenpaa.
<a class="reference external" href="http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf">http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf</a>, 2002.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r648eb9e75080-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id19">1</a>, <a class="fn-backref" href="#id21">2</a>)</em> Face recognition with local binary patterns.
Timo Ahonen, Abdenour Hadid, Matti Pietikainen,
<a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.214.6851">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.214.6851</a>,
2004.</td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-local-binary-pattern">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.local_binary_pattern</span></code><a class="headerlink" href="#examples-using-skimage-feature-local-binary-pattern" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on LBP (Local Binary Pattern). LBP ..."><div class="figure" id="id71">
<img alt="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" src="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-local-binary-pattern-py"><span class="std std-ref">Local Binary Pattern for texture classification</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="multiblock-lbp">
<h2>multiblock_lbp<a class="headerlink" href="#multiblock-lbp" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.multiblock_lbp">
<code class="descclassname">skimage.feature.</code><code class="descname">multiblock_lbp</code><span class="sig-paren">(</span><em>int_image</em>, <em>r</em>, <em>c</em>, <em>width</em>, <em>height</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/texture.py#L333"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.multiblock_lbp" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-block local binary pattern (MB-LBP).</p>
<p>The features are calculated similarly to local binary patterns (LBPs),
(See <a class="reference internal" href="#skimage.feature.local_binary_pattern" title="skimage.feature.local_binary_pattern"><code class="xref py py-meth docutils literal notranslate"><span class="pre">local_binary_pattern()</span></code></a>) except that summed blocks are
used instead of individual pixel values.</p>
<p>MB-LBP is an extension of LBP that can be computed on multiple scales
in constant time using the integral image. Nine equally-sized rectangles
are used to compute a feature. For each rectangle, the sum of the pixel
intensities is computed. Comparisons of these sums to that of the central
rectangle determine the feature, similarly to LBP.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>int_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, M) array</span></dt>
<dd><p class="first last">Integral image.</p>
</dd>
<dt><strong>r</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Row-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>c</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Column-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>width</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Width of one of the 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
<dt><strong>height</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Height of one of the 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">8-bit MB-LBP feature descriptor.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="ra36744213751-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id22">[1]</a></td><td>Face Detection Based on Multi-Block LBP
Representation. Lun Zhang, Rufeng Chu, Shiming Xiang, Shengcai Liao,
Stan Z. Li
<a class="reference external" href="http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf">http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf</a></td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-multiblock-lbp">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.multiblock_lbp</span></code><a class="headerlink" href="#examples-using-skimage-feature-multiblock-lbp" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example shows how to compute multi-block local binary pattern (MB-LBP) features as well as..."><div class="figure" id="id72">
<img alt="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" src="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_multiblock_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-multiblock-local-binary-pattern-py"><span class="std std-ref">Multi-Block Local Binary Pattern for texture classification</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="draw-multiblock-lbp">
<h2>draw_multiblock_lbp<a class="headerlink" href="#draw-multiblock-lbp" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.draw_multiblock_lbp">
<code class="descclassname">skimage.feature.</code><code class="descname">draw_multiblock_lbp</code><span class="sig-paren">(</span><em>image</em>, <em>r</em>, <em>c</em>, <em>width</em>, <em>height</em>, <em>lbp_code=0</em>, <em>color_greater_block=(1</em>, <em>1</em>, <em>1)</em>, <em>color_less_block=(0</em>, <em>0.69</em>, <em>0.96)</em>, <em>alpha=0.5</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/texture.py#L379"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.draw_multiblock_lbp" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-block local binary pattern visualization.</p>
<p>Blocks with higher sums are colored with alpha-blended white rectangles,
whereas blocks with lower sums are colored alpha-blended cyan. Colors
and the <cite>alpha</cite> parameter can be changed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of float or uint</span></dt>
<dd><p class="first last">Image on which to visualize the pattern.</p>
</dd>
<dt><strong>r</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Row-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>c</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Column-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>width</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Width of one of 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
<dt><strong>height</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Height of one of 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
<dt><strong>lbp_code</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The descriptor of feature to visualize. If not provided, the
descriptor with 0 value will be used.</p>
</dd>
<dt><strong>color_greater_block</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple of 3 floats</span></dt>
<dd><p class="first last">Floats specifying the color for the block that has greater
intensity value. They should be in the range [0, 1].
Corresponding values define (R, G, B) values. Default value
is white (1, 1, 1).</p>
</dd>
<dt><strong>color_greater_block</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple of 3 floats</span></dt>
<dd><p class="first last">Floats specifying the color for the block that has greater intensity
value. They should be in the range [0, 1]. Corresponding values define
(R, G, B) values. Default value is cyan (0, 0.69, 0.96).</p>
</dd>
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Value in the range [0, 1] that specifies opacity of visualization.
1 - fully transparent, 0 - opaque.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of float</span></dt>
<dd><p class="first last">Image with MB-LBP visualization.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="re2978af1b6c8-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id23">[1]</a></td><td>Face Detection Based on Multi-Block LBP
Representation. Lun Zhang, Rufeng Chu, Shiming Xiang, Shengcai Liao,
Stan Z. Li
<a class="reference external" href="http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf">http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf</a></td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-draw-multiblock-lbp">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_multiblock_lbp</span></code><a class="headerlink" href="#examples-using-skimage-feature-draw-multiblock-lbp" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example shows how to compute multi-block local binary pattern (MB-LBP) features as well as..."><div class="figure" id="id73">
<img alt="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" src="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_multiblock_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-multiblock-local-binary-pattern-py"><span class="std std-ref">Multi-Block Local Binary Pattern for texture classification</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="peak-local-max">
<h2>peak_local_max<a class="headerlink" href="#peak-local-max" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.peak_local_max">
<code class="descclassname">skimage.feature.</code><code class="descname">peak_local_max</code><span class="sig-paren">(</span><em>image</em>, <em>min_distance=1</em>, <em>threshold_abs=None</em>, <em>threshold_rel=None</em>, <em>exclude_border=True</em>, <em>indices=True</em>, <em>num_peaks=inf</em>, <em>footprint=None</em>, <em>labels=None</em>, <em>num_peaks_per_label=inf</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/peak.py#L25"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.peak_local_max" title="Permalink to this definition">¶</a></dt>
<dd><p>Find peaks in an image as coordinate list or boolean mask.</p>
<p>Peaks are the local maxima in a region of <cite>2 * min_distance + 1</cite>
(i.e. peaks are separated by at least <cite>min_distance</cite>).</p>
<p>If there are multiple local maxima with identical pixel intensities
inside the region defined with <cite>min_distance</cite>,
the coordinates of all such pixels are returned.</p>
<p>If both <cite>threshold_abs</cite> and <cite>threshold_rel</cite> are provided, the maximum
of the two is chosen as the minimum intensity threshold of peaks.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>min_distance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Minimum number of pixels separating peaks in a region of <cite>2 *
min_distance + 1</cite> (i.e. peaks are separated by at least
<cite>min_distance</cite>).
To find the maximum number of peaks, use <cite>min_distance=1</cite>.</p>
</dd>
<dt><strong>threshold_abs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Minimum intensity of peaks. By default, the absolute threshold is
the minimum intensity of the image.</p>
</dd>
<dt><strong>threshold_rel</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Minimum intensity of peaks, calculated as <cite>max(image) * threshold_rel</cite>.</p>
</dd>
<dt><strong>exclude_border</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int or bool, optional</span></dt>
<dd><p class="first last">If nonzero int, <cite>exclude_border</cite> excludes peaks from
within <cite>exclude_border</cite>-pixels of the border of the image.
If True, takes the <cite>min_distance</cite> parameter as value.
If zero or False, peaks are identified regardless of their
distance from the border.</p>
</dd>
<dt><strong>indices</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, the output will be an array representing peak
coordinates.  If False, the output will be a boolean array shaped as
<cite>image.shape</cite> with peaks present at True elements.</p>
</dd>
<dt><strong>num_peaks</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of peaks. When the number of peaks exceeds <cite>num_peaks</cite>,
return <cite>num_peaks</cite> peaks based on highest peak intensity.</p>
</dd>
<dt><strong>footprint</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of bools, optional</span></dt>
<dd><p class="first last">If provided, <cite>footprint == 1</cite> represents the local region within which
to search for peaks at every point in <cite>image</cite>.  Overrides
<cite>min_distance</cite> (also for <cite>exclude_border</cite>).</p>
</dd>
<dt><strong>labels</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of ints, optional</span></dt>
<dd><p class="first last">If provided, each unique region <cite>labels == value</cite> represents a unique
region to search for peaks. Zero is reserved for background.</p>
</dd>
<dt><strong>num_peaks_per_label</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of peaks for each label.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or ndarray of bools</span></dt>
<dd><ul class="first last simple">
<li>If <cite>indices = True</cite>  : (row, column, …) coordinates of peaks.</li>
<li>If <cite>indices = False</cite> : Boolean array shaped like <cite>image</cite>, with peaks
represented by True values.</li>
</ul>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The peak local maximum function returns the coordinates of local peaks
(maxima) in an image. A maximum filter is used for finding local maxima.
This operation dilates the original image. After comparison of the dilated
and original image, this function returns the coordinates or a mask of the
peaks where the dilated image equals the original image.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span>
<span class="go">array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  1.5,  0. ,  1. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[3, 4],</span>
<span class="go">       [3, 2]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[3, 2]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span> <span class="n">exclude_border</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">array([[10, 10, 10]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-peak-local-max">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max</span></code><a class="headerlink" href="#examples-using-skimage-feature-peak-local-max" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The ``peak_local_max`` function returns the coordinates of local peaks (maxima) in an image. A ..."><div class="figure" id="id74">
<img alt="../_images/sphx_glr_plot_peak_local_max_thumb.png" src="../_images/sphx_glr_plot_peak_local_max_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/segmentation/plot_peak_local_max.html#sphx-glr-auto-examples-segmentation-plot-peak-local-max-py"><span class="std std-ref">Finding local maxima</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The watershed is a classical algorithm used for **segmentation**, that is, for separating diffe..."><div class="figure" id="id75">
<img alt="../_images/sphx_glr_plot_watershed_thumb.png" src="../_images/sphx_glr_plot_watershed_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/segmentation/plot_watershed.html#sphx-glr-auto-examples-segmentation-plot-watershed-py"><span class="std std-ref">Watershed segmentation</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="structure-tensor">
<h2>structure_tensor<a class="headerlink" href="#structure-tensor" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.structure_tensor">
<code class="descclassname">skimage.feature.</code><code class="descname">structure_tensor</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1</em>, <em>mode='constant'</em>, <em>cval=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L46"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.structure_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute structure tensor using sum of squared differences.</p>
<p>The structure tensor A is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>which is approximated by the weighted sum of squared differences in a local
window around each pixel in the image.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, which is used as a
weighting function for the local summation of squared differences.</p>
</dd>
<dt><strong>mode</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt>
<dd><p class="first last">How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>Axx</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Axy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Ayy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the structure tensor for each pixel in the input image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">structure_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Axx</span><span class="p">,</span> <span class="n">Axy</span><span class="p">,</span> <span class="n">Ayy</span> <span class="o">=</span> <span class="n">structure_tensor</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Axx</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  4.,  0.,  4.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="structure-tensor-eigvals">
<h2>structure_tensor_eigvals<a class="headerlink" href="#structure-tensor-eigvals" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.structure_tensor_eigvals">
<code class="descclassname">skimage.feature.</code><code class="descname">structure_tensor_eigvals</code><span class="sig-paren">(</span><em>Axx</em>, <em>Axy</em>, <em>Ayy</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L262"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.structure_tensor_eigvals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Eigen values of structure tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>Axx</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Axy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Ayy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the structure tensor for each pixel in the input image.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>l1</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Larger eigen value for each input matrix.</p>
</dd>
<dt><strong>l2</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Smaller eigen value for each input matrix.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">structure_tensor</span><span class="p">,</span> <span class="n">structure_tensor_eigvals</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Axx</span><span class="p">,</span> <span class="n">Axy</span><span class="p">,</span> <span class="n">Ayy</span> <span class="o">=</span> <span class="n">structure_tensor</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">structure_tensor_eigvals</span><span class="p">(</span><span class="n">Axx</span><span class="p">,</span> <span class="n">Axy</span><span class="p">,</span> <span class="n">Ayy</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  2.,  4.,  2.,  0.],</span>
<span class="go">       [ 0.,  4.,  0.,  4.,  0.],</span>
<span class="go">       [ 0.,  2.,  4.,  2.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="hessian-matrix">
<h2>hessian_matrix<a class="headerlink" href="#hessian-matrix" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hessian_matrix">
<code class="descclassname">skimage.feature.</code><code class="descname">hessian_matrix</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1</em>, <em>mode='constant'</em>, <em>cval=0</em>, <em>order=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L106"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hessian_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Hessian matrix.</p>
<p>The Hessian matrix is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H</span> <span class="o">=</span> <span class="p">[</span><span class="n">Hrr</span> <span class="n">Hrc</span><span class="p">]</span>
    <span class="p">[</span><span class="n">Hrc</span> <span class="n">Hcc</span><span class="p">]</span>
</pre></div>
</div>
<p>which is computed by convolving the image with the second derivatives
of the Gaussian kernel in the respective x- and y-directions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
<dt><strong>mode</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt>
<dd><p class="first last">How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
<dt><strong>order</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘xy’, ‘rc’}, optional</span></dt>
<dd><p class="first last">This parameter allows for the use of reverse or forward order of
the image axes in gradient computation. ‘xy’ indicates the usage
of the last axis initially (Hxx, Hxy, Hyy), whilst ‘rc’ indicates
the use of the first axis initially (Hrr, Hrc, Hcc).</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>Hrr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hrc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hcc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">hessian_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Hrr</span><span class="p">,</span> <span class="n">Hrc</span><span class="p">,</span> <span class="n">Hcc</span> <span class="o">=</span> <span class="n">hessian_matrix</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">order</span> <span class="o">=</span> <span class="s1">&#39;rc&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Hrc</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0., -1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0., -1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="hessian-matrix-det">
<h2>hessian_matrix_det<a class="headerlink" href="#hessian-matrix-det" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hessian_matrix_det">
<code class="descclassname">skimage.feature.</code><code class="descname">hessian_matrix_det</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1</em>, <em>approximate=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L211"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hessian_matrix_det" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the approximate Hessian Determinant over an image.</p>
<p>The 2D approximate method uses box filters over integral images to
compute the approximate Hessian Determinant, as described in <a class="reference internal" href="#r48e33a732c34-1" id="id24">[1]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The image over which to compute Hessian Determinant.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, used for the Hessian
matrix.</p>
</dd>
<dt><strong>approximate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If <code class="docutils literal notranslate"><span class="pre">True</span></code> and the image is 2D, use a much faster approximate
computation. This argument has no effect on 3D and higher images.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The array of the Determinant of Hessians.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>For 2D images when <code class="docutils literal notranslate"><span class="pre">approximate=True</span></code>, the running time of this method
only depends on size of the image. It is independent of <cite>sigma</cite> as one
would expect. The downside is that the result for <cite>sigma</cite> less than <cite>3</cite>
is not accurate, i.e., not similar to the result obtained if someone
computed the Hessian and took its determinant.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r48e33a732c34-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id24">1</a>, <a class="fn-backref" href="#id25">2</a>)</em> Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool,
“SURF: Speeded Up Robust Features”
<a class="reference external" href="ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf">ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf</a></td></tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="hessian-matrix-eigvals">
<h2>hessian_matrix_eigvals<a class="headerlink" href="#hessian-matrix-eigvals" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hessian_matrix_eigvals">
<code class="descclassname">skimage.feature.</code><code class="descname">hessian_matrix_eigvals</code><span class="sig-paren">(</span><em>H_elems</em>, <em>Hxy=None</em>, <em>Hyy=None</em>, <em>Hxx=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L299"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hessian_matrix_eigvals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Eigenvalues of Hessian matrix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>H_elems</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of ndarray</span></dt>
<dd><p class="first last">The upper-diagonal elements of the Hessian matrix, as returned
by <cite>hessian_matrix</cite>.</p>
</dd>
<dt><strong>Hxy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray, deprecated</span></dt>
<dd><p class="first last">Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hyy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray, deprecated</span></dt>
<dd><p class="first last">Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hxx</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray, deprecated</span></dt>
<dd><p class="first last">Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>eigs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">The eigenvalues of the Hessian matrix, in decreasing order. The
eigenvalues are the leading dimension. That is, <code class="docutils literal notranslate"><span class="pre">eigs[i,</span> <span class="pre">j,</span> <span class="pre">k]</span></code>
contains the ith-largest eigenvalue at position (j, k).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">hessian_matrix</span><span class="p">,</span> <span class="n">hessian_matrix_eigvals</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H_elems</span> <span class="o">=</span> <span class="n">hessian_matrix</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;rc&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hessian_matrix_eigvals</span><span class="p">(</span><span class="n">H_elems</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([[ 0.,  0.,  2.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 2.,  0., -2.,  0.,  2.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  2.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="shape-index">
<h2>shape_index<a class="headerlink" href="#shape-index" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.shape_index">
<code class="descclassname">skimage.feature.</code><code class="descname">shape_index</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1</em>, <em>mode='constant'</em>, <em>cval=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L352"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.shape_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the shape index.</p>
<p>The shape index, as defined by Koenderink &amp; van Doorn <a class="reference internal" href="#rc8faae48965f-1" id="id26">[1]</a>, is a
single valued measure of local curvature, assuming the image as a 3D plane
with intensities representing heights.</p>
<p>It is derived from the eigen values of the Hessian, and its
value ranges from -1 to 1 (and is undefined (=NaN) in <em>flat</em> regions),
with following ranges representing following shapes:</p>
<table border="1" class="docutils" id="id76">
<caption><span class="caption-text">Ranges of the shape index and corresponding shapes.</span><a class="headerlink" href="#id76" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="59%" />
<col width="41%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Interval (s in …)</th>
<th class="head">Shape</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>[  -1, -7/8)</td>
<td>Spherical cup</td>
</tr>
<tr class="row-odd"><td>[-7/8, -5/8)</td>
<td>Through</td>
</tr>
<tr class="row-even"><td>[-5/8, -3/8)</td>
<td>Rut</td>
</tr>
<tr class="row-odd"><td>[-3/8, -1/8)</td>
<td>Saddle rut</td>
</tr>
<tr class="row-even"><td>[-1/8, +1/8)</td>
<td>Saddle</td>
</tr>
<tr class="row-odd"><td>[+1/8, +3/8)</td>
<td>Saddle ridge</td>
</tr>
<tr class="row-even"><td>[+3/8, +5/8)</td>
<td>Ridge</td>
</tr>
<tr class="row-odd"><td>[+5/8, +7/8)</td>
<td>Dome</td>
</tr>
<tr class="row-even"><td>[+7/8,   +1]</td>
<td>Spherical cap</td>
</tr>
</tbody>
</table>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, which is used for
smoothing the input data before Hessian eigen value calculation.</p>
</dd>
<dt><strong>mode</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt>
<dd><p class="first last">How to handle values outside the image borders</p>
</dd>
<dt><strong>cval</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>s</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Shape index</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rc8faae48965f-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id26">1</a>, <a class="fn-backref" href="#id27">2</a>)</em> Koenderink, J. J. &amp; van Doorn, A. J.,
“Surface shape and curvature scales”,
Image and Vision Computing, 1992, 10, 557-564.
<a class="reference external" href="https://doi.org/10.1016/0262-8856(92)90076-F">DOI:10.1016/0262-8856(92)90076-F</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">shape_index</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">shape_index</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span>
<span class="go">array([[ nan,  nan, -0.5,  nan,  nan],</span>
<span class="go">       [ nan, -0. ,  nan, -0. ,  nan],</span>
<span class="go">       [-0.5,  nan, -1. ,  nan, -0.5],</span>
<span class="go">       [ nan, -0. ,  nan, -0. ,  nan],</span>
<span class="go">       [ nan,  nan, -0.5,  nan,  nan]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-shape-index">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.shape_index</span></code><a class="headerlink" href="#examples-using-skimage-feature-shape-index" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The shape index is a single valued measure of local curvature, derived from the eigen values of..."><div class="figure" id="id77">
<img alt="../_images/sphx_glr_plot_shape_index_thumb.png" src="../_images/sphx_glr_plot_shape_index_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_shape_index.html#sphx-glr-auto-examples-features-detection-plot-shape-index-py"><span class="std std-ref">Shape Index</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="corner-kitchen-rosenfeld">
<h2>corner_kitchen_rosenfeld<a class="headerlink" href="#corner-kitchen-rosenfeld" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_kitchen_rosenfeld">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_kitchen_rosenfeld</code><span class="sig-paren">(</span><em>image</em>, <em>mode='constant'</em>, <em>cval=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L424"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_kitchen_rosenfeld" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Kitchen and Rosenfeld corner measure response image.</p>
<p>The corner measure is calculated as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">imxx</span> <span class="o">*</span> <span class="n">imy</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">imyy</span> <span class="o">*</span> <span class="n">imx</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">imxy</span> <span class="o">*</span> <span class="n">imx</span> <span class="o">*</span> <span class="n">imy</span><span class="p">)</span>
    <span class="o">/</span> <span class="p">(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Where imx and imy are the first and imxx, imxy, imyy the second
derivatives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>mode</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt>
<dd><p class="first last">How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>response</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Kitchen and Rosenfeld response image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="corner-harris">
<h2>corner_harris<a class="headerlink" href="#corner-harris" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_harris">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_harris</code><span class="sig-paren">(</span><em>image</em>, <em>method='k'</em>, <em>k=0.05</em>, <em>eps=1e-06</em>, <em>sigma=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L467"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_harris" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Harris corner measure response image.</p>
<p>This corner detector uses information from the auto-correlation matrix A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="p">(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)</span>   <span class="p">(</span><span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>   <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>Where imx and imy are first derivatives, averaged with a gaussian filter.
The corner measure is then defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">-</span> <span class="n">k</span> <span class="o">*</span> <span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
<p>or:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2</span> <span class="o">*</span> <span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘k’, ‘eps’}, optional</span></dt>
<dd><p class="first last">Method to compute the response image from the auto-correlation matrix.</p>
</dd>
<dt><strong>k</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Sensitivity factor to separate corners from edges, typically in range
<cite>[0, 0.2]</cite>. Small values of k result in detection of sharp corners.</p>
</dd>
<dt><strong>eps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Normalisation factor (Noble’s corner measure).</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>response</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Harris response image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rc19c7843bb6d-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id28">[1]</a></td><td><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_harris</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">square</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 7],</span>
<span class="go">       [7, 2],</span>
<span class="go">       [7, 7]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-corner-harris">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_harris</span></code><a class="headerlink" href="#examples-using-skimage-feature-corner-harris" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure" id="id78">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of co..."><div class="figure" id="id79">
<img alt="../_images/sphx_glr_plot_corner_thumb.png" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure" id="id80">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="corner-shi-tomasi">
<h2>corner_shi_tomasi<a class="headerlink" href="#corner-shi-tomasi" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_shi_tomasi">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_shi_tomasi</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L547"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_shi_tomasi" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Shi-Tomasi (Kanade-Tomasi) corner measure response image.</p>
<p>This corner detector uses information from the auto-correlation matrix A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="p">(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)</span>   <span class="p">(</span><span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>   <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>Where imx and imy are first derivatives, averaged with a gaussian filter.
The corner measure is then defined as the smaller eigenvalue of A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">((</span><span class="n">Axx</span> <span class="o">+</span> <span class="n">Ayy</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">((</span><span class="n">Axx</span> <span class="o">-</span> <span class="n">Ayy</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">Axy</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>response</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Shi-Tomasi response image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r26d4c89afc0d-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id29">[1]</a></td><td><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_shi_tomasi</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_shi_tomasi</span><span class="p">(</span><span class="n">square</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 7],</span>
<span class="go">       [7, 2],</span>
<span class="go">       [7, 7]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-foerstner">
<h2>corner_foerstner<a class="headerlink" href="#corner-foerstner" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_foerstner">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_foerstner</code><span class="sig-paren">(</span><em>image</em>, <em>sigma=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L609"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_foerstner" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Foerstner corner measure response image.</p>
<p>This corner detector uses information from the auto-correlation matrix A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="p">(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)</span>   <span class="p">(</span><span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>   <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>Where imx and imy are first derivatives, averaged with a gaussian filter.
The corner measure is then defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>           <span class="p">(</span><span class="n">size</span> <span class="n">of</span> <span class="n">error</span> <span class="n">ellipse</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>    <span class="p">(</span><span class="n">roundness</span> <span class="n">of</span> <span class="n">error</span> <span class="n">ellipse</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>w</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Error ellipse sizes.</p>
</dd>
<dt><strong>q</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Roundness of error ellipse.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r9d429c80f73f-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id30">[1]</a></td><td><a class="reference external" href="http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/foerstner87.fast.pdf">http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/foerstner87.fast.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r9d429c80f73f-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id31">[2]</a></td><td><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_foerstner</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">corner_foerstner</span><span class="p">(</span><span class="n">square</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_thresh</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roundness_thresh</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">foerstner</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">&gt;</span> <span class="n">roundness_thresh</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">w</span> <span class="o">&gt;</span> <span class="n">accuracy_thresh</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">foerstner</span><span class="p">,</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 7],</span>
<span class="go">       [7, 2],</span>
<span class="go">       [7, 7]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-subpix">
<h2>corner_subpix<a class="headerlink" href="#corner-subpix" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_subpix">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_subpix</code><span class="sig-paren">(</span><em>image</em>, <em>corners</em>, <em>window_size=11</em>, <em>alpha=0.99</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L752"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_subpix" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine subpixel position of corners.</p>
<p>A statistical test decides whether the corner is defined as the
intersection of two edges or a single peak. Depending on the classification
result, the subpixel corner location is determined based on the local
covariance of the grey-values. If the significance level for either
statistical test is not sufficient, the corner cannot be classified, and
the output subpixel position is set to NaN.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>corners</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) ndarray</span></dt>
<dd><p class="first last">Corner coordinates <cite>(row, col)</cite>.</p>
</dd>
<dt><strong>window_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Search window size for subpixel estimation.</p>
</dd>
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Significance level for corner classification.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>positions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) ndarray</span></dt>
<dd><p class="first last">Subpixel corner positions. NaN for “not classified” corners.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="ra33874b5943a-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id32">[1]</a></td><td><a class="reference external" href="http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/">http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/</a>           foerstner87.fast.pdf</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ra33874b5943a-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id33">[2]</a></td><td><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_harris</span><span class="p">,</span> <span class="n">corner_peaks</span><span class="p">,</span> <span class="n">corner_subpix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="p">[</span><span class="mi">5</span><span class="p">:,</span> <span class="mi">5</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coords</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coords_subpix</span> <span class="o">=</span> <span class="n">corner_subpix</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coords_subpix</span>
<span class="go">array([[ 4.5,  4.5]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-corner-subpix">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_subpix</span></code><a class="headerlink" href="#examples-using-skimage-feature-corner-subpix" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure" id="id81">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of co..."><div class="figure" id="id82">
<img alt="../_images/sphx_glr_plot_corner_thumb.png" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="corner-peaks">
<h2>corner_peaks<a class="headerlink" href="#corner-peaks" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_peaks">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_peaks</code><span class="sig-paren">(</span><em>image</em>, <em>min_distance=1</em>, <em>threshold_abs=None</em>, <em>threshold_rel=0.1</em>, <em>exclude_border=True</em>, <em>indices=True</em>, <em>num_peaks=inf</em>, <em>footprint=None</em>, <em>labels=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L927"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_peaks" title="Permalink to this definition">¶</a></dt>
<dd><p>Find corners in corner measure response image.</p>
<p>This differs from <cite>skimage.feature.peak_local_max</cite> in that it suppresses
multiple connected peaks with the same accumulator value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>*</strong> <span class="classifier-delimiter">:</span> <span class="classifier">*</span></dt>
<dd><p class="first last">See <a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code class="xref py py-meth docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max()</span></code></a>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">peak_local_max</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  1.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  1.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="go">array([[3, 3],</span>
<span class="go">       [3, 2],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [2, 2]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="go">array([[2, 2]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-corner-peaks">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_peaks</span></code><a class="headerlink" href="#examples-using-skimage-feature-corner-peaks" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure" id="id83">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of co..."><div class="figure" id="id84">
<img alt="../_images/sphx_glr_plot_corner_thumb.png" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure" id="id85">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="corner-moravec">
<h2>corner_moravec<a class="headerlink" href="#corner-moravec" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_moravec">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_moravec</code><span class="sig-paren">(</span><em>image</em>, <em>window_size=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L981"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_moravec" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Moravec corner measure response image.</p>
<p>This is one of the simplest corner detectors and is comparatively fast but
has several limitations (e.g. not rotation invariant).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>window_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Window size.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>response</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Moravec response image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rdf16f0a1a068-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id34">[1]</a></td><td><a class="reference external" href="https://en.wikipedia.org/wiki/Corner_detection">https://en.wikipedia.org/wiki/Corner_detection</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_moravec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_moravec</span><span class="p">(</span><span class="n">square</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 2, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-fast">
<h2>corner_fast<a class="headerlink" href="#corner-fast" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_fast">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_fast</code><span class="sig-paren">(</span><em>image</em>, <em>n=12</em>, <em>threshold=0.15</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L689"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_fast" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract FAST corners for a given image.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>n</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Minimum number of consecutive pixels out of 16 pixels on the circle
that should all be either brighter or darker w.r.t testpixel.
A point c on the circle is darker w.r.t test pixel p if
<cite>Ic &lt; Ip - threshold</cite> and brighter if <cite>Ic &gt; Ip + threshold</cite>. Also
stands for the n in <cite>FAST-n</cite> corner detector.</p>
</dd>
<dt><strong>threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Threshold used in deciding whether the pixels on the circle are
brighter, darker or similar w.r.t. the test pixel. Decrease the
threshold when more corners are desired and vice-versa.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>response</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">FAST corner response image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r92fff83e7342-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id35">[1]</a></td><td>Edward Rosten and Tom Drummond
“Machine Learning for high-speed corner detection”,
<a class="reference external" href="http://www.edwardrosten.com/work/rosten_2006_machine.pdf">http://www.edwardrosten.com/work/rosten_2006_machine.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r92fff83e7342-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id36">[2]</a></td><td>Wikipedia, “Features from accelerated segment test”,
<a class="reference external" href="https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test">https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_fast</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_fast</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[3, 3],</span>
<span class="go">       [3, 8],</span>
<span class="go">       [8, 3],</span>
<span class="go">       [8, 8]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-orientations">
<h2>corner_orientations<a class="headerlink" href="#corner-orientations" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_orientations">
<code class="descclassname">skimage.feature.</code><code class="descname">corner_orientations</code><span class="sig-paren">(</span><em>image</em>, <em>corners</em>, <em>mask</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/corner.py#L1028"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_orientations" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the orientation of corners.</p>
<p>The orientation of corners is computed using the first order central moment
i.e. the center of mass approach. The corner orientation is the angle of
the vector from the corner coordinate to the intensity centroid in the
local neighborhood around the corner calculated using first order central
moment.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Input grayscale image.</p>
</dd>
<dt><strong>corners</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) array</span></dt>
<dd><p class="first last">Corner coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>mask</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Mask defining the local neighborhood of the corner used for the
calculation of the central moment.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>orientations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 1) array</span></dt>
<dd><p class="first last">Orientations of corners in the range [-pi, pi].</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r0592d7afdba5-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id37">[1]</a></td><td>Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski
“ORB : An efficient alternative to SIFT and SURF”
<a class="reference external" href="http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf">http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r0592d7afdba5-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id38">[2]</a></td><td>Paul L. Rosin, “Measuring Corner Properties”
<a class="reference external" href="http://users.cs.cf.ac.uk/Paul.Rosin/corner2.pdf">http://users.cs.cf.ac.uk/Paul.Rosin/corner2.pdf</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.morphology</span> <span class="k">import</span> <span class="n">octagon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="p">(</span><span class="n">corner_fast</span><span class="p">,</span> <span class="n">corner_peaks</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">corner_orientations</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corners</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_fast</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corners</span>
<span class="go">array([[3, 3],</span>
<span class="go">       [3, 8],</span>
<span class="go">       [8, 3],</span>
<span class="go">       [8, 8]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">orientations</span> <span class="o">=</span> <span class="n">corner_orientations</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">corners</span><span class="p">,</span> <span class="n">octagon</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">rad2deg</span><span class="p">(</span><span class="n">orientations</span><span class="p">)</span>
<span class="go">array([  45.,  135.,  -45., -135.])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="match-template">
<h2>match_template<a class="headerlink" href="#match-template" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.match_template">
<code class="descclassname">skimage.feature.</code><code class="descname">match_template</code><span class="sig-paren">(</span><em>image</em>, <em>template</em>, <em>pad_input=False</em>, <em>mode='constant'</em>, <em>constant_values=0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/template.py#L31"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.match_template" title="Permalink to this definition">¶</a></dt>
<dd><p>Match a template to a 2-D or 3-D image using normalized correlation.</p>
<p>The output is an array with values between -1.0 and 1.0. The value at a
given position corresponds to the correlation coefficient between the image
and the template.</p>
<p>For <cite>pad_input=True</cite> matches correspond to the center and otherwise to the
top-left corner of the template. To find the best match you must search for
peaks in the response (output) image.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N[, D]) array</span></dt>
<dd><p class="first last">2-D or 3-D input image.</p>
</dd>
<dt><strong>template</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(m, n[, d]) array</span></dt>
<dd><p class="first last">Template to locate. It must be <cite>(m &lt;= M, n &lt;= N[, d &lt;= D])</cite>.</p>
</dd>
<dt><strong>pad_input</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">If True, pad <cite>image</cite> so that output is the same size as the image, and
output values correspond to the template center. Otherwise, the output
is an array with shape <cite>(M - m + 1, N - n + 1)</cite> for an <cite>(M, N)</cite> image
and an <cite>(m, n)</cite> template, and matches correspond to origin
(top-left corner) of the template.</p>
</dd>
<dt><strong>mode</strong> <span class="classifier-delimiter">:</span> <span class="classifier">see <cite>numpy.pad</cite>, optional</span></dt>
<dd><p class="first last">Padding mode.</p>
</dd>
<dt><strong>constant_values</strong> <span class="classifier-delimiter">:</span> <span class="classifier">see <cite>numpy.pad</cite>, optional</span></dt>
<dd><p class="first last">Constant values used in conjunction with <code class="docutils literal notranslate"><span class="pre">mode='constant'</span></code>.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">Response image with correlation coefficients.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Details on the cross-correlation are presented in <a class="reference internal" href="#r7bfca17c0278-1" id="id39">[1]</a>. This implementation
uses FFT convolutions of the image and the template. Reference <a class="reference internal" href="#r7bfca17c0278-2" id="id40">[2]</a>
presents similar derivations but the approximation presented in this
reference is not used in our implementation.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r7bfca17c0278-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id39">1</a>, <a class="fn-backref" href="#id41">2</a>)</em> J. P. Lewis, “Fast Normalized Cross-Correlation”, Industrial Light
and Magic.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r7bfca17c0278-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id40">1</a>, <a class="fn-backref" href="#id42">2</a>)</em> Briechle and Hanebeck, “Template Matching using Fast Normalized
Cross Correlation”, Proceedings of the SPIE (2001).
<a class="reference external" href="https://doi.org/10.1117/12.421129">DOI:10.1117/12.421129</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span>
<span class="go">array([[ 0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0., -1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.,  0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">match_template</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">array([[ 1.   , -0.125,  0.   ,  0.   ],</span>
<span class="go">       [-0.125, -0.125,  0.   ,  0.   ],</span>
<span class="go">       [ 0.   ,  0.   ,  0.125,  0.125],</span>
<span class="go">       [ 0.   ,  0.   ,  0.125, -1.   ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">match_template</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">template</span><span class="p">,</span> <span class="n">pad_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">array([[-0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ],</span>
<span class="go">       [-0.125,  1.   , -0.125,  0.   ,  0.   ,  0.   ],</span>
<span class="go">       [-0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ],</span>
<span class="go">       [ 0.   ,  0.   ,  0.   ,  0.125,  0.125,  0.125],</span>
<span class="go">       [ 0.   ,  0.   ,  0.   ,  0.125, -1.   ,  0.125],</span>
<span class="go">       [ 0.   ,  0.   ,  0.   ,  0.125,  0.125,  0.125]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-match-template">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_template</span></code><a class="headerlink" href="#examples-using-skimage-feature-match-template" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="We use template matching to identify the occurrence of an image patch (in this case, a sub-imag..."><div class="figure" id="id86">
<img alt="../_images/sphx_glr_plot_template_thumb.png" src="../_images/sphx_glr_plot_template_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_template.html#sphx-glr-auto-examples-features-detection-plot-template-py"><span class="std std-ref">Template Matching</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="register-translation">
<h2>register_translation<a class="headerlink" href="#register-translation" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.register_translation">
<code class="descclassname">skimage.feature.</code><code class="descname">register_translation</code><span class="sig-paren">(</span><em>src_image</em>, <em>target_image</em>, <em>upsample_factor=1</em>, <em>space='real'</em>, <em>return_error=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/register_translation.py#L107"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.register_translation" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient subpixel image translation registration by cross-correlation.</p>
<p>This code gives the same precision as the FFT upsampled cross-correlation
in a fraction of the computation time and with reduced memory requirements.
It obtains an initial estimate of the cross-correlation peak by an FFT and
then refines the shift estimation by upsampling the DFT only in a small
neighborhood of that estimate by means of a matrix-multiply DFT.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>src_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">Reference image.</p>
</dd>
<dt><strong>target_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">Image to register.  Must be same dimensionality as <code class="docutils literal notranslate"><span class="pre">src_image</span></code>.</p>
</dd>
<dt><strong>upsample_factor</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Upsampling factor. Images will be registered to within
<code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">upsample_factor</span></code> of a pixel. For example
<code class="docutils literal notranslate"><span class="pre">upsample_factor</span> <span class="pre">==</span> <span class="pre">20</span></code> means the images will be registered
within 1/20th of a pixel.  Default is 1 (no upsampling)</p>
</dd>
<dt><strong>space</strong> <span class="classifier-delimiter">:</span> <span class="classifier">string, one of “real” or “fourier”, optional</span></dt>
<dd><p class="first last">Defines how the algorithm interprets input data.  “real” means data
will be FFT’d to compute the correlation, while “fourier” data will
bypass FFT of input data.  Case insensitive.</p>
</dd>
<dt><strong>return_error</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Returns error and phase difference if on,
otherwise only shifts are returned</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>shifts</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Shift vector (in pixels) required to register <code class="docutils literal notranslate"><span class="pre">target_image</span></code> with
<code class="docutils literal notranslate"><span class="pre">src_image</span></code>.  Axis ordering is consistent with numpy (e.g. Z, Y, X)</p>
</dd>
<dt><strong>error</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Translation invariant normalized RMS error between <code class="docutils literal notranslate"><span class="pre">src_image</span></code> and
<code class="docutils literal notranslate"><span class="pre">target_image</span></code>.</p>
</dd>
<dt><strong>phasediff</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Global phase difference between the two images (should be
zero if images are non-negative).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r690c39d932a8-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id43">[1]</a></td><td>Manuel Guizar-Sicairos, Samuel T. Thurman, and James R. Fienup,
“Efficient subpixel image registration algorithms,”
Optics Letters 33, 156-158 (2008). <a class="reference external" href="https://doi.org/10.1364/OL.33.000156">DOI:10.1364/OL.33.000156</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r690c39d932a8-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id44">[2]</a></td><td>James R. Fienup, “Invariant error metrics for image reconstruction”
Optics Letters 36, 8352-8357 (1997). <a class="reference external" href="https://doi.org/10.1364/AO.36.008352">DOI:10.1364/AO.36.008352</a></td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-register-translation">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.register_translation</span></code><a class="headerlink" href="#examples-using-skimage-feature-register-translation" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we use phase correlation to identify the relative shift between two similar-si..."><div class="figure" id="id87">
<img alt="../_images/sphx_glr_plot_register_translation_thumb.png" src="../_images/sphx_glr_plot_register_translation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_register_translation.html#sphx-glr-auto-examples-transform-plot-register-translation-py"><span class="std std-ref">Cross-Correlation (Phase Correlation)</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="masked-register-translation">
<h2>masked_register_translation<a class="headerlink" href="#masked-register-translation" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.masked_register_translation">
<code class="descclassname">skimage.feature.</code><code class="descname">masked_register_translation</code><span class="sig-paren">(</span><em>src_image</em>, <em>target_image</em>, <em>src_mask</em>, <em>target_mask=None</em>, <em>overlap_ratio=0.3</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/masked_register_translation.py#L23"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.masked_register_translation" title="Permalink to this definition">¶</a></dt>
<dd><p>Masked image translation registration by masked normalized
cross-correlation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>src_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Reference image.</p>
</dd>
<dt><strong>target_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Image to register.  Must be same dimensionality as <code class="docutils literal notranslate"><span class="pre">src_image</span></code>,
but not necessarily the same size.</p>
</dd>
<dt><strong>src_mask</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Boolean mask for <code class="docutils literal notranslate"><span class="pre">src_image</span></code>. The mask should evaluate to <code class="docutils literal notranslate"><span class="pre">True</span></code>
(or 1) on valid pixels. <code class="docutils literal notranslate"><span class="pre">src_mask</span></code> should have the same shape
as <code class="docutils literal notranslate"><span class="pre">src_mask</span></code>.</p>
</dd>
<dt><strong>target_mask</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or None, optional</span></dt>
<dd><p class="first last">Boolean mask for <code class="docutils literal notranslate"><span class="pre">target_image</span></code>. The mask should evaluate to <code class="docutils literal notranslate"><span class="pre">True</span></code>
(or 1) on valid pixels. <code class="docutils literal notranslate"><span class="pre">target_mask</span></code> should have the same shape
as <code class="docutils literal notranslate"><span class="pre">target_image</span></code>. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">src_mask</span></code> will be used.</p>
</dd>
<dt><strong>overlap_ratio</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Minimum allowed overlap ratio between images. The correlation for
translations corresponding with an overlap ratio lower than this 
threshold will be ignored. A lower <cite>overlap_ratio</cite> leads to smaller 
maximum translation, while a higher <cite>overlap_ratio</cite> leads to greater 
robustness against spurious matches due to small overlap between 
masked images.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>shifts</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Shift vector (in pixels) required to register <code class="docutils literal notranslate"><span class="pre">target_image</span></code> with
<code class="docutils literal notranslate"><span class="pre">src_image</span></code>. Axis ordering is consistent with numpy (e.g. Z, Y, X)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="ra353c37068de-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id45">[1]</a></td><td>Dirk Padfield. Masked Object Registration in the Fourier Domain.
IEEE Transactions on Image Processing, vol. 21(5), 
pp. 2706-2718 (2012). <a class="reference external" href="https://doi.org/10.1109/TIP.2011.2181402">DOI:10.1109/TIP.2011.2181402</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ra353c37068de-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id46">[2]</a></td><td>D. Padfield. “Masked FFT registration”. In Proc. Computer Vision and 
Pattern Recognition, pp. 2918-2925 (2010).  
<a class="reference external" href="https://doi.org/10.1109/CVPR.2010.5540032">DOI:10.1109/CVPR.2010.5540032</a></td></tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-masked-register-translation">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.masked_register_translation</span></code><a class="headerlink" href="#examples-using-skimage-feature-masked-register-translation" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we use the masked normalized cross-correlation to identify the relative shift ..."><div class="figure" id="id88">
<img alt="../_images/sphx_glr_plot_masked_register_translation_thumb.png" src="../_images/sphx_glr_plot_masked_register_translation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_masked_register_translation.html#sphx-glr-auto-examples-transform-plot-masked-register-translation-py"><span class="std std-ref">Masked Normalized Cross-Correlation</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="match-descriptors">
<h2>match_descriptors<a class="headerlink" href="#match-descriptors" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.match_descriptors">
<code class="descclassname">skimage.feature.</code><code class="descname">match_descriptors</code><span class="sig-paren">(</span><em>descriptors1</em>, <em>descriptors2</em>, <em>metric=None</em>, <em>p=2</em>, <em>max_distance=inf</em>, <em>cross_check=True</em>, <em>max_ratio=1.0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/match.py#L5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.match_descriptors" title="Permalink to this definition">¶</a></dt>
<dd><p>Brute-force matching of descriptors.</p>
<p>For each descriptor in the first set this matcher finds the closest
descriptor in the second set (and vice-versa in the case of enabled
cross-checking).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>descriptors1</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, P) array</span></dt>
<dd><p class="first last">Binary descriptors of size P about M keypoints in the first image.</p>
</dd>
<dt><strong>descriptors2</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, P) array</span></dt>
<dd><p class="first last">Binary descriptors of size P about N keypoints in the second image.</p>
</dd>
<dt><strong>metric</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘euclidean’, ‘cityblock’, ‘minkowski’, ‘hamming’, …} , optional</span></dt>
<dd><p class="first last">The metric to compute the distance between two descriptors. See
<cite>scipy.spatial.distance.cdist</cite> for all possible types. The hamming
distance should be used for binary descriptors. By default the L2-norm
is used for all descriptors of dtype float or double and the Hamming
distance is used for binary descriptors automatically.</p>
</dd>
<dt><strong>p</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">The p-norm to apply for <code class="docutils literal notranslate"><span class="pre">metric='minkowski'</span></code>.</p>
</dd>
<dt><strong>max_distance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Maximum allowed distance between descriptors of two keypoints
in separate images to be regarded as a match.</p>
</dd>
<dt><strong>cross_check</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, the matched keypoints are returned after cross checking i.e. a
matched pair (keypoint1, keypoint2) is returned if keypoint2 is the
best match for keypoint1 in second image and keypoint1 is the best
match for keypoint2 in first image.</p>
</dd>
<dt><strong>max_ratio</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Maximum ratio of distances between first and second closest descriptor
in the second set of descriptors. This threshold is useful to filter
ambiguous matches between the two descriptor sets. The choice of this
value depends on the statistics of the chosen descriptor, e.g.,
for SIFT descriptors a value of 0.8 is usually chosen, see
D.G. Lowe, “Distinctive Image Features from Scale-Invariant Keypoints”,
International Journal of Computer Vision, 2004.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>matches</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(Q, 2) array</span></dt>
<dd><p class="first last">Indices of corresponding matches in first and second set of
descriptors, where <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">0]</span></code> denote the indices in the first
and <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">1]</span></code> the indices in the second set of descriptors.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-match-descriptors">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_descriptors</span></code><a class="headerlink" href="#examples-using-skimage-feature-match-descriptors" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to robustly estimate epipolar geometry between two views using sp..."><div class="figure" id="id89">
<img alt="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" src="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_fundamental_matrix.html#sphx-glr-auto-examples-transform-plot-fundamental-matrix-py"><span class="std std-ref">Fundamental matrix estimation</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the ORB feature detection and binary description algorithm. It uses a..."><div class="figure" id="id90">
<img alt="../_images/sphx_glr_plot_orb_thumb.png" src="../_images/sphx_glr_plot_orb_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_orb.html#sphx-glr-auto-examples-features-detection-plot-orb-py"><span class="std std-ref">ORB feature detector and binary descriptor</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure" id="id91">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="plot-matches">
<h2>plot_matches<a class="headerlink" href="#plot-matches" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.plot_matches">
<code class="descclassname">skimage.feature.</code><code class="descname">plot_matches</code><span class="sig-paren">(</span><em>ax</em>, <em>image1</em>, <em>image2</em>, <em>keypoints1</em>, <em>keypoints2</em>, <em>matches</em>, <em>keypoints_color='k'</em>, <em>matches_color=None</em>, <em>only_matches=False</em>, <em>alignment='horizontal'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/util.py#L43"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.plot_matches" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot matched features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>ax</strong> <span class="classifier-delimiter">:</span> <span class="classifier">matplotlib.axes.Axes</span></dt>
<dd><p class="first last">Matches and image are drawn in this ax.</p>
</dd>
<dt><strong>image1</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, M [, 3]) array</span></dt>
<dd><p class="first last">First grayscale or color image.</p>
</dd>
<dt><strong>image2</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, M [, 3]) array</span></dt>
<dd><p class="first last">Second grayscale or color image.</p>
</dd>
<dt><strong>keypoints1</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(K1, 2) array</span></dt>
<dd><p class="first last">First keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>keypoints2</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(K2, 2) array</span></dt>
<dd><p class="first last">Second keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>matches</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(Q, 2) array</span></dt>
<dd><p class="first last">Indices of corresponding matches in first and second set of
descriptors, where <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">0]</span></code> denote the indices in the first
and <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">1]</span></code> the indices in the second set of descriptors.</p>
</dd>
<dt><strong>keypoints_color</strong> <span class="classifier-delimiter">:</span> <span class="classifier">matplotlib color, optional</span></dt>
<dd><p class="first last">Color for keypoint locations.</p>
</dd>
<dt><strong>matches_color</strong> <span class="classifier-delimiter">:</span> <span class="classifier">matplotlib color, optional</span></dt>
<dd><p class="first last">Color for lines which connect keypoint matches. By default the
color is chosen randomly.</p>
</dd>
<dt><strong>only_matches</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Whether to only plot matches and not plot the keypoint locations.</p>
</dd>
<dt><strong>alignment</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘horizontal’, ‘vertical’}, optional</span></dt>
<dd><p class="first last">Whether to show images side by side, <code class="docutils literal notranslate"><span class="pre">'horizontal'</span></code>, or one above
the other, <code class="docutils literal notranslate"><span class="pre">'vertical'</span></code>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-plot-matches">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.plot_matches</span></code><a class="headerlink" href="#examples-using-skimage-feature-plot-matches" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to robustly estimate epipolar geometry between two views using sp..."><div class="figure" id="id92">
<img alt="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" src="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_fundamental_matrix.html#sphx-glr-auto-examples-transform-plot-fundamental-matrix-py"><span class="std std-ref">Fundamental matrix estimation</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure" id="id93">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the ORB feature detection and binary description algorithm. It uses a..."><div class="figure" id="id94">
<img alt="../_images/sphx_glr_plot_orb_thumb.png" src="../_images/sphx_glr_plot_orb_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_orb.html#sphx-glr-auto-examples-features-detection-plot-orb-py"><span class="std std-ref">ORB feature detector and binary descriptor</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure" id="id95">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="blob-dog">
<h2>blob_dog<a class="headerlink" href="#blob-dog" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.blob_dog">
<code class="descclassname">skimage.feature.</code><code class="descname">blob_dog</code><span class="sig-paren">(</span><em>image</em>, <em>min_sigma=1</em>, <em>max_sigma=50</em>, <em>sigma_ratio=1.6</em>, <em>threshold=2.0</em>, <em>overlap=0.5</em>, <em>*</em>, <em>exclude_border=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/blob.py#L168"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.blob_dog" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds blobs in the given grayscale image.</p>
<p>Blobs are found using the Difference of Gaussian (DoG) method <a class="reference internal" href="#rf5218630e229-1" id="id47">[1]</a>.
For each blob found, the method returns its coordinates and the standard
deviation of the Gaussian kernel that detected the blob.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D or 3D ndarray</span></dt>
<dd><p class="first last">Input grayscale image, blobs are assumed to be light on dark
background (white on black).</p>
</dd>
<dt><strong>min_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">scalar or sequence of scalars, optional</span></dt>
<dd><p class="first last">The minimum standard deviation for Gaussian kernel. Keep this low to
detect smaller blobs. The standard deviations of the Gaussian filter
are given for each axis as a sequence, or as a single number, in
which case it is equal for all axes.</p>
</dd>
<dt><strong>max_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">scalar or sequence of scalars, optional</span></dt>
<dd><p class="first last">The maximum standard deviation for Gaussian kernel. Keep this high to
detect larger blobs. The standard deviations of the Gaussian filter
are given for each axis as a sequence, or as a single number, in
which case it is equal for all axes.</p>
</dd>
<dt><strong>sigma_ratio</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">The ratio between the standard deviation of Gaussian Kernels used for
computing the Difference of Gaussians</p>
</dd>
<dt><strong>threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional.</span></dt>
<dd><p class="first last">The absolute lower bound for scale space maxima. Local maxima smaller
than thresh are ignored. Reduce this to detect blobs with less
intensities.</p>
</dd>
<dt><strong>overlap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">A value between 0 and 1. If the area of two blobs overlaps by a
fraction greater than <cite>threshold</cite>, the smaller blob is eliminated.</p>
</dd>
<dt><strong>exclude_border</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int or bool, optional</span></dt>
<dd><p class="first last">If nonzero int, <cite>exclude_border</cite> excludes blobs from
within <cite>exclude_border</cite>-pixels of the border of the image.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n, image.ndim + sigma) ndarray</span></dt>
<dd><p class="first last">A 2d array with each row representing 2 coordinate values for a 2D
image, and 3 coordinate values for a 3D image, plus the sigma(s) used.
When a single sigma is passed, outputs are:
<code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code> or <code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code> where <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c)</span></code> or
<code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c)</span></code> are coordinates of the blob and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the standard
deviation of the Gaussian kernel which detected the blob. When an
anisotropic gaussian is used (sigmas per dimension), the detected sigma
is returned for each dimension.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The radius of each blob is approximately <span class="math notranslate nohighlight">\(\sqrt{2}\sigma\)</span> for
a 2-D image and <span class="math notranslate nohighlight">\(\sqrt{3}\sigma\)</span> for a 3-D image.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rf5218630e229-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id47">1</a>, <a class="fn-backref" href="#id48">2</a>)</em> <a class="reference external" href="https://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach">https://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="o">.</span><span class="n">blob_dog</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">(),</span> <span class="n">threshold</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_sigma</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="go">array([[ 267.      ,  359.      ,   16.777216],</span>
<span class="go">       [ 267.      ,  115.      ,   10.48576 ],</span>
<span class="go">       [ 263.      ,  302.      ,   16.777216],</span>
<span class="go">       [ 263.      ,  245.      ,   16.777216],</span>
<span class="go">       [ 261.      ,  173.      ,   16.777216],</span>
<span class="go">       [ 260.      ,   46.      ,   16.777216],</span>
<span class="go">       [ 198.      ,  155.      ,   10.48576 ],</span>
<span class="go">       [ 196.      ,   43.      ,   10.48576 ],</span>
<span class="go">       [ 195.      ,  102.      ,   16.777216],</span>
<span class="go">       [ 194.      ,  277.      ,   16.777216],</span>
<span class="go">       [ 193.      ,  213.      ,   16.777216],</span>
<span class="go">       [ 185.      ,  347.      ,   16.777216],</span>
<span class="go">       [ 128.      ,  154.      ,   10.48576 ],</span>
<span class="go">       [ 127.      ,  102.      ,   10.48576 ],</span>
<span class="go">       [ 125.      ,  208.      ,   10.48576 ],</span>
<span class="go">       [ 125.      ,   45.      ,   16.777216],</span>
<span class="go">       [ 124.      ,  337.      ,   10.48576 ],</span>
<span class="go">       [ 120.      ,  272.      ,   16.777216],</span>
<span class="go">       [  58.      ,  100.      ,   10.48576 ],</span>
<span class="go">       [  54.      ,  276.      ,   10.48576 ],</span>
<span class="go">       [  54.      ,   42.      ,   16.777216],</span>
<span class="go">       [  52.      ,  216.      ,   16.777216],</span>
<span class="go">       [  52.      ,  155.      ,   16.777216],</span>
<span class="go">       [  45.      ,  336.      ,   16.777216]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-blob-dog">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code><a class="headerlink" href="#examples-using-skimage-feature-blob-dog" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are dete..."><div class="figure" id="id96">
<img alt="../_images/sphx_glr_plot_blob_thumb.png" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="blob-doh">
<h2>blob_doh<a class="headerlink" href="#blob-doh" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.blob_doh">
<code class="descclassname">skimage.feature.</code><code class="descname">blob_doh</code><span class="sig-paren">(</span><em>image</em>, <em>min_sigma=1</em>, <em>max_sigma=30</em>, <em>num_sigma=10</em>, <em>threshold=0.01</em>, <em>overlap=0.5</em>, <em>log_scale=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/blob.py#L459"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.blob_doh" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds blobs in the given grayscale image.</p>
<p>Blobs are found using the Determinant of Hessian method <a class="reference internal" href="#ra19a7aed16ca-1" id="id49">[1]</a>. For each blob
found, the method returns its coordinates and the standard deviation
of the Gaussian Kernel used for the Hessian matrix whose determinant
detected the blob. Determinant of Hessians is approximated using <a class="reference internal" href="#ra19a7aed16ca-2" id="id50">[2]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D ndarray</span></dt>
<dd><p class="first last">Input grayscale image.Blobs can either be light on dark or vice versa.</p>
</dd>
<dt><strong>min_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">The minimum standard deviation for Gaussian Kernel used to compute
Hessian matrix. Keep this low to detect smaller blobs.</p>
</dd>
<dt><strong>max_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">The maximum standard deviation for Gaussian Kernel used to compute
Hessian matrix. Keep this high to detect larger blobs.</p>
</dd>
<dt><strong>num_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">The number of intermediate values of standard deviations to consider
between <cite>min_sigma</cite> and <cite>max_sigma</cite>.</p>
</dd>
<dt><strong>threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional.</span></dt>
<dd><p class="first last">The absolute lower bound for scale space maxima. Local maxima smaller
than thresh are ignored. Reduce this to detect less prominent blobs.</p>
</dd>
<dt><strong>overlap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">A value between 0 and 1. If the area of two blobs overlaps by a
fraction greater than <cite>threshold</cite>, the smaller blob is eliminated.</p>
</dd>
<dt><strong>log_scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If set intermediate values of standard deviations are interpolated
using a logarithmic scale to the base <cite>10</cite>. If not, linear
interpolation is used.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n, 3) ndarray</span></dt>
<dd><p class="first last">A 2d array with each row representing 3 values, <code class="docutils literal notranslate"><span class="pre">(y,x,sigma)</span></code>
where <code class="docutils literal notranslate"><span class="pre">(y,x)</span></code> are coordinates of the blob and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the
standard deviation of the Gaussian kernel of the Hessian Matrix whose
determinant detected the blob.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The radius of each blob is approximately <cite>sigma</cite>.
Computation of Determinant of Hessians is independent of the standard
deviation. Therefore detecting larger blobs won’t take more time. In
methods line <a class="reference internal" href="#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code class="xref py py-meth docutils literal notranslate"><span class="pre">blob_dog()</span></code></a> and <a class="reference internal" href="#skimage.feature.blob_log" title="skimage.feature.blob_log"><code class="xref py py-meth docutils literal notranslate"><span class="pre">blob_log()</span></code></a> the computation
of Gaussians for larger <cite>sigma</cite> takes more time. The downside is that
this method can’t be used for detecting blobs of radius less than <cite>3px</cite>
due to the box filters used in the approximation of Hessian Determinant.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="ra19a7aed16ca-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id49">1</a>, <a class="fn-backref" href="#id51">2</a>)</em> <a class="reference external" href="https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian">https://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ra19a7aed16ca-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id50">1</a>, <a class="fn-backref" href="#id52">2</a>)</em> Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool,
“SURF: Speeded Up Robust Features”
<a class="reference external" href="ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf">ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="o">.</span><span class="n">blob_doh</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="go">array([[ 270.        ,  363.        ,   30.        ],</span>
<span class="go">       [ 265.        ,  113.        ,   23.55555556],</span>
<span class="go">       [ 262.        ,  243.        ,   23.55555556],</span>
<span class="go">       [ 260.        ,  173.        ,   30.        ],</span>
<span class="go">       [ 197.        ,  153.        ,   20.33333333],</span>
<span class="go">       [ 197.        ,   44.        ,   20.33333333],</span>
<span class="go">       [ 195.        ,  100.        ,   23.55555556],</span>
<span class="go">       [ 193.        ,  275.        ,   23.55555556],</span>
<span class="go">       [ 192.        ,  212.        ,   23.55555556],</span>
<span class="go">       [ 185.        ,  348.        ,   30.        ],</span>
<span class="go">       [ 156.        ,  302.        ,   30.        ],</span>
<span class="go">       [ 126.        ,  153.        ,   20.33333333],</span>
<span class="go">       [ 126.        ,  101.        ,   20.33333333],</span>
<span class="go">       [ 124.        ,  336.        ,   20.33333333],</span>
<span class="go">       [ 123.        ,  205.        ,   20.33333333],</span>
<span class="go">       [ 123.        ,   44.        ,   23.55555556],</span>
<span class="go">       [ 121.        ,  271.        ,   30.        ]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-blob-doh">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_doh</span></code><a class="headerlink" href="#examples-using-skimage-feature-blob-doh" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are dete..."><div class="figure" id="id97">
<img alt="../_images/sphx_glr_plot_blob_thumb.png" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="blob-log">
<h2>blob_log<a class="headerlink" href="#blob-log" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.blob_log">
<code class="descclassname">skimage.feature.</code><code class="descname">blob_log</code><span class="sig-paren">(</span><em>image</em>, <em>min_sigma=1</em>, <em>max_sigma=50</em>, <em>num_sigma=10</em>, <em>threshold=0.2</em>, <em>overlap=0.5</em>, <em>log_scale=False</em>, <em>*</em>, <em>exclude_border=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/blob.py#L313"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.blob_log" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds blobs in the given grayscale image.</p>
<p>Blobs are found using the Laplacian of Gaussian (LoG) method <a class="reference internal" href="#r520e53dd5fa2-1" id="id53">[1]</a>.
For each blob found, the method returns its coordinates and the standard
deviation of the Gaussian kernel that detected the blob.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D or 3D ndarray</span></dt>
<dd><p class="first last">Input grayscale image, blobs are assumed to be light on dark
background (white on black).</p>
</dd>
<dt><strong>min_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">scalar or sequence of scalars, optional</span></dt>
<dd><p class="first last">the minimum standard deviation for Gaussian kernel. Keep this low to
detect smaller blobs. The standard deviations of the Gaussian filter
are given for each axis as a sequence, or as a single number, in
which case it is equal for all axes.</p>
</dd>
<dt><strong>max_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">scalar or sequence of scalars, optional</span></dt>
<dd><p class="first last">The maximum standard deviation for Gaussian kernel. Keep this high to
detect larger blobs. The standard deviations of the Gaussian filter
are given for each axis as a sequence, or as a single number, in
which case it is equal for all axes.</p>
</dd>
<dt><strong>num_sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">The number of intermediate values of standard deviations to consider
between <cite>min_sigma</cite> and <cite>max_sigma</cite>.</p>
</dd>
<dt><strong>threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional.</span></dt>
<dd><p class="first last">The absolute lower bound for scale space maxima. Local maxima smaller
than thresh are ignored. Reduce this to detect blobs with less
intensities.</p>
</dd>
<dt><strong>overlap</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">A value between 0 and 1. If the area of two blobs overlaps by a
fraction greater than <cite>threshold</cite>, the smaller blob is eliminated.</p>
</dd>
<dt><strong>log_scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If set intermediate values of standard deviations are interpolated
using a logarithmic scale to the base <cite>10</cite>. If not, linear
interpolation is used.</p>
</dd>
<dt><strong>exclude_border</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int or bool, optional</span></dt>
<dd><p class="first last">If nonzero int, <cite>exclude_border</cite> excludes blobs from
within <cite>exclude_border</cite>-pixels of the border of the image.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>A</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n, image.ndim + sigma) ndarray</span></dt>
<dd><p class="first last">A 2d array with each row representing 2 coordinate values for a 2D
image, and 3 coordinate values for a 3D image, plus the sigma(s) used.
When a single sigma is passed, outputs are:
<code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code> or <code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code> where <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c)</span></code> or
<code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c)</span></code> are coordinates of the blob and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the standard
deviation of the Gaussian kernel which detected the blob. When an
anisotropic gaussian is used (sigmas per dimension), the detected sigma
is returned for each dimension.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The radius of each blob is approximately <span class="math notranslate nohighlight">\(\sqrt{2}\sigma\)</span> for
a 2-D image and <span class="math notranslate nohighlight">\(\sqrt{3}\sigma\)</span> for a 3-D image.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r520e53dd5fa2-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id53">1</a>, <a class="fn-backref" href="#id54">2</a>)</em> <a class="reference external" href="https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian">https://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">exposure</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">exposure</span><span class="o">.</span><span class="n">equalize_hist</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  <span class="c1"># improves detection</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="o">.</span><span class="n">blob_log</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">3</span><span class="p">)</span>
<span class="go">array([[ 266.        ,  115.        ,   11.88888889],</span>
<span class="go">       [ 263.        ,  302.        ,   17.33333333],</span>
<span class="go">       [ 263.        ,  244.        ,   17.33333333],</span>
<span class="go">       [ 260.        ,  174.        ,   17.33333333],</span>
<span class="go">       [ 198.        ,  155.        ,   11.88888889],</span>
<span class="go">       [ 198.        ,  103.        ,   11.88888889],</span>
<span class="go">       [ 197.        ,   44.        ,   11.88888889],</span>
<span class="go">       [ 194.        ,  276.        ,   17.33333333],</span>
<span class="go">       [ 194.        ,  213.        ,   17.33333333],</span>
<span class="go">       [ 185.        ,  344.        ,   17.33333333],</span>
<span class="go">       [ 128.        ,  154.        ,   11.88888889],</span>
<span class="go">       [ 127.        ,  102.        ,   11.88888889],</span>
<span class="go">       [ 126.        ,  208.        ,   11.88888889],</span>
<span class="go">       [ 126.        ,   46.        ,   11.88888889],</span>
<span class="go">       [ 124.        ,  336.        ,   11.88888889],</span>
<span class="go">       [ 121.        ,  272.        ,   17.33333333],</span>
<span class="go">       [ 113.        ,  323.        ,    1.        ]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-blob-log">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_log</span></code><a class="headerlink" href="#examples-using-skimage-feature-blob-log" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are dete..."><div class="figure" id="id98">
<img alt="../_images/sphx_glr_plot_blob_thumb.png" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="haar-like-feature">
<h2>haar_like_feature<a class="headerlink" href="#haar-like-feature" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.haar_like_feature">
<code class="descclassname">skimage.feature.</code><code class="descname">haar_like_feature</code><span class="sig-paren">(</span><em>int_image</em>, <em>r</em>, <em>c</em>, <em>width</em>, <em>height</em>, <em>feature_type=None</em>, <em>feature_coord=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/haar.py#L87"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.haar_like_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Haar-like features for a region of interest (ROI) of an
integral image.</p>
<p>Haar-like features have been successfully used for image classification and
object detection <a class="reference internal" href="#rbcb83f52fce4-1" id="id55">[1]</a>. It has been used for real-time face detection
algorithm proposed in <a class="reference internal" href="#rbcb83f52fce4-2" id="id56">[2]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>int_image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N) ndarray</span></dt>
<dd><p class="first last">Integral image for which the features need to be computed.</p>
</dd>
<dt><strong>r</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Row-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>c</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Column-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>width</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Width of the detection window.</p>
</dd>
<dt><strong>height</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Height of the detection window.</p>
</dd>
<dt><strong>feature_type</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or list of str or None, optional</span></dt>
<dd><p class="first">The type of feature to consider:</p>
<ul class="simple">
<li>‘type-2-x’: 2 rectangles varying along the x axis;</li>
<li>‘type-2-y’: 2 rectangles varying along the y axis;</li>
<li>‘type-3-x’: 3 rectangles varying along the x axis;</li>
<li>‘type-3-y’: 3 rectangles varying along the y axis;</li>
<li>‘type-4’: 4 rectangles varying along x and y axis.</li>
</ul>
<p>By default all features are extracted.</p>
<p class="last">If using with <cite>feature_coord</cite>, it should correspond to the feature
type of each associated coordinate feature.</p>
</dd>
<dt><strong>feature_coord</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of list of tuples or None, optional</span></dt>
<dd><p class="first last">The array of coordinates to be extracted. This is useful when you want
to recompute only a subset of features. In this case <cite>feature_type</cite>
needs to be an array containing the type of each feature, as returned
by <a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code class="xref py py-func docutils literal notranslate"><span class="pre">haar_like_feature_coord()</span></code></a>. By default, all coordinates are
computed.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>haar_features</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n_features,) ndarray of int or float</span></dt>
<dd><p class="first last">Resulting Haar-like features. Each value is equal to the subtraction of
sums of the positive and negative rectangles. The data type depends of
the data type of <cite>int_image</cite>: <cite>int</cite> when the data type of <cite>int_image</cite>
is <cite>uint</cite> or <cite>int</cite> and <cite>float</cite> when the data type of <cite>int_image</cite> is
<cite>float</cite>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>When extracting those features in parallel, be aware that the choice of the
backend (i.e. multiprocessing vs threading) will have an impact on the
performance. The rule of thumb is as follows: use multiprocessing when
extracting features for all possible ROI in an image; use threading when
extracting the feature at specific location for a limited number of ROIs.
Refer to the example
<a class="reference internal" href="../auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a>
for more insights.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rbcb83f52fce4-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><em>(<a class="fn-backref" href="#id55">1</a>, <a class="fn-backref" href="#id57">2</a>)</em> <a class="reference external" href="https://en.wikipedia.org/wiki/Haar-like_feature">https://en.wikipedia.org/wiki/Haar-like_feature</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rbcb83f52fce4-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id56">1</a>, <a class="fn-backref" href="#id58">2</a>)</em> Oren, M., Papageorgiou, C., Sinha, P., Osuna, E., &amp; Poggio, T.
(1997, June). Pedestrian detection using wavelet templates.
In Computer Vision and Pattern Recognition, 1997. Proceedings.,
1997 IEEE Computer Society Conference on (pp. 193-199). IEEE.
<a class="reference external" href="http://tinyurl.com/y6ulxfta">http://tinyurl.com/y6ulxfta</a>
<a class="reference external" href="https://doi.org/10.1109/CVPR.1997.609319">DOI:10.1109/CVPR.1997.609319</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rbcb83f52fce4-3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id59">[3]</a></td><td>Viola, Paul, and Michael J. Jones. “Robust real-time face
detection.” International journal of computer vision 57.2
(2004): 137-154.
<a class="reference external" href="http://www.merl.com/publications/docs/TR2004-043.pdf">http://www.merl.com/publications/docs/TR2004-043.pdf</a>
<a class="reference external" href="https://doi.org/10.1109/CVPR.2001.990517">DOI:10.1109/CVPR.2001.990517</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="k">import</span> <span class="n">integral_image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img_ii</span> <span class="o">=</span> <span class="n">integral_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span> <span class="o">=</span> <span class="n">haar_like_feature</span><span class="p">(</span><span class="n">img_ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;type-3-x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span>
<span class="go">array([-1, -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -4, -1,</span>
<span class="go">       -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -1, -2, -3, -1, -2, -3, -1,</span>
<span class="go">       -2, -1, -2, -1, -2, -1, -1, -1])</span>
</pre></div>
</div>
<p>You can compute the feature for some pre-computed coordinates.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature_coord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_coord</span><span class="p">,</span> <span class="n">feature_type</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
<span class="gp">... </span>    <span class="o">*</span><span class="p">[</span><span class="n">haar_like_feature_coord</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">feat_t</span><span class="p">)</span>
<span class="gp">... </span>      <span class="k">for</span> <span class="n">feat_t</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;type-2-x&#39;</span><span class="p">,</span> <span class="s1">&#39;type-3-x&#39;</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># only select one feature over two</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_coord</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">feature_coord</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">feature_type</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span> <span class="o">=</span> <span class="n">haar_like_feature</span><span class="p">(</span><span class="n">img_ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">feature_type</span><span class="o">=</span><span class="n">feature_type</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">feature_coord</span><span class="o">=</span><span class="n">feature_coord</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span>
<span class="go">array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,</span>
<span class="go">        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,</span>
<span class="go">        0,  0,  0,  0,  0,  0,  0,  0, -1, -3, -1, -3, -1, -3, -1, -3, -1,</span>
<span class="go">       -3, -1, -3, -1, -3, -2, -1, -3, -2, -2, -2, -1])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-haar-like-feature">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature</span></code><a class="headerlink" href="#examples-using-skimage-feature-haar-like-feature" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face dete..."><div class="figure" id="id99">
<img alt="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="haar-like-feature-coord">
<h2>haar_like_feature_coord<a class="headerlink" href="#haar-like-feature-coord" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.haar_like_feature_coord">
<code class="descclassname">skimage.feature.</code><code class="descname">haar_like_feature_coord</code><span class="sig-paren">(</span><em>width</em>, <em>height</em>, <em>feature_type=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/haar.py#L36"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.haar_like_feature_coord" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the coordinates of Haar-like features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>width</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Width of the detection window.</p>
</dd>
<dt><strong>height</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Height of the detection window.</p>
</dd>
<dt><strong>feature_type</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or list of str or None, optional</span></dt>
<dd><p class="first">The type of feature to consider:</p>
<ul class="simple">
<li>‘type-2-x’: 2 rectangles varying along the x axis;</li>
<li>‘type-2-y’: 2 rectangles varying along the y axis;</li>
<li>‘type-3-x’: 3 rectangles varying along the x axis;</li>
<li>‘type-3-y’: 3 rectangles varying along the y axis;</li>
<li>‘type-4’: 4 rectangles varying along x and y axis.</li>
</ul>
<p class="last">By default all features are extracted.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>feature_coord</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n_features, n_rectangles, 2, 2), ndarray of list of tuple coord</span></dt>
<dd><p class="first last">Coordinates of the rectangles for each feature.</p>
</dd>
<dt><strong>feature_type</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(n_features,), ndarray of str</span></dt>
<dd><p class="first last">The corresponding type for each feature.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="k">import</span> <span class="n">integral_image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature_coord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat_coord</span><span class="p">,</span> <span class="n">feat_type</span> <span class="o">=</span> <span class="n">haar_like_feature_coord</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;type-4&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat_coord</span> <span class="c1"># doctest: +SKIP</span>
<span class="go">array([ list([[(0, 0), (0, 0)], [(0, 1), (0, 1)],</span>
<span class="go">              [(1, 1), (1, 1)], [(1, 0), (1, 0)]])], dtype=object)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat_type</span>
<span class="go">array([&#39;type-4&#39;], dtype=object)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-haar-like-feature-coord">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature_coord</span></code><a class="headerlink" href="#examples-using-skimage-feature-haar-like-feature-coord" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Haar-like features are simple digital image features that were introduced in a real-time face d..."><div class="figure" id="id100">
<img alt="../_images/sphx_glr_plot_haar_thumb.png" src="../_images/sphx_glr_plot_haar_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_haar.html#sphx-glr-auto-examples-features-detection-plot-haar-py"><span class="std std-ref">Haar-like feature descriptor</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face dete..."><div class="figure" id="id101">
<img alt="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="draw-haar-like-feature">
<h2>draw_haar_like_feature<a class="headerlink" href="#draw-haar-like-feature" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.draw_haar_like_feature">
<code class="descclassname">skimage.feature.</code><code class="descname">draw_haar_like_feature</code><span class="sig-paren">(</span><em>image</em>, <em>r</em>, <em>c</em>, <em>width</em>, <em>height</em>, <em>feature_coord</em>, <em>color_positive_block=(1.0</em>, <em>0.0</em>, <em>0.0)</em>, <em>color_negative_block=(0.0</em>, <em>1.0</em>, <em>0.0)</em>, <em>alpha=0.5</em>, <em>max_n_features=None</em>, <em>random_state=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/haar.py#L222"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.draw_haar_like_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualization of Haar-like features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N) ndarray</span></dt>
<dd><p class="first last">The region of an integral image for which the features need to be
computed.</p>
</dd>
<dt><strong>r</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Row-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>c</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Column-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>width</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Width of the detection window.</p>
</dd>
<dt><strong>height</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Height of the detection window.</p>
</dd>
<dt><strong>feature_coord</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of list of tuples or None, optional</span></dt>
<dd><p class="first last">The array of coordinates to be extracted. This is useful when you want
to recompute only a subset of features. In this case <cite>feature_type</cite>
needs to be an array containing the type of each feature, as returned
by <a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code class="xref py py-func docutils literal notranslate"><span class="pre">haar_like_feature_coord()</span></code></a>. By default, all coordinates are
computed.</p>
</dd>
<dt><strong>color_positive_rectangle</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple of 3 floats</span></dt>
<dd><p class="first last">Floats specifying the color for the positive block. Corresponding
values define (R, G, B) values. Default value is red (1, 0, 0).</p>
</dd>
<dt><strong>color_negative_block</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple of 3 floats</span></dt>
<dd><p class="first last">Floats specifying the color for the negative block Corresponding values
define (R, G, B) values. Default value is blue (0, 1, 0).</p>
</dd>
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Value in the range [0, 1] that specifies opacity of visualization. 1 -
fully transparent, 0 - opaque.</p>
</dd>
<dt><strong>max_n_features</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, default=None</span></dt>
<dd><p class="first last">The maximum number of features to be returned.
By default, all features are returned.</p>
</dd>
<dt><strong>random_state</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional</span></dt>
<dd><p class="first last">If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. The random state is used when generating a set of
features smaller than the total number of available features.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>features</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(M, N), ndarray</span></dt>
<dd><p class="first last">An image in which the different features will be added.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature_coord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">draw_haar_like_feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_coord</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">haar_like_feature_coord</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;type-4&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">draw_haar_like_feature</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
<span class="gp">... </span>                               <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">feature_coord</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">max_n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span>
<span class="go">array([[[ 0. ,  0.5,  0. ],</span>
<span class="go">        [ 0.5,  0. ,  0. ]],</span>
<span class="go">&lt;BLANKLINE&gt;</span>
<span class="go">       [[ 0.5,  0. ,  0. ],</span>
<span class="go">        [ 0. ,  0.5,  0. ]]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-draw-haar-like-feature">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_haar_like_feature</span></code><a class="headerlink" href="#examples-using-skimage-feature-draw-haar-like-feature" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Haar-like features are simple digital image features that were introduced in a real-time face d..."><div class="figure" id="id102">
<img alt="../_images/sphx_glr_plot_haar_thumb.png" src="../_images/sphx_glr_plot_haar_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_haar.html#sphx-glr-auto-examples-features-detection-plot-haar-py"><span class="std std-ref">Haar-like feature descriptor</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face dete..."><div class="figure" id="id103">
<img alt="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></span></p>
</div>
</div></div>
</div>
<div class="section" id="cascade">
<h2><a class="reference internal" href="#skimage.feature.Cascade" title="skimage.feature.Cascade"><code class="xref py py-class docutils literal notranslate"><span class="pre">Cascade</span></code></a><a class="headerlink" href="#cascade" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.Cascade">
<em class="property">class </em><code class="descclassname">skimage.feature.</code><code class="descname">Cascade</code><a class="headerlink" href="#skimage.feature.Cascade" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Class for cascade of classifiers that is used for object detection.</p>
<p>The main idea behind cascade of classifiers is to create classifiers
of medium accuracy and ensemble them into one strong classifier
instead of just creating a strong one. The second advantage of cascade
classifier is that easy examples can be classified only by evaluating
some of the classifiers in the cascade, making the process much faster
than the process of evaluating a one strong classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>eps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Accuracy parameter. Increasing it, makes the classifier detect less
false positives but at the same time the false negative score increases.</p>
</dd>
<dt><strong>stages_number</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Py_ssize_t</span></dt>
<dd><p class="first last">Amount of stages in a cascade. Each cascade consists of stumps i.e.
trained features.</p>
</dd>
<dt><strong>stumps_number</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Py_ssize_t</span></dt>
<dd><p class="first last">The overall amount of stumps in all the stages of cascade.</p>
</dd>
<dt><strong>features_number</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Py_ssize_t</span></dt>
<dd><p class="first last">The overall amount of different features used by cascade.
Two stumps can use the same features but has different trained
values.</p>
</dd>
<dt><strong>window_width</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Py_ssize_t</span></dt>
<dd><p class="first last">The width of a detection window that is used. Objects smaller than
this window can’t be detected.</p>
</dd>
<dt><strong>window_height</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Py_ssize_t</span></dt>
<dd><p class="first last">The height of a detection window.</p>
</dd>
<dt><strong>stages</strong> <span class="classifier-delimiter">:</span> <span class="classifier">Stage*</span></dt>
<dd><p class="first last">A link to the c array that stores stages information using
Stage struct.</p>
</dd>
<dt><strong>features</strong> <span class="classifier-delimiter">:</span> <span class="classifier">MBLBP*</span></dt>
<dd><p class="first last">Link to the c array that stores MBLBP features using MBLBP struct.</p>
</dd>
<dt><strong>LUTs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cnp.uint32_t*</span></dt>
<dd><p class="first last">The ling to the array with look-up tables that are used by trained
MBLBP features (MBLBPStumps) to evaluate a particular region.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skimage.feature.Cascade.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#skimage.feature.Cascade.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize cascade classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>xml_file</strong> <span class="classifier-delimiter">:</span> <span class="classifier">file’s path or file’s object</span></dt>
<dd><p class="first last">A file in a OpenCv format from which all the cascade classifier’s
parameters are loaded.</p>
</dd>
<dt><strong>eps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Accuracy parameter. Increasing it, makes the classifier detect less
false positives but at the same time the false negative score increases.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.Cascade.detect_multi_scale">
<code class="descname">detect_multi_scale</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#skimage.feature.Cascade.detect_multi_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Search for the object on multiple scales of input image.</p>
<p>The function takes the input image, the scale factor by which the
searching window is multiplied on each step, minimum window size
and maximum window size that specify the interval for the search
windows that are applied to the input image to detect objects.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>img</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2-D or 3-D ndarray</span></dt>
<dd><p class="first last">Ndarray that represents the input image.</p>
</dd>
<dt><strong>scale_factor</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The scale by which searching window is multiplied on each step.</p>
</dd>
<dt><strong>step_ratio</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The ratio by which the search step in multiplied on each scale
of the image. 1 represents the exaustive search and usually is
slow. By setting this parameter to higher values the results will
be worse but the computation will be much faster. Usually, values
in the interval [1, 1.5] give good results.</p>
</dd>
<dt><strong>min_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">typle (int, int)</span></dt>
<dd><p class="first last">Minimum size of the search window.</p>
</dd>
<dt><strong>max_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">typle (int, int)</span></dt>
<dd><p class="first last">Maximum size of the search window.</p>
</dd>
<dt><strong>min_neighbour_number</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Minimum amount of intersecting detections in order for detection
to be approved by the function.</p>
</dd>
<dt><strong>intersection_score_threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The minimum value of value of ratio
(intersection area) / (small rectangle ratio) in order to merge
two detections into one.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>output</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of dicts</span></dt>
<dd><p class="first last">Dict have form {‘r’: int, ‘c’: int, ‘width’: int, ‘height’: int},
where ‘r’ represents row position of top left corner of detected
window, ‘c’ - col position, ‘width’ - width of detected window,
‘height’ - height of detected window.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="skimage.feature.Cascade.eps">
<code class="descname">eps</code><a class="headerlink" href="#skimage.feature.Cascade.eps" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="skimage.feature.Cascade.features_number">
<code class="descname">features_number</code><a class="headerlink" href="#skimage.feature.Cascade.features_number" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="skimage.feature.Cascade.stages_number">
<code class="descname">stages_number</code><a class="headerlink" href="#skimage.feature.Cascade.stages_number" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="skimage.feature.Cascade.stumps_number">
<code class="descname">stumps_number</code><a class="headerlink" href="#skimage.feature.Cascade.stumps_number" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="skimage.feature.Cascade.window_height">
<code class="descname">window_height</code><a class="headerlink" href="#skimage.feature.Cascade.window_height" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="skimage.feature.Cascade.window_width">
<code class="descname">window_width</code><a class="headerlink" href="#skimage.feature.Cascade.window_width" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="brief">
<h2><a class="reference internal" href="#skimage.feature.BRIEF" title="skimage.feature.BRIEF"><code class="xref py py-class docutils literal notranslate"><span class="pre">BRIEF</span></code></a><a class="headerlink" href="#brief" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.BRIEF">
<em class="property">class </em><code class="descclassname">skimage.feature.</code><code class="descname">BRIEF</code><span class="sig-paren">(</span><em>descriptor_size=256</em>, <em>patch_size=49</em>, <em>mode='normal'</em>, <em>sigma=1</em>, <em>sample_seed=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/brief.py#L11"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.BRIEF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.DescriptorExtractor</span></code></p>
<p>BRIEF binary descriptor extractor.</p>
<p>BRIEF (Binary Robust Independent Elementary Features) is an efficient
feature point descriptor. It is highly discriminative even when using
relatively few bits and is computed using simple intensity difference
tests.</p>
<p>For each keypoint, intensity comparisons are carried out for a specifically
distributed number N of pixel-pairs resulting in a binary descriptor of
length N. For binary descriptors the Hamming distance can be used for
feature matching, which leads to lower computational cost in comparison to
the L2 norm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>descriptor_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Size of BRIEF descriptor for each keypoint. Sizes 128, 256 and 512
recommended by the authors. Default is 256.</p>
</dd>
<dt><strong>patch_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Length of the two dimensional square patch sampling region around
the keypoints. Default is 49.</p>
</dd>
<dt><strong>mode</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘normal’, ‘uniform’}, optional</span></dt>
<dd><p class="first last">Probability distribution for sampling location of decision pixel-pairs
around keypoints.</p>
</dd>
<dt><strong>sample_seed</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Seed for the random sampling of the decision pixel-pairs. From a square
window with length <cite>patch_size</cite>, pixel pairs are sampled using the
<cite>mode</cite> parameter to build the descriptors using intensity comparison.
The value of <cite>sample_seed</cite> must be the same for the images to be
matched while building the descriptors.</p>
</dd>
<dt><strong>sigma</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Standard deviation of the Gaussian low-pass filter applied to the image
to alleviate noise sensitivity, which is strongly recommended to obtain
discriminative and good descriptors.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="p">(</span><span class="n">corner_harris</span><span class="p">,</span> <span class="n">corner_peaks</span><span class="p">,</span> <span class="n">BRIEF</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">match_descriptors</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square1</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square1</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square2</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square2</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints1</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">square1</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints2</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">square2</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extractor</span> <span class="o">=</span> <span class="n">BRIEF</span><span class="p">(</span><span class="n">patch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">square1</span><span class="p">,</span> <span class="n">keypoints1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descriptors1</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">descriptors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">square2</span><span class="p">,</span> <span class="n">keypoints2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descriptors2</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">descriptors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span> <span class="o">=</span> <span class="n">match_descriptors</span><span class="p">(</span><span class="n">descriptors1</span><span class="p">,</span> <span class="n">descriptors2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span>
<span class="go">array([[0, 0],</span>
<span class="go">       [1, 1],</span>
<span class="go">       [2, 2],</span>
<span class="go">       [3, 3]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints1</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 5],</span>
<span class="go">       [5, 2],</span>
<span class="go">       [5, 5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints2</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 6],</span>
<span class="go">       [6, 2],</span>
<span class="go">       [6, 6]])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>descriptors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(Q, <cite>descriptor_size</cite>) array of dtype bool</span></dt>
<dd><p class="first last">2D ndarray of binary descriptors of size <cite>descriptor_size</cite> for Q
keypoints after filtering out border keypoints with value at an
index <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> either being <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code> representing
the outcome of the intensity comparison for i-th keypoint on j-th
decision pixel-pair. It is <code class="docutils literal notranslate"><span class="pre">Q</span> <span class="pre">==</span> <span class="pre">np.sum(mask)</span></code>.</p>
</dd>
<dt><strong>mask</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array of dtype bool</span></dt>
<dd><p class="first last">Mask indicating whether a keypoint has been filtered out
(<code class="docutils literal notranslate"><span class="pre">False</span></code>) or is described in the <cite>descriptors</cite> array (<code class="docutils literal notranslate"><span class="pre">True</span></code>).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skimage.feature.BRIEF.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>descriptor_size=256</em>, <em>patch_size=49</em>, <em>mode='normal'</em>, <em>sigma=1</em>, <em>sample_seed=1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/brief.py#L114"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.BRIEF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.BRIEF.extract">
<code class="descname">extract</code><span class="sig-paren">(</span><em>image</em>, <em>keypoints</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/brief.py#L130"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.BRIEF.extract" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract BRIEF binary descriptors for given keypoints in image.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>keypoints</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) array</span></dt>
<dd><p class="first last">Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="censure">
<h2><a class="reference internal" href="#skimage.feature.CENSURE" title="skimage.feature.CENSURE"><code class="xref py py-class docutils literal notranslate"><span class="pre">CENSURE</span></code></a><a class="headerlink" href="#censure" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.CENSURE">
<em class="property">class </em><code class="descclassname">skimage.feature.</code><code class="descname">CENSURE</code><span class="sig-paren">(</span><em>min_scale=1</em>, <em>max_scale=7</em>, <em>mode='DoB'</em>, <em>non_max_threshold=0.15</em>, <em>line_threshold=10</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/censure.py#L111"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.CENSURE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.FeatureDetector</span></code></p>
<p>CENSURE keypoint detector.</p>
<dl class="docutils">
<dt>min_scale <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>Minimum scale to extract keypoints from.</dd>
<dt>max_scale <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd>Maximum scale to extract keypoints from. The keypoints will be
extracted from all the scales except the first and the last i.e.
from the scales in the range [min_scale + 1, max_scale - 1]. The filter
sizes for different scales is such that the two adjacent scales
comprise of an octave.</dd>
<dt>mode <span class="classifier-delimiter">:</span> <span class="classifier">{‘DoB’, ‘Octagon’, ‘STAR’}, optional</span></dt>
<dd>Type of bi-level filter used to get the scales of the input image.
Possible values are ‘DoB’, ‘Octagon’ and ‘STAR’. The three modes
represent the shape of the bi-level filters i.e. box(square), octagon
and star respectively. For instance, a bi-level octagon filter consists
of a smaller inner octagon and a larger outer octagon with the filter
weights being uniformly negative in both the inner octagon while
uniformly positive in the difference region. Use STAR and Octagon for
better features and DoB for better performance.</dd>
<dt>non_max_threshold <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd>Threshold value used to suppress maximas and minimas with a weak
magnitude response obtained after Non-Maximal Suppression.</dd>
<dt>line_threshold <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd>Threshold for rejecting interest points which have ratio of principal
curvatures greater than this value.</dd>
</dl>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="recc8560c357f-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id60">[1]</a></td><td>Motilal Agrawal, Kurt Konolige and Morten Rufus Blas
“CENSURE: Center Surround Extremas for Realtime Feature
Detection and Matching”,
<a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-540-88693-8_8">https://link.springer.com/chapter/10.1007/978-3-540-88693-8_8</a>
<a class="reference external" href="https://doi.org/10.1007/978-3-540-88693-8_8">DOI:10.1007/978-3-540-88693-8_8</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="recc8560c357f-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id61">[2]</a></td><td>Adam Schmidt, Marek Kraft, Michal Fularz and Zuzanna Domagala
“Comparative Assessment of Point Feature Detectors and
Descriptors in the Context of Robot Navigation”
<a class="reference external" href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-268aaf28-0faf-4872-a4df-7e2e61cb364c/c/Schmidt_comparative.pdf">http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-268aaf28-0faf-4872-a4df-7e2e61cb364c/c/Schmidt_comparative.pdf</a>
<a class="reference external" href="https://doi.org/10.1.1.465.1117">DOI:10.1.1.465.1117</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="k">import</span> <span class="n">astronaut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="k">import</span> <span class="n">rgb2gray</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">CENSURE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">astronaut</span><span class="p">()[</span><span class="mi">100</span><span class="p">:</span><span class="mi">300</span><span class="p">,</span> <span class="mi">100</span><span class="p">:</span><span class="mi">300</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span> <span class="o">=</span> <span class="n">CENSURE</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span><span class="o">.</span><span class="n">keypoints</span>
<span class="go">array([[  4, 148],</span>
<span class="go">       [ 12,  73],</span>
<span class="go">       [ 21, 176],</span>
<span class="go">       [ 91,  22],</span>
<span class="go">       [ 93,  56],</span>
<span class="go">       [ 94,  22],</span>
<span class="go">       [ 95,  54],</span>
<span class="go">       [100,  51],</span>
<span class="go">       [103,  51],</span>
<span class="go">       [106,  67],</span>
<span class="go">       [108,  15],</span>
<span class="go">       [117,  20],</span>
<span class="go">       [122,  60],</span>
<span class="go">       [125,  37],</span>
<span class="go">       [129,  37],</span>
<span class="go">       [133,  76],</span>
<span class="go">       [145,  44],</span>
<span class="go">       [146,  94],</span>
<span class="go">       [150, 114],</span>
<span class="go">       [153,  33],</span>
<span class="go">       [154, 156],</span>
<span class="go">       [155, 151],</span>
<span class="go">       [184,  63]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span><span class="o">.</span><span class="n">scales</span>
<span class="go">array([2, 6, 6, 2, 4, 3, 2, 3, 2, 6, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 4, 2, 2])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>keypoints</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) array</span></dt>
<dd><p class="first last">Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>scales</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array</span></dt>
<dd><p class="first last">Corresponding scales.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skimage.feature.CENSURE.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>min_scale=1</em>, <em>max_scale=7</em>, <em>mode='DoB'</em>, <em>non_max_threshold=0.15</em>, <em>line_threshold=10</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/censure.py#L197"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.CENSURE.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.CENSURE.detect">
<code class="descname">detect</code><span class="sig-paren">(</span><em>image</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/censure.py#L217"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.CENSURE.detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect CENSURE keypoints along with the corresponding scale.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D ndarray</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="orb">
<h2><a class="reference internal" href="#skimage.feature.ORB" title="skimage.feature.ORB"><code class="xref py py-class docutils literal notranslate"><span class="pre">ORB</span></code></a><a class="headerlink" href="#orb" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.ORB">
<em class="property">class </em><code class="descclassname">skimage.feature.</code><code class="descname">ORB</code><span class="sig-paren">(</span><em>downscale=1.2</em>, <em>n_scales=8</em>, <em>n_keypoints=500</em>, <em>fast_n=9</em>, <em>fast_threshold=0.08</em>, <em>harris_k=0.04</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/orb.py#L22"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.FeatureDetector</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.DescriptorExtractor</span></code></p>
<p>Oriented FAST and rotated BRIEF feature detector and binary descriptor
extractor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_keypoints</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of keypoints to be returned. The function will return the best
<cite>n_keypoints</cite> according to the Harris corner response if more than
<cite>n_keypoints</cite> are detected. If not, then all the detected keypoints
are returned.</p>
</dd>
<dt><strong>fast_n</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">The <cite>n</cite> parameter in <cite>skimage.feature.corner_fast</cite>. Minimum number of
consecutive pixels out of 16 pixels on the circle that should all be
either brighter or darker w.r.t test-pixel. A point c on the circle is
darker w.r.t test pixel p if <code class="docutils literal notranslate"><span class="pre">Ic</span> <span class="pre">&lt;</span> <span class="pre">Ip</span> <span class="pre">-</span> <span class="pre">threshold</span></code> and brighter if
<code class="docutils literal notranslate"><span class="pre">Ic</span> <span class="pre">&gt;</span> <span class="pre">Ip</span> <span class="pre">+</span> <span class="pre">threshold</span></code>. Also stands for the n in <code class="docutils literal notranslate"><span class="pre">FAST-n</span></code> corner
detector.</p>
</dd>
<dt><strong>fast_threshold</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">The <code class="docutils literal notranslate"><span class="pre">threshold</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">feature.corner_fast</span></code>. Threshold used
to decide whether the pixels on the circle are brighter, darker or
similar w.r.t. the test pixel. Decrease the threshold when more
corners are desired and vice-versa.</p>
</dd>
<dt><strong>harris_k</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">The <cite>k</cite> parameter in <cite>skimage.feature.corner_harris</cite>. Sensitivity
factor to separate corners from edges, typically in range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0.2]</span></code>.
Small values of <cite>k</cite> result in detection of sharp corners.</p>
</dd>
<dt><strong>downscale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Downscale factor for the image pyramid. Default value 1.2 is chosen so
that there are more dense scales which enable robust scale invariance
for a subsequent feature description.</p>
</dd>
<dt><strong>n_scales</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Maximum number of scales from the bottom of the image pyramid to
extract the features from.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rb3ecaf5c48ec-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id62">[1]</a></td><td>Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski
“ORB: An efficient alternative to SIFT and SURF”
<a class="reference external" href="http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf">http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf</a></td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">ORB</span><span class="p">,</span> <span class="n">match_descriptors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">img1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span><span class="p">[</span><span class="mi">40</span><span class="p">:</span><span class="mi">60</span><span class="p">,</span> <span class="mi">40</span><span class="p">:</span><span class="mi">60</span><span class="p">]</span> <span class="o">=</span> <span class="n">square</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span><span class="p">[</span><span class="mi">53</span><span class="p">:</span><span class="mi">73</span><span class="p">,</span> <span class="mi">53</span><span class="p">:</span><span class="mi">73</span><span class="p">]</span> <span class="o">=</span> <span class="n">square</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor1</span> <span class="o">=</span> <span class="n">ORB</span><span class="p">(</span><span class="n">n_keypoints</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor2</span> <span class="o">=</span> <span class="n">ORB</span><span class="p">(</span><span class="n">n_keypoints</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor1</span><span class="o">.</span><span class="n">detect_and_extract</span><span class="p">(</span><span class="n">img1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor2</span><span class="o">.</span><span class="n">detect_and_extract</span><span class="p">(</span><span class="n">img2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span> <span class="o">=</span> <span class="n">match_descriptors</span><span class="p">(</span><span class="n">detector_extractor1</span><span class="o">.</span><span class="n">descriptors</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">detector_extractor2</span><span class="o">.</span><span class="n">descriptors</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span>
<span class="go">array([[0, 0],</span>
<span class="go">       [1, 1],</span>
<span class="go">       [2, 2],</span>
<span class="go">       [3, 3],</span>
<span class="go">       [4, 4]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor1</span><span class="o">.</span><span class="n">keypoints</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="go">array([[ 42.,  40.],</span>
<span class="go">       [ 47.,  58.],</span>
<span class="go">       [ 44.,  40.],</span>
<span class="go">       [ 59.,  42.],</span>
<span class="go">       [ 45.,  44.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor2</span><span class="o">.</span><span class="n">keypoints</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="go">array([[ 55.,  53.],</span>
<span class="go">       [ 60.,  71.],</span>
<span class="go">       [ 57.,  53.],</span>
<span class="go">       [ 72.,  55.],</span>
<span class="go">       [ 58.,  57.]])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>keypoints</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) array</span></dt>
<dd><p class="first last">Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>scales</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array</span></dt>
<dd><p class="first last">Corresponding scales.</p>
</dd>
<dt><strong>orientations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array</span></dt>
<dd><p class="first last">Corresponding orientations in radians.</p>
</dd>
<dt><strong>responses</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array</span></dt>
<dd><p class="first last">Corresponding Harris corner responses.</p>
</dd>
<dt><strong>descriptors</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(Q, <cite>descriptor_size</cite>) array of dtype bool</span></dt>
<dd><p class="first last">2D array of binary descriptors of size <cite>descriptor_size</cite> for Q
keypoints after filtering out border keypoints with value at an
index <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> either being <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code> representing
the outcome of the intensity comparison for i-th keypoint on j-th
decision pixel-pair. It is <code class="docutils literal notranslate"><span class="pre">Q</span> <span class="pre">==</span> <span class="pre">np.sum(mask)</span></code>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skimage.feature.ORB.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>downscale=1.2</em>, <em>n_scales=8</em>, <em>n_keypoints=500</em>, <em>fast_n=9</em>, <em>fast_threshold=0.08</em>, <em>harris_k=0.04</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/orb.py#L117"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.ORB.detect">
<code class="descname">detect</code><span class="sig-paren">(</span><em>image</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/orb.py#L162"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect oriented FAST keypoints along with the corresponding scale.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.ORB.detect_and_extract">
<code class="descname">detect_and_extract</code><span class="sig-paren">(</span><em>image</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/orb.py#L277"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.detect_and_extract" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect oriented FAST keypoints and extract rBRIEF descriptors.</p>
<p>Note that this is faster than first calling <cite>detect</cite> and then
<cite>extract</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.ORB.extract">
<code class="descname">extract</code><span class="sig-paren">(</span><em>image</em>, <em>keypoints</em>, <em>scales</em>, <em>orientations</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.15.0/skimage/feature/orb.py#L223"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.extract" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract rBRIEF binary descriptors for given keypoints in image.</p>
<p>Note that the keypoints must be extracted using the same <cite>downscale</cite>
and <cite>n_scales</cite> parameters. Additionally, if you want to extract both
keypoints and descriptors you should use the faster
<cite>detect_and_extract</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>image</strong> <span class="classifier-delimiter">:</span> <span class="classifier">2D array</span></dt>
<dd><p class="first last">Input image.</p>
</dd>
<dt><strong>keypoints</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, 2) array</span></dt>
<dd><p class="first last">Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>scales</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array</span></dt>
<dd><p class="first last">Corresponding scales.</p>
</dd>
<dt><strong>orientations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">(N, ) array</span></dt>
<dd><p class="first last">Corresponding orientations in radians.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


        </div>
    </div>
    <div class="well footer">
        <small>
            &copy; Copyright the scikit-image development team.
            Created using <a href="http://getbootstrap.com/">Bootstrap</a> and <a href="http://sphinx-doc.org/">Sphinx</a>.
        </small>
    </div>
</body>
</html>


<!-- Piwik -->
<script type="text/javascript">
  var _paq = _paq || [];
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//piwik.sciunto.org/piwik/";
    _paq.push(['setTrackerUrl', u+'piwik.php']);
    _paq.push(['setSiteId', 2]);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<noscript><p><img src="//piwik.sciunto.org/piwik/piwik.php?idsite=2" style="border:0;" alt="" /></p></noscript>
<!-- End Piwik Code -->