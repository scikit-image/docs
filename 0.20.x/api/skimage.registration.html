
<!DOCTYPE html>
<html lang="en">
<head>
        <title>Module: registration &mdash; skimage v0.20.0 docs</title><meta name="generator" content="Docutils 0.18: http://docutils.sourceforge.net/" />

    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link href="../_static/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="../_static/css/custom.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
        <link rel="stylesheet" href="../_static/none" type="text/css" />
        <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
        <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
        <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
        <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
        <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
        <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
    
    <script src="https://code.jquery.com/jquery-latest.js"></script>
    <script src="../_static/js/bootstrap.min.js"></script>
    <script src="../_static/js/togglebutton.js"></script>
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.20.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        LINK_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script>
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="index" title="Index" href="../genindex.html" />
        <link rel="search" title="Search" href="../search.html" />
        <link rel="top" title="skimage v0.20.0 docs" href="../index.html" />
        <link rel="up" title="API Reference for skimage 0.20.0" href="api.html" />
        <link rel="next" title="Module: restoration" href="skimage.restoration.html" />
        <link rel="prev" title="Module: morphology" href="skimage.morphology.html" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
    <link rel="shortcut icon" href="../_static/favicon.ico">
    <!-- Plausible analytics -->
    <script async defer data-domain="scikit-image.org" src="https://plausible.io/js/plausible.outbound-links.js"></script>
</head>
<body class="container">
    <a href="https://scikit-image.org" class="logo"><img src="../_static/img/logo.png" alt=""></a>
    <div class="clearfix"></div>
    <div class="navbar">
        <div class="navbar-inner">
            <ul class="nav">
                <li><a href="/docs/stable/install.html">Installation</a></li>
<li><a href="../auto_examples/index.html">Gallery</a></li>
<li><a href="../index.html">Documentation</a></li>
<li><a href="/community_guidelines.html">Community</a></li>

<li><a href="https://github.com/scikit-image/scikit-image">
    <img src="../_static/GitHub-Mark-32px.png"
        style="height: 15px; width: 15px;
               display: inline; float: none;
               padding-bottom: 3px;">
    Source</a>
</li>
            </ul>
        </div>
    </div>
    <div class="row">
        <div class="span3"><div style="padding-bottom: 3em">
  <form class="navbar-form pull-right" action="../search.html" method="get">
    <input type="text" class="search span3" name="q" placeholder="Search documentation ...">
    <input type="hidden" name="check_keywords" value="yes" >
    <input type="hidden" name="area" value="default" >
  </form>
</div><!-- 
        <h4 class="sidebar-box-heading">Contents</h4>
        <div class="well sidebar-box toc">
            <ul class="nav nav-list">
<li><a class="reference internal" href="#">Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">registration</span></code></a><ul class="nav nav-list">
<li><a class="reference internal" href="#optical-flow-ilk">optical_flow_ilk</a><ul class="nav nav-list">
<li><a class="reference internal" href="#skimage.registration.optical_flow_ilk"><code class="docutils literal notranslate"><span class="pre">optical_flow_ilk()</span></code></a></li>
<li><a class="reference internal" href="#examples-using-skimage-registration-optical-flow-ilk">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.registration.optical_flow_ilk</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#optical-flow-tvl1">optical_flow_tvl1</a><ul class="nav nav-list">
<li><a class="reference internal" href="#skimage.registration.optical_flow_tvl1"><code class="docutils literal notranslate"><span class="pre">optical_flow_tvl1()</span></code></a></li>
<li><a class="reference internal" href="#examples-using-skimage-registration-optical-flow-tvl1">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.registration.optical_flow_tvl1</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#phase-cross-correlation">phase_cross_correlation</a><ul class="nav nav-list">
<li><a class="reference internal" href="#skimage.registration.phase_cross_correlation"><code class="docutils literal notranslate"><span class="pre">phase_cross_correlation()</span></code></a></li>
<li><a class="reference internal" href="#examples-using-skimage-registration-phase-cross-correlation">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.registration.phase_cross_correlation</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>


 --><div class="well">
    <strong>Docs for 0.20.0<br></strong>

    <a id="other">All versions</a>

    <ul id="versionList" style="display: none;">
        <script src="../../dev/_static/docversions.js"></script>
        <script type="text/javascript">
            insert_version_links();
        </script>
    </ul>

 </div>

<script type="text/javascript">
	$("#other").click(function() {
		$("#versionList").toggle();
	});
</script>
        </div>
        <div class="span9" class="body" role="main">
            
  <section id="module-skimage.registration">
<span id="module-registration"></span><h1>Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">registration</span></code><a class="headerlink" href="#module-skimage.registration" title="Permalink to this heading">¶</a></h1>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.registration.optical_flow_ilk" title="skimage.registration.optical_flow_ilk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.registration.optical_flow_ilk</span></code></a>(...[, ...])</p></td>
<td><p>Coarse to fine optical flow estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.registration.optical_flow_tvl1" title="skimage.registration.optical_flow_tvl1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.registration.optical_flow_tvl1</span></code></a>(...)</p></td>
<td><p>Coarse to fine optical flow estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.registration.phase_cross_correlation" title="skimage.registration.phase_cross_correlation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.registration.phase_cross_correlation</span></code></a>(...)</p></td>
<td><p>Efficient subpixel image translation registration by cross-correlation.</p></td>
</tr>
</tbody>
</table>
<section id="optical-flow-ilk">
<h2>optical_flow_ilk<a class="headerlink" href="#optical-flow-ilk" title="Permalink to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="skimage.registration.optical_flow_ilk">
<span class="sig-prename descclassname"><span class="pre">skimage.registration.</span></span><span class="sig-name descname"><span class="pre">optical_flow_ilk</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reference_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius=7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_warp=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaussian=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefilter=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.20.0/skimage/registration/_optical_flow.py#L310-L384"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.registration.optical_flow_ilk" title="Permalink to this definition">¶</a></dt>
<dd><p>Coarse to fine optical flow estimator.</p>
<p>The iterative Lucas-Kanade (iLK) solver is applied at each level
of the image pyramid. iLK <a class="reference internal" href="#r8ab46b4fab1c-1" id="id1">[1]</a> is a fast and robust alternative to
TVL1 algorithm although less accurate for rendering flat surfaces
and object boundaries (see <a class="reference internal" href="#r8ab46b4fab1c-2" id="id2">[2]</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>reference_image</strong><span class="classifier">ndarray, shape (M, N[, P[, …]])</span></dt><dd><p>The first gray scale image of the sequence.</p>
</dd>
<dt><strong>moving_image</strong><span class="classifier">ndarray, shape (M, N[, P[, …]])</span></dt><dd><p>The second gray scale image of the sequence.</p>
</dd>
<dt><strong>radius</strong><span class="classifier">int, optional</span></dt><dd><p>Radius of the window considered around each pixel.</p>
</dd>
<dt><strong>num_warp</strong><span class="classifier">int, optional</span></dt><dd><p>Number of times moving_image is warped.</p>
</dd>
<dt><strong>gaussian</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, a Gaussian kernel is used for the local
integration. Otherwise, a uniform kernel is used.</p>
</dd>
<dt><strong>prefilter</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to prefilter the estimated optical flow before each
image warp. When True, a median filter with window size 3
along each axis is applied. This helps to remove potential
outliers.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">dtype, optional</span></dt><dd><p>Output data type: must be floating point. Single precision
provides good results and saves memory usage and computation
time compared to double precision.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>flow</strong><span class="classifier">ndarray, shape ((reference_image.ndim, M, N[, P[, …]])</span></dt><dd><p>The estimated optical flow components for each axis.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>The implemented algorithm is described in <strong>Table2</strong> of <a class="reference internal" href="#r8ab46b4fab1c-1" id="id3">[1]</a>.</p></li>
<li><p>Color images are not supported.</p></li>
</ul>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r8ab46b4fab1c-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id3">2</a>)</span>
<p>Le Besnerais, G., &amp; Champagnat, F. (2005, September). Dense
optical flow by iterative local window registration. In IEEE
International Conference on Image Processing 2005 (Vol. 1,
pp. I-137). IEEE. <a class="reference external" href="https://doi.org/10.1109/ICIP.2005.1529706">DOI:10.1109/ICIP.2005.1529706</a></p>
</div>
<div class="citation" id="r8ab46b4fab1c-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Plyer, A., Le Besnerais, G., &amp; Champagnat,
F. (2016). Massively parallel Lucas Kanade optical flow for
real-time video processing applications. Journal of Real-Time
Image Processing, 11(4), 713-730. <a class="reference external" href="https://doi.org/10.1007/s11554-014-0423-0">DOI:10.1007/s11554-014-0423-0</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">rgb2gray</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">stereo_motorcycle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.registration</span> <span class="kn">import</span> <span class="n">optical_flow_ilk</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference_image</span><span class="p">,</span> <span class="n">moving_image</span><span class="p">,</span> <span class="n">disp</span> <span class="o">=</span> <span class="n">stereo_motorcycle</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># --- Convert the images to gray level: color is not supported.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference_image</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">reference_image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">moving_image</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">moving_image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flow</span> <span class="o">=</span> <span class="n">optical_flow_ilk</span><span class="p">(</span><span class="n">moving_image</span><span class="p">,</span> <span class="n">reference_image</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<section id="examples-using-skimage-registration-optical-flow-ilk">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.registration.optical_flow_ilk</span></code><a class="headerlink" href="#examples-using-skimage-registration-optical-flow-ilk" title="Permalink to this heading">¶</a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Demonstration of image registration using optical flow."><img alt="Registration using optical flow" src="../_images/sphx_glr_plot_opticalflow_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py"><span class="std std-ref">Registration using optical flow</span></a></p>
  <div class="sphx-glr-thumbnail-title">Registration using optical flow</div>
</div></div></section>
</section>
<section id="optical-flow-tvl1">
<h2>optical_flow_tvl1<a class="headerlink" href="#optical-flow-tvl1" title="Permalink to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="skimage.registration.optical_flow_tvl1">
<span class="sig-prename descclassname"><span class="pre">skimage.registration.</span></span><span class="sig-name descname"><span class="pre">optical_flow_tvl1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reference_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attachment=15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tightness=0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_warp=5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iter=10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol=0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefilter=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.20.0/skimage/registration/_optical_flow.py#L143-L228"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.registration.optical_flow_tvl1" title="Permalink to this definition">¶</a></dt>
<dd><p>Coarse to fine optical flow estimator.</p>
<p>The TV-L1 solver is applied at each level of the image
pyramid. TV-L1 is a popular algorithm for optical flow estimation
introduced by Zack et al. <a class="reference internal" href="#rda1bf5cbeff5-1" id="id6">[1]</a>, improved in <a class="reference internal" href="#rda1bf5cbeff5-2" id="id7">[2]</a> and detailed in <a class="reference internal" href="#rda1bf5cbeff5-3" id="id8">[3]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>reference_image</strong><span class="classifier">ndarray, shape (M, N[, P[, …]])</span></dt><dd><p>The first gray scale image of the sequence.</p>
</dd>
<dt><strong>moving_image</strong><span class="classifier">ndarray, shape (M, N[, P[, …]])</span></dt><dd><p>The second gray scale image of the sequence.</p>
</dd>
<dt><strong>attachment</strong><span class="classifier">float, optional</span></dt><dd><p>Attachment parameter (<span class="math notranslate nohighlight">\(\lambda\)</span> in <a class="reference internal" href="#rda1bf5cbeff5-1" id="id9">[1]</a>). The smaller
this parameter is, the smoother the returned result will be.</p>
</dd>
<dt><strong>tightness</strong><span class="classifier">float, optional</span></dt><dd><p>Tightness parameter (<span class="math notranslate nohighlight">\(\tau\)</span> in <a class="reference internal" href="#rda1bf5cbeff5-1" id="id10">[1]</a>). It should have
a small value in order to maintain attachment and
regularization parts in correspondence.</p>
</dd>
<dt><strong>num_warp</strong><span class="classifier">int, optional</span></dt><dd><p>Number of times moving_image is warped.</p>
</dd>
<dt><strong>num_iter</strong><span class="classifier">int, optional</span></dt><dd><p>Number of fixed point iteration.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, optional</span></dt><dd><p>Tolerance used as stopping criterion based on the L² distance
between two consecutive values of (u, v).</p>
</dd>
<dt><strong>prefilter</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to prefilter the estimated optical flow before each
image warp. When True, a median filter with window size 3
along each axis is applied. This helps to remove potential
outliers.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">dtype, optional</span></dt><dd><p>Output data type: must be floating point. Single precision
provides good results and saves memory usage and computation
time compared to double precision.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>flow</strong><span class="classifier">ndarray, shape ((image0.ndim, M, N[, P[, …]])</span></dt><dd><p>The estimated optical flow components for each axis.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Color images are not supported.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rda1bf5cbeff5-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id6">1</a>,<a role="doc-backlink" href="#id9">2</a>,<a role="doc-backlink" href="#id10">3</a>)</span>
<p>Zach, C., Pock, T., &amp; Bischof, H. (2007, September). A
duality based approach for realtime TV-L 1 optical flow. In Joint
pattern recognition symposium (pp. 214-223). Springer, Berlin,
Heidelberg. <a class="reference external" href="https://doi.org/10.1007/978-3-540-74936-3_22">DOI:10.1007/978-3-540-74936-3_22</a></p>
</div>
<div class="citation" id="rda1bf5cbeff5-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">2</a><span class="fn-bracket">]</span></span>
<p>Wedel, A., Pock, T., Zach, C., Bischof, H., &amp; Cremers,
D. (2009). An improved algorithm for TV-L 1 optical flow. In
Statistical and geometrical approaches to visual motion analysis
(pp. 23-45). Springer, Berlin, Heidelberg.
<a class="reference external" href="https://doi.org/10.1007/978-3-642-03061-1_2">DOI:10.1007/978-3-642-03061-1_2</a></p>
</div>
<div class="citation" id="rda1bf5cbeff5-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">3</a><span class="fn-bracket">]</span></span>
<p>Pérez, J. S., Meinhardt-Llopis, E., &amp; Facciolo,
G. (2013). TV-L1 optical flow estimation. Image Processing On
Line, 2013, 137-150. <a class="reference external" href="https://doi.org/10.5201/ipol.2013.26">DOI:10.5201/ipol.2013.26</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">rgb2gray</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">stereo_motorcycle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.registration</span> <span class="kn">import</span> <span class="n">optical_flow_tvl1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image0</span><span class="p">,</span> <span class="n">image1</span><span class="p">,</span> <span class="n">disp</span> <span class="o">=</span> <span class="n">stereo_motorcycle</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># --- Convert the images to gray level: color is not supported.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image0</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">image0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image1</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">image1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flow</span> <span class="o">=</span> <span class="n">optical_flow_tvl1</span><span class="p">(</span><span class="n">image1</span><span class="p">,</span> <span class="n">image0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<section id="examples-using-skimage-registration-optical-flow-tvl1">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.registration.optical_flow_tvl1</span></code><a class="headerlink" href="#examples-using-skimage-registration-optical-flow-tvl1" title="Permalink to this heading">¶</a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Demonstration of image registration using optical flow."><img alt="Registration using optical flow" src="../_images/sphx_glr_plot_opticalflow_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py"><span class="std std-ref">Registration using optical flow</span></a></p>
  <div class="sphx-glr-thumbnail-title">Registration using optical flow</div>
</div></div></section>
</section>
<section id="phase-cross-correlation">
<h2>phase_cross_correlation<a class="headerlink" href="#phase-cross-correlation" title="Permalink to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="skimage.registration.phase_cross_correlation">
<span class="sig-prename descclassname"><span class="pre">skimage.registration.</span></span><span class="sig-name descname"><span class="pre">phase_cross_correlation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reference_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_image</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upsample_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'real'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disambiguate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_error</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">moving_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'phase'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.20.0/skimage/registration/_phase_cross_correlation.py#L182-L418"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.registration.phase_cross_correlation" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient subpixel image translation registration by cross-correlation.</p>
<p>This code gives the same precision as the FFT upsampled cross-correlation
in a fraction of the computation time and with reduced memory requirements.
It obtains an initial estimate of the cross-correlation peak by an FFT and
then refines the shift estimation by upsampling the DFT only in a small
neighborhood of that estimate by means of a matrix-multiply DFT <a class="reference internal" href="#r065f4156fcfd-1" id="id14">[1]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>reference_image</strong><span class="classifier">array</span></dt><dd><p>Reference image.</p>
</dd>
<dt><strong>moving_image</strong><span class="classifier">array</span></dt><dd><p>Image to register. Must be same dimensionality as
<code class="docutils literal notranslate"><span class="pre">reference_image</span></code>.</p>
</dd>
<dt><strong>upsample_factor</strong><span class="classifier">int, optional</span></dt><dd><p>Upsampling factor. Images will be registered to within
<code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">upsample_factor</span></code> of a pixel. For example
<code class="docutils literal notranslate"><span class="pre">upsample_factor</span> <span class="pre">==</span> <span class="pre">20</span></code> means the images will be registered
within 1/20th of a pixel. Default is 1 (no upsampling).
Not used if any of <code class="docutils literal notranslate"><span class="pre">reference_mask</span></code> or <code class="docutils literal notranslate"><span class="pre">moving_mask</span></code> is not None.</p>
</dd>
<dt><strong>space</strong><span class="classifier">string, one of “real” or “fourier”, optional</span></dt><dd><p>Defines how the algorithm interprets input data. “real” means
data will be FFT’d to compute the correlation, while “fourier”
data will bypass FFT of input data. Case insensitive. Not
used if any of <code class="docutils literal notranslate"><span class="pre">reference_mask</span></code> or <code class="docutils literal notranslate"><span class="pre">moving_mask</span></code> is not
None.</p>
</dd>
<dt><strong>disambiguate</strong><span class="classifier">bool</span></dt><dd><p>The shift returned by this function is only accurate <em>modulo</em> the
image shape, due to the periodic nature of the Fourier transform. If
this parameter is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <em>real</em> space cross-correlation
is computed for each possible shift, and the shift with the highest
cross-correlation within the overlapping area is returned.</p>
</dd>
<dt><strong>return_error</strong><span class="classifier">bool, {“always”}, optional</span></dt><dd><p>Returns error and phase difference if “always” is given. If False, or
either <code class="docutils literal notranslate"><span class="pre">reference_mask</span></code> or <code class="docutils literal notranslate"><span class="pre">moving_mask</span></code> are given, only the shift
is returned.</p>
</dd>
<dt><strong>reference_mask</strong><span class="classifier">ndarray</span></dt><dd><p>Boolean mask for <code class="docutils literal notranslate"><span class="pre">reference_image</span></code>. The mask should evaluate
to <code class="docutils literal notranslate"><span class="pre">True</span></code> (or 1) on valid pixels. <code class="docutils literal notranslate"><span class="pre">reference_mask</span></code> should
have the same shape as <code class="docutils literal notranslate"><span class="pre">reference_image</span></code>.</p>
</dd>
<dt><strong>moving_mask</strong><span class="classifier">ndarray or None, optional</span></dt><dd><p>Boolean mask for <code class="docutils literal notranslate"><span class="pre">moving_image</span></code>. The mask should evaluate to <code class="docutils literal notranslate"><span class="pre">True</span></code>
(or 1) on valid pixels. <code class="docutils literal notranslate"><span class="pre">moving_mask</span></code> should have the same shape
as <code class="docutils literal notranslate"><span class="pre">moving_image</span></code>. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">reference_mask</span></code> will be used.</p>
</dd>
<dt><strong>overlap_ratio</strong><span class="classifier">float, optional</span></dt><dd><p>Minimum allowed overlap ratio between images. The correlation for
translations corresponding with an overlap ratio lower than this
threshold will be ignored. A lower <em class="xref py py-obj">overlap_ratio</em> leads to smaller
maximum translation, while a higher <em class="xref py py-obj">overlap_ratio</em> leads to greater
robustness against spurious matches due to small overlap between
masked images. Used only if one of <code class="docutils literal notranslate"><span class="pre">reference_mask</span></code> or
<code class="docutils literal notranslate"><span class="pre">moving_mask</span></code> is not None.</p>
</dd>
<dt><strong>normalization</strong><span class="classifier">{“phase”, None}</span></dt><dd><p>The type of normalization to apply to the cross-correlation. This
parameter is unused when masks (<em class="xref py py-obj">reference_mask</em> and <em class="xref py py-obj">moving_mask</em>) are
supplied.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>shift</strong><span class="classifier">ndarray</span></dt><dd><p>Shift vector (in pixels) required to register <code class="docutils literal notranslate"><span class="pre">moving_image</span></code>
with <code class="docutils literal notranslate"><span class="pre">reference_image</span></code>. Axis ordering is consistent with
the axis order of the input array.</p>
</dd>
<dt><strong>error</strong><span class="classifier">float</span></dt><dd><p>Translation invariant normalized RMS error between
<code class="docutils literal notranslate"><span class="pre">reference_image</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_image</span></code>. For masked cross-correlation
this error is not available and NaN is returned if <code class="docutils literal notranslate"><span class="pre">return_error</span></code>
is “always”.</p>
</dd>
<dt><strong>phasediff</strong><span class="classifier">float</span></dt><dd><p>Global phase difference between the two images (should be
zero if images are non-negative). For masked cross-correlation
this phase difference is not available and NaN is returned if
<code class="docutils literal notranslate"><span class="pre">return_error</span></code> is “always”.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The use of cross-correlation to estimate image translation has a long
history dating back to at least <a class="reference internal" href="#r065f4156fcfd-2" id="id15">[2]</a>. The “phase correlation”
method (selected by <code class="docutils literal notranslate"><span class="pre">normalization=&quot;phase&quot;</span></code>) was first proposed in <a class="reference internal" href="#r065f4156fcfd-3" id="id16">[3]</a>.
Publications <a class="reference internal" href="#r065f4156fcfd-1" id="id17">[1]</a> and <a class="reference internal" href="#r065f4156fcfd-2" id="id18">[2]</a> use an unnormalized cross-correlation
(<code class="docutils literal notranslate"><span class="pre">normalization=None</span></code>). Which form of normalization is better is
application-dependent. For example, the phase correlation method works
well in registering images under different illumination, but is not very
robust to noise. In a high noise scenario, the unnormalized method may be
preferable.</p>
<p>When masks are provided, a masked normalized cross-correlation algorithm is
used <a class="reference internal" href="#r065f4156fcfd-5" id="id19">[5]</a>, <a class="reference internal" href="#r065f4156fcfd-6" id="id20">[6]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r065f4156fcfd-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id14">1</a>,<a role="doc-backlink" href="#id17">2</a>)</span>
<p>Manuel Guizar-Sicairos, Samuel T. Thurman, and James R. Fienup,
“Efficient subpixel image registration algorithms,”
Optics Letters 33, 156-158 (2008). <a class="reference external" href="https://doi.org/10.1364/OL.33.000156">DOI:10.1364/OL.33.000156</a></p>
</div>
<div class="citation" id="r065f4156fcfd-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id15">1</a>,<a role="doc-backlink" href="#id18">2</a>)</span>
<p>P. Anuta, Spatial registration of multispectral and multitemporal
digital imagery using fast Fourier transform techniques, IEEE Trans.
Geosci. Electron., vol. 8, no. 4, pp. 353–368, Oct. 1970.
<a class="reference external" href="https://doi.org/10.1109/TGE.1970.271435">DOI:10.1109/TGE.1970.271435</a>.</p>
</div>
<div class="citation" id="r065f4156fcfd-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id16">3</a><span class="fn-bracket">]</span></span>
<p>C. D. Kuglin D. C. Hines. The phase correlation image alignment
method, Proceeding of IEEE International Conference on Cybernetics
and Society, pp. 163-165, New York, NY, USA, 1975, pp. 163–165.</p>
</div>
<div class="citation" id="r065f4156fcfd-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>James R. Fienup, “Invariant error metrics for image reconstruction”
Optics Letters 36, 8352-8357 (1997). <a class="reference external" href="https://doi.org/10.1364/AO.36.008352">DOI:10.1364/AO.36.008352</a></p>
</div>
<div class="citation" id="r065f4156fcfd-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">5</a><span class="fn-bracket">]</span></span>
<p>Dirk Padfield. Masked Object Registration in the Fourier Domain.
IEEE Transactions on Image Processing, vol. 21(5),
pp. 2706-2718 (2012). <a class="reference external" href="https://doi.org/10.1109/TIP.2011.2181402">DOI:10.1109/TIP.2011.2181402</a></p>
</div>
<div class="citation" id="r065f4156fcfd-6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">6</a><span class="fn-bracket">]</span></span>
<p>D. Padfield. “Masked FFT registration”. In Proc. Computer Vision and
Pattern Recognition, pp. 2918-2925 (2010).
<a class="reference external" href="https://doi.org/10.1109/CVPR.2010.5540032">DOI:10.1109/CVPR.2010.5540032</a></p>
</div>
</div>
</dd></dl>

<section id="examples-using-skimage-registration-phase-cross-correlation">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.registration.phase_cross_correlation</span></code><a class="headerlink" href="#examples-using-skimage-registration-phase-cross-correlation" title="Permalink to this heading">¶</a></h3>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we use phase cross-correlation to identify the relative shift between two simi..."><img alt="Image Registration" src="../_images/sphx_glr_plot_register_translation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_register_translation.html#sphx-glr-auto-examples-registration-plot-register-translation-py"><span class="std std-ref">Image Registration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image Registration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we use the masked normalized cross-correlation to identify the relative shift ..."><img alt="Masked Normalized Cross-Correlation" src="../_images/sphx_glr_plot_masked_register_translation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_masked_register_translation.html#sphx-glr-auto-examples-registration-plot-masked-register-translation-py"><span class="std std-ref">Masked Normalized Cross-Correlation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Masked Normalized Cross-Correlation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Phase correlation (``registration.phase_cross_correlation``) is an efficient method for determi..."><img alt="Using Polar and Log-Polar Transformations for Registration" src="../_images/sphx_glr_plot_register_rotation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_register_rotation.html#sphx-glr-auto-examples-registration-plot-register-rotation-py"><span class="std std-ref">Using Polar and Log-Polar Transformations for Registration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using Polar and Log-Polar Transformations for Registration</div>
</div></div></section>
</section>
</section>


        </div>
    </div>
    <div class="forum link" role="contentinfo">
	 
    </div>
    <div class="well footer" role="contentinfo">
        <small>
            &copy; Copyright the scikit-image development team.
            Created using <a href="https://getbootstrap.com/">Bootstrap</a> and <a href="https://www.sphinx-doc.org/">Sphinx</a>.
        </small>
    </div>
</body>
</html>