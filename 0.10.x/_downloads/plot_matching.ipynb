{
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": [
            "%matplotlib inline"
          ], 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\" id=\"robust-matching-using-ransac\">\n<h1 class=\"title\">Robust matching using RANSAC</h1>\n<p>In this simplified example we first generate two synthetic images as if they\nwere taken from different view points.</p>\n<p>In the next step we find interest points in both images and find\ncorrespondences based on a weighted sum of squared differences of a small\nneighborhood around them. Note, that this measure is only robust towards\nlinear radiometric and not geometric distortions and is thus only usable with\nslight view point changes.</p>\n<p>After finding the correspondences we end up having a set of source and\ndestination coordinates which can be used to estimate the geometric\ntransformation between both images. However, many of the correspondences are\nfaulty and simply estimating the parameter set with all coordinates is not\nsufficient. Therefore, the RANSAC algorithm is used on top of the normal model\nto robustly estimate the parameter set by detecting outliers.</p>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "from __future__ import print_function\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom skimage import data\nfrom skimage.util import img_as_float\nfrom skimage.feature import (corner_harris, corner_subpix, corner_peaks,\n                             plot_matches)\nfrom skimage.transform import warp, AffineTransform\nfrom skimage.exposure import rescale_intensity\nfrom skimage.color import rgb2gray\nfrom skimage.measure import ransac\n\n\n# generate synthetic checkerboard image and add gradient for the later matching\ncheckerboard = img_as_float(data.checkerboard())\nimg_orig = np.zeros(list(checkerboard.shape) + [3])\nimg_orig[..., 0] = checkerboard\ngradient_r, gradient_c = np.mgrid[0:img_orig.shape[0],\n                                  0:img_orig.shape[1]] / float(img_orig.shape[0])\nimg_orig[..., 1] = gradient_r\nimg_orig[..., 2] = gradient_c\nimg_orig = rescale_intensity(img_orig)\nimg_orig_gray = rgb2gray(img_orig)\n\n# warp synthetic image\ntform = AffineTransform(scale=(0.9, 0.9), rotation=0.2, translation=(20, -10))\nimg_warped = warp(img_orig, tform.inverse, output_shape=(200, 200))\nimg_warped_gray = rgb2gray(img_warped)\n\n# extract corners using Harris' corner measure\ncoords_orig = corner_peaks(corner_harris(img_orig_gray), threshold_rel=0.001,\n                           min_distance=5)\ncoords_warped = corner_peaks(corner_harris(img_warped_gray),\n                             threshold_rel=0.001, min_distance=5)\n\n# determine sub-pixel corner position\ncoords_orig_subpix = corner_subpix(img_orig_gray, coords_orig, window_size=9)\ncoords_warped_subpix = corner_subpix(img_warped_gray, coords_warped,\n                                     window_size=9)\n\n\ndef gaussian_weights(window_ext, sigma=1):\n    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]\n    g = np.zeros(y.shape, dtype=np.double)\n    g[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))\n    g /= 2 * np.pi * sigma * sigma\n    return g\n\n\ndef match_corner(coord, window_ext=5):\n    r, c =  np.round(coord).astype(np.intp)\n    window_orig = img_orig[r-window_ext:r+window_ext+1,\n                           c-window_ext:c+window_ext+1, :]\n\n    # weight pixels depending on distance to center pixel\n    weights = gaussian_weights(window_ext, 3)\n    weights = np.dstack((weights, weights, weights))\n\n    # compute sum of squared differences to all corners in warped image\n    SSDs = []\n    for cr, cc in coords_warped:\n        window_warped = img_warped[cr-window_ext:cr+window_ext+1,\n                                   cc-window_ext:cc+window_ext+1, :]\n        SSD = np.sum(weights * (window_orig - window_warped)**2)\n        SSDs.append(SSD)\n\n    # use corner with minimum SSD as correspondence\n    min_idx = np.argmin(SSDs)\n    return coords_warped_subpix[min_idx]\n\n\n# find correspondences using simple weighted sum of squared differences\nsrc = []\ndst = []\nfor coord in coords_orig_subpix:\n    src.append(coord)\n    dst.append(match_corner(coord))\nsrc = np.array(src)\ndst = np.array(dst)\n\n\n# estimate affine transform model using all coordinates\nmodel = AffineTransform()\nmodel.estimate(src, dst)\n\n# robustly estimate affine transform model with RANSAC\nmodel_robust, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n                               residual_threshold=2, max_trials=100)\noutliers = inliers == False\n\n\n# compare \"true\" and estimated transform parameters\nprint(tform.scale, tform.translation, tform.rotation)\nprint(model.scale, model.translation, model.rotation)\nprint(model_robust.scale, model_robust.translation, model_robust.rotation)\n\n# visualize correspondence\nfig, ax = plt.subplots(nrows=2, ncols=1)\n\nplt.gray()\n\ninlier_idxs = np.nonzero(inliers)[0]\nplot_matches(ax[0], img_orig_gray, img_warped_gray, src, dst,\n             np.column_stack((inlier_idxs, inlier_idxs)), matches_color='b')\nax[0].axis('off')\nax[0].set_title('Correct correspondences')\n\noutlier_idxs = np.nonzero(outliers)[0]\nplot_matches(ax[1], img_orig_gray, img_warped_gray, src, dst,\n             np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')\nax[1].axis('off')\nax[1].set_title('Faulty correspondences')\n\nplt.show()", 
          "metadata": {}
        }
      ], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "name": ""
  }
}