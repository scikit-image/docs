{
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": [
            "%matplotlib inline"
          ], 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\" id=\"morphological-filtering\">\n<h1 class=\"title\">Morphological Filtering</h1>\n<p>Morphological image processing is a collection of non-linear operations related\nto the shape or morphology of features in an image, such as boundaries,\nskeletons, etc. In any given technique, we probe an image with a small shape or\ntemplate called a structuring element, which defines the region of interest or\nneighborhood around a pixel.</p>\n<p>In this document we outline the following basic morphological operations:</p>\n<ol class=\"arabic simple\">\n<li>Erosion</li>\n<li>Dilation</li>\n<li>Opening</li>\n<li>Closing</li>\n<li>White Tophat</li>\n<li>Black Tophat</li>\n<li>Skeletonize</li>\n<li>Convex Hull</li>\n</ol>\n<p>To get started, let's load an image using <tt class=\"docutils literal\">io.imread</tt>. Note that morphology\nfunctions only work on gray-scale or binary images, so we set <tt class=\"docutils literal\">as_grey=True</tt>.</p>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nimport matplotlib.pyplot as plt\nfrom skimage.data import data_dir\nfrom skimage.util import img_as_ubyte\nfrom skimage import io\n\nphantom = img_as_ubyte(io.imread(data_dir+'/phantom.png', as_grey=True))\nfig, ax = plt.subplots()\nax.imshow(phantom, cmap=plt.cm.gray)", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>Let's also define a convenience function for plotting comparisons:</p>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\ndef plot_comparison(original, filtered, filter_name):\n\n    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 4))\n    ax1.imshow(original, cmap=plt.cm.gray)\n    ax1.set_title('original')\n    ax1.axis('off')\n    ax2.imshow(filtered, cmap=plt.cm.gray)\n    ax2.set_title(filter_name)\n    ax2.axis('off')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\" id=\"erosion\">\n<h1 class=\"title\">Erosion</h1>\n<p>Morphological <tt class=\"docutils literal\">erosion</tt> sets a pixel at (i, j) to the <em>minimum over all\npixels in the neighborhood centered at (i, j)</em>. The structuring element,\n<tt class=\"docutils literal\">selem</tt>, passed to <tt class=\"docutils literal\">erosion</tt> is a boolean array that describes this\nneighborhood. Below, we use <tt class=\"docutils literal\">disk</tt> to create a circular structuring element,\nwhich we use for most of the following examples.</p>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nfrom skimage.morphology import erosion, dilation, opening, closing, white_tophat\nfrom skimage.morphology import black_tophat, skeletonize, convex_hull_image\nfrom skimage.morphology import disk\n\nselem = disk(6)\neroded = erosion(phantom, selem)\nplot_comparison(phantom, eroded, 'erosion')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>Notice how the white boundary of the image disappears or gets eroded as we\nincrease the size of the disk. Also notice the increase in size of the two\nblack ellipses in the center and the disappearance of the 3 light grey\npatches in the lower part of the image.</p>\n<div class=\"section\" id=\"dilation\">\n<h1>Dilation</h1>\n<p>Morphological <tt class=\"docutils literal\">dilation</tt> sets a pixel at (i, j) to the <em>maximum over all\npixels in the neighborhood centered at (i, j)</em>. Dilation enlarges bright\nregions and shrinks dark regions.</p>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\ndilated = dilation(phantom, selem)\nplot_comparison(phantom, dilated, 'dilation')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>Notice how the white boundary of the image thickens, or gets dilated, as we\nincrease the size of the disk. Also notice the decrease in size of the two\nblack ellipses in the centre, and the thickening of the light grey circle in\nthe center and the 3 patches in the lower part of the image.</p>\n<div class=\"section\" id=\"opening\">\n<h1>Opening</h1>\n<p>Morphological <tt class=\"docutils literal\">opening</tt> on an image is defined as an <em>erosion followed by a\ndilation</em>. Opening can remove small bright spots (i.e. &quot;salt&quot;) and connect\nsmall dark cracks.</p>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nopened = opening(phantom, selem)\nplot_comparison(phantom, opened, 'opening')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>Since <tt class=\"docutils literal\">opening</tt> an image starts with an erosion operation, light regions that\nare <em>smaller</em> than the structuring element are removed. The dilation operation\nthat follows ensures that light regions that are <em>larger</em> than the structuring\nelement retain their original size. Notice how the light and dark shapes in the\ncenter their original thickness but the 3 lighter patches in the bottom get\ncompletely eroded. The size dependence is highlighted by the outer white ring:\nThe parts of the ring thinner than the structuring element were completely\nerased, while the thicker region at the top retains its original thickness.</p>\n<div class=\"section\" id=\"closing\">\n<h1>Closing</h1>\n<p>Morphological <tt class=\"docutils literal\">closing</tt> on an image is defined as a <em>dilation followed by an\nerosion</em>. Closing can remove small dark spots (i.e. &quot;pepper&quot;) and connect\nsmall bright cracks.</p>\n<p>To illustrate this more clearly, let's add a small crack to the white border:</p>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nphantom = img_as_ubyte(io.imread(data_dir+'/phantom.png', as_grey=True))\nphantom[10:30, 200:210] = 0\n\nclosed = closing(phantom, selem)\nplot_comparison(phantom, closed, 'closing')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>Since <tt class=\"docutils literal\">closing</tt> an image starts with an dilation operation, dark regions\nthat are <em>smaller</em> than the structuring element are removed. The dilation\noperation that follows ensures that dark regions that are <em>larger</em> than the\nstructuring element retain their original size. Notice how the white ellipses\nat the bottom get connected because of dilation, but other dark region retain\ntheir original sizes. Also notice how the crack we added is mostly removed.</p>\n<div class=\"section\" id=\"white-tophat\">\n<h1>White tophat</h1>\n<p>The <tt class=\"docutils literal\">white_tophat</tt> of an image is defined as the <em>image minus its\nmorphological opening</em>. This operation returns the bright spots of the image\nthat are smaller than the structuring element.</p>\n<p>To make things interesting, we'll add bright and dark spots to the image:</p>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nphantom = img_as_ubyte(io.imread(data_dir+'/phantom.png', as_grey=True))\nphantom[340:350, 200:210] = 255\nphantom[100:110, 200:210] = 0\n\nw_tophat = white_tophat(phantom, selem)\nplot_comparison(phantom, w_tophat, 'white tophat')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>As you can see, the 10-pixel wide white square is highlighted since it is\nsmaller than the structuring element. Also, the thin, white edges around most\nof the ellipse are retained because they're smaller than the structuring\nelement, but the thicker region at the top disappears.</p>\n<div class=\"section\" id=\"black-tophat\">\n<h1>Black tophat</h1>\n<p>The <tt class=\"docutils literal\">black_tophat</tt> of an image is defined as its morphological <strong>closing\nminus the original image</strong>. This operation returns the <em>dark spots of the\nimage that are smaller than the structuring element</em>.</p>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nb_tophat = black_tophat(phantom, selem)\nplot_comparison(phantom, b_tophat, 'black tophat')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>As you can see, the 10-pixel wide black square is highlighted since it is\nsmaller than the structuring element.</p>\n<div class=\"section\" id=\"duality\">\n<h1>Duality</h1>\n<p>As you should have noticed, many of these operations are simply the reverse\nof another operation. This duality can be summarized as follows:</p>\n<ol class=\"arabic simple\">\n<li>Erosion &lt;-&gt; Dilation</li>\n<li>Opening &lt;-&gt; Closing</li>\n<li>White tophat &lt;-&gt; Black tophat</li>\n</ol>\n<div class=\"section\" id=\"skeletonize\">\n<h2>Skeletonize</h2>\n<p>Thinning is used to reduce each connected component in a binary image to a\n<em>single-pixel wide skeleton</em>. It is important to note that this is performed\non binary images only.</p>\n</div>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nfrom skimage import img_as_bool\nhorse = ~img_as_bool(io.imread(data_dir+'/horse.png', as_grey=True))\n\nsk = skeletonize(horse)\nplot_comparison(horse, sk, 'skeletonize')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>As the name suggests, this technique is used to thin the image to 1-pixel wide\nskeleton by applying thinning successively.</p>\n<div class=\"section\" id=\"convex-hull\">\n<h1>Convex hull</h1>\n<p>The <tt class=\"docutils literal\">convex_hull_image</tt> is the <em>set of pixels included in the smallest\nconvex polygon that surround all white pixels in the input image</em>. Again note\nthat this is also performed on binary images.</p>\n</div>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nhull1 = convex_hull_image(horse)\nplot_comparison(horse, hull1, 'convex hull')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\">\n<p>As the figure illustrates, <tt class=\"docutils literal\">convex_hull_image</tt> gives the smallest polygon\nwhich covers the white or True completely in the image.</p>\n<p>If we add a small grain to the image, we can see how the convex hull adapts to\nenclose that grain:</p>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nimport numpy as np\n\nhorse2 = np.copy(horse)\nhorse2[45:50, 75:80] = 1\n\nhull2 = convex_hull_image(horse2)\nplot_comparison(horse2, hull2, 'convex hull')", 
          "metadata": {}
        }, 
        {
          "source": "<div class=\"document\" id=\"additional-resources\">\n<h1 class=\"title\">Additional Resources</h1>\n<p>1. <a class=\"reference external\" href=\"http://www.mathworks.com/help/images/morphology-fundamentals-dilation-and-erosion.html\">MathWorks tutorial on morphological processing</a>\n2. <a class=\"reference external\" href=\"http://www.cs.auckland.ac.nz/courses/compsci773s1c/lectures/ImageProcessing-html/topic4.htm\">Auckland university's tutorial on Morphological Image Processing</a>\n3. <a class=\"reference external\" href=\"http://en.wikipedia.org/wiki/Mathematical_morphology\">http://en.wikipedia.org/wiki/Mathematical_morphology</a></p>\n</div>\n", 
          "cell_type": "markdown", 
          "metadata": {}
        }, 
        {
          "cell_type": "code", 
          "language": "python", 
          "outputs": [], 
          "collapsed": false, 
          "input": "\nplt.show()", 
          "metadata": {}
        }
      ], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "name": ""
  }
}