


<!DOCTYPE html>
<html lang="en">
<head>
        <title>Module: feature &mdash; skimage v0.14.3 docs</title>
    
    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link href="../_static/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="../_static/css/custom.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    
    <script src="http://code.jquery.com/jquery-latest.js"></script>
    <script src="../_static/js/bootstrap.min.js"></script>
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.14.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <link rel="index" title="Index" href="../genindex.html" />
        <link rel="search" title="Search" href="../search.html" />
        <link rel="top" title="skimage v0.14.3 docs" href="../index.html" />
        <link rel="up" title="API Reference for skimage 0.14.3" href="api.html" />
        <link rel="next" title="Module: filters" href="skimage.filters.html" />
        <link rel="prev" title="Module: external.tifffile" href="skimage.external.tifffile.html" />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
    <link rel="shortcut icon" href="../_static/favicon.ico">
</head>
<body class="container">
    <a href="http://scikit-image.org" class="logo"><img src="../_static/img/logo.png" alt=""></a>
    <div class="clearfix"></div>
    <div class="navbar">
        <div class="navbar-inner">
            <ul class="nav">
                <li><a href="/docs/stable/install.html">Download</a></li>
<li><a href="../auto_examples/index.html">Gallery</a></li>
<li><a href="../index.html">Documentation</a></li>
<li><a href="/community_guidelines.html">Community Guidelines</a></li>

<li><a href="https://github.com/scikit-image/scikit-image">
    <img src="../_static/GitHub-Mark-32px.png"
        style="height: 15px; width: 15px;
               display: inline; float: none;
               padding-bottom: 3px;">
    Source</a>
</li>
            </ul>
        </div>
    </div>
    <div class="row">
        <div class="span3"><div style="padding-bottom: 3em">
  <form class="navbar-form pull-right" action="../search.html" method="get">
    <input type="text" class="search span3" name="q" placeholder="Search documentation ...">
    <input type="hidden" name="check_keywords" value="yes" >
    <input type="hidden" name="area" value="default" >
  </form>
</div><!-- 
        <h4 class="sidebar-box-heading">Contents</h4>
        <div class="well sidebar-box toc">
            <ul class="nav nav-list">
<li><a class="reference internal" href="#">Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">feature</span></code></a><ul class="nav nav-list">
<li><a class="reference internal" href="#canny">canny</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-canny">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#daisy">daisy</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-daisy">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.daisy</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#hog">hog</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-hog">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.hog</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#greycomatrix">greycomatrix</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-greycomatrix">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycomatrix</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#greycoprops">greycoprops</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-greycoprops">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycoprops</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#local-binary-pattern">local_binary_pattern</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-local-binary-pattern">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.local_binary_pattern</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiblock-lbp">multiblock_lbp</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-multiblock-lbp">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.multiblock_lbp</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#draw-multiblock-lbp">draw_multiblock_lbp</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-draw-multiblock-lbp">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_multiblock_lbp</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#peak-local-max">peak_local_max</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-peak-local-max">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#structure-tensor">structure_tensor</a></li>
<li><a class="reference internal" href="#structure-tensor-eigvals">structure_tensor_eigvals</a></li>
<li><a class="reference internal" href="#hessian-matrix">hessian_matrix</a></li>
<li><a class="reference internal" href="#hessian-matrix-det">hessian_matrix_det</a></li>
<li><a class="reference internal" href="#hessian-matrix-eigvals">hessian_matrix_eigvals</a></li>
<li><a class="reference internal" href="#shape-index">shape_index</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-shape-index">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.shape_index</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-kitchen-rosenfeld">corner_kitchen_rosenfeld</a></li>
<li><a class="reference internal" href="#corner-harris">corner_harris</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-corner-harris">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_harris</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-shi-tomasi">corner_shi_tomasi</a></li>
<li><a class="reference internal" href="#corner-foerstner">corner_foerstner</a></li>
<li><a class="reference internal" href="#corner-subpix">corner_subpix</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-corner-subpix">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_subpix</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-peaks">corner_peaks</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-corner-peaks">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_peaks</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#corner-moravec">corner_moravec</a></li>
<li><a class="reference internal" href="#corner-fast">corner_fast</a></li>
<li><a class="reference internal" href="#corner-orientations">corner_orientations</a></li>
<li><a class="reference internal" href="#match-template">match_template</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-match-template">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_template</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#register-translation">register_translation</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-register-translation">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.register_translation</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#match-descriptors">match_descriptors</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-match-descriptors">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_descriptors</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#plot-matches">plot_matches</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-plot-matches">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.plot_matches</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#blob-dog">blob_dog</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-blob-dog">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#blob-doh">blob_doh</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-blob-doh">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_doh</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#blob-log">blob_log</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-blob-log">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_log</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#haar-like-feature">haar_like_feature</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-haar-like-feature">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#haar-like-feature-coord">haar_like_feature_coord</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-haar-like-feature-coord">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature_coord</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#draw-haar-like-feature">draw_haar_like_feature</a><ul class="nav nav-list">
<li><a class="reference internal" href="#examples-using-skimage-feature-draw-haar-like-feature">Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_haar_like_feature</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#brief"><code class="xref py py-class docutils literal notranslate"><span class="pre">BRIEF</span></code></a></li>
<li><a class="reference internal" href="#censure"><code class="xref py py-class docutils literal notranslate"><span class="pre">CENSURE</span></code></a></li>
<li><a class="reference internal" href="#orb"><code class="xref py py-class docutils literal notranslate"><span class="pre">ORB</span></code></a></li>
</ul>
</li>
</ul>

        </div>


 --><div class="well">
    <strong>Docs for 0.14.3<br></strong>

    <a id="other">All versions</a>

    <ul id="versionList" style="display: none;">
        <script src="../../dev/_static/docversions.js"></script>
        <script type="text/javascript">
            insert_version_links();
        </script>
    </ul>

 </div>

<script type="text/javascript">
	$("#other").click(function() {
		$("#versionList").toggle();
	});
</script>
        </div>
        <div class="span9">
            
  <div class="section" id="module-skimage.feature">
<span id="module-feature"></span><h1>Module: <code class="xref py py-mod docutils literal notranslate"><span class="pre">feature</span></code><a class="headerlink" href="#module-skimage.feature" title="Permalink to this headline">¶</a></h1>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a>(image[, sigma, …])</p></td>
<td><p>Edge filter an image using the Canny algorithm.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.daisy" title="skimage.feature.daisy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.daisy</span></code></a>(image[, step, radius, …])</p></td>
<td><p>Extract DAISY feature descriptors densely for the given image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.hog" title="skimage.feature.hog"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hog</span></code></a>(image[, orientations, …])</p></td>
<td><p>Extract Histogram of Oriented Gradients (HOG) for a given image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.greycomatrix" title="skimage.feature.greycomatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.greycomatrix</span></code></a>(image, …[, …])</p></td>
<td><p>Calculate the grey-level co-occurrence matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.greycoprops" title="skimage.feature.greycoprops"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.greycoprops</span></code></a>(P[, prop])</p></td>
<td><p>Calculate texture properties of a GLCM.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.local_binary_pattern" title="skimage.feature.local_binary_pattern"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.local_binary_pattern</span></code></a>(image, P, R)</p></td>
<td><p>Gray scale and rotation invariant LBP (Local Binary Patterns).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.multiblock_lbp" title="skimage.feature.multiblock_lbp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.multiblock_lbp</span></code></a>(int_image, r, …)</p></td>
<td><p>Multi-block local binary pattern (MB-LBP).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.draw_multiblock_lbp" title="skimage.feature.draw_multiblock_lbp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.draw_multiblock_lbp</span></code></a>(image, …)</p></td>
<td><p>Multi-block local binary pattern visualization.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max</span></code></a>(image[, …])</p></td>
<td><p>Find peaks in an image as coordinate list or boolean mask.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.structure_tensor" title="skimage.feature.structure_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.structure_tensor</span></code></a>(image[, …])</p></td>
<td><p>Compute structure tensor using sum of squared differences.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.structure_tensor_eigvals" title="skimage.feature.structure_tensor_eigvals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.structure_tensor_eigvals</span></code></a>(…)</p></td>
<td><p>Compute Eigen values of structure tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.hessian_matrix" title="skimage.feature.hessian_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hessian_matrix</span></code></a>(image[, …])</p></td>
<td><p>Compute Hessian matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.hessian_matrix_det" title="skimage.feature.hessian_matrix_det"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hessian_matrix_det</span></code></a>(image[, …])</p></td>
<td><p>Compute the approximate Hessian Determinant over an image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.hessian_matrix_eigvals" title="skimage.feature.hessian_matrix_eigvals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.hessian_matrix_eigvals</span></code></a>(H_elems)</p></td>
<td><p>Compute Eigenvalues of Hessian matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.shape_index" title="skimage.feature.shape_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.shape_index</span></code></a>(image[, sigma, …])</p></td>
<td><p>Compute the shape index.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.corner_kitchen_rosenfeld" title="skimage.feature.corner_kitchen_rosenfeld"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_kitchen_rosenfeld</span></code></a>(image)</p></td>
<td><p>Compute Kitchen and Rosenfeld corner measure response image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.corner_harris" title="skimage.feature.corner_harris"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_harris</span></code></a>(image[, …])</p></td>
<td><p>Compute Harris corner measure response image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.corner_shi_tomasi" title="skimage.feature.corner_shi_tomasi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_shi_tomasi</span></code></a>(image[, sigma])</p></td>
<td><p>Compute Shi-Tomasi (Kanade-Tomasi) corner measure response image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.corner_foerstner" title="skimage.feature.corner_foerstner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_foerstner</span></code></a>(image[, sigma])</p></td>
<td><p>Compute Foerstner corner measure response image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.corner_subpix" title="skimage.feature.corner_subpix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_subpix</span></code></a>(image, corners)</p></td>
<td><p>Determine subpixel position of corners.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.corner_peaks" title="skimage.feature.corner_peaks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_peaks</span></code></a>(image[, …])</p></td>
<td><p>Find corners in corner measure response image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.corner_moravec" title="skimage.feature.corner_moravec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_moravec</span></code></a>(image[, …])</p></td>
<td><p>Compute Moravec corner measure response image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.corner_fast" title="skimage.feature.corner_fast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_fast</span></code></a>(image[, n, …])</p></td>
<td><p>Extract FAST corners for a given image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.corner_orientations" title="skimage.feature.corner_orientations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.corner_orientations</span></code></a>(image, …)</p></td>
<td><p>Compute the orientation of corners.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.match_template" title="skimage.feature.match_template"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.match_template</span></code></a>(image, template)</p></td>
<td><p>Match a template to a 2-D or 3-D image using normalized correlation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.register_translation" title="skimage.feature.register_translation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.register_translation</span></code></a>(…[, …])</p></td>
<td><p>Efficient subpixel image translation registration by cross-correlation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.match_descriptors" title="skimage.feature.match_descriptors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.match_descriptors</span></code></a>(…[, …])</p></td>
<td><p>Brute-force matching of descriptors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.plot_matches" title="skimage.feature.plot_matches"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.plot_matches</span></code></a>(ax, image1, …)</p></td>
<td><p>Plot matched features.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code></a>(image[, min_sigma, …])</p></td>
<td><p>Finds blobs in the given grayscale image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.blob_doh" title="skimage.feature.blob_doh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_doh</span></code></a>(image[, min_sigma, …])</p></td>
<td><p>Finds blobs in the given grayscale image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.blob_log" title="skimage.feature.blob_log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_log</span></code></a>(image[, min_sigma, …])</p></td>
<td><p>Finds blobs in the given grayscale image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.haar_like_feature" title="skimage.feature.haar_like_feature"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature</span></code></a>(int_image, …)</p></td>
<td><p>Compute the Haar-like features for a region of interest (ROI) of an integral image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature_coord</span></code></a>(…)</p></td>
<td><p>Compute the coordinates of Haar-like features.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.draw_haar_like_feature" title="skimage.feature.draw_haar_like_feature"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.draw_haar_like_feature</span></code></a>(…)</p></td>
<td><p>Visualization of Haar-like features.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.BRIEF" title="skimage.feature.BRIEF"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.BRIEF</span></code></a>([descriptor_size, …])</p></td>
<td><p>BRIEF binary descriptor extractor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.feature.CENSURE" title="skimage.feature.CENSURE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.CENSURE</span></code></a>([min_scale, …])</p></td>
<td><p>CENSURE keypoint detector.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.feature.ORB" title="skimage.feature.ORB"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.ORB</span></code></a>([downscale, n_scales, …])</p></td>
<td><p>Oriented FAST and rotated BRIEF feature detector and binary descriptor extractor.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="canny">
<h2>canny<a class="headerlink" href="#canny" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.canny">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">canny</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1.0</em>, <em class="sig-param">low_threshold=None</em>, <em class="sig-param">high_threshold=None</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">use_quantiles=False</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/_canny.py#L53"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.canny" title="Permalink to this definition">¶</a></dt>
<dd><p>Edge filter an image using the Canny algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D array</span></dt><dd><p>Grayscale input image to detect edges on; can be of any dtype.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float</span></dt><dd><p>Standard deviation of the Gaussian filter.</p>
</dd>
<dt><strong>low_threshold</strong><span class="classifier">float</span></dt><dd><p>Lower bound for hysteresis thresholding (linking edges).
If None, low_threshold is set to 10% of dtype’s max.</p>
</dd>
<dt><strong>high_threshold</strong><span class="classifier">float</span></dt><dd><p>Upper bound for hysteresis thresholding (linking edges).
If None, high_threshold is set to 20% of dtype’s max.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">array, dtype=bool, optional</span></dt><dd><p>Mask to limit the application of Canny to a certain area.</p>
</dd>
<dt><strong>use_quantiles</strong><span class="classifier">bool, optional</span></dt><dd><p>If True then treat low_threshold and high_threshold as quantiles of the
edge magnitude image, rather than absolute edge magnitude values. If True
then the thresholds must be in the range [0, 1].</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2D array (image)</span></dt><dd><p>The binary edge map.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.sobel</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The steps of the algorithm are as follows:</p>
<ul class="simple">
<li><p>Smooth the image using a Gaussian with <code class="docutils literal notranslate"><span class="pre">sigma</span></code> width.</p></li>
<li><p>Apply the horizontal and vertical Sobel operators to get the gradients
within the image. The edge strength is the norm of the gradient.</p></li>
<li><p>Thin potential edges to 1-pixel wide curves. First, find the normal
to the edge at each point. This is done by looking at the
signs and the relative magnitude of the X-Sobel and Y-Sobel
to sort the points into 4 categories: horizontal, vertical,
diagonal and antidiagonal. Then look in the normal and reverse
directions to see if the values in either of those directions are
greater than the point in question. Use interpolation to get a mix of
points instead of picking the one that’s the closest to the normal.</p></li>
<li><p>Perform a hysteresis thresholding: first label all points above the
high threshold as edges. Then recursively label any point above the
low threshold that is 8-connected to a labeled point as an edge.</p></li>
</ul>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r5f5bcbc11495-1"><span class="brackets">1</span></dt>
<dd><p>Canny, J., A Computational Approach To Edge Detection, IEEE Trans.
Pattern Analysis and Machine Intelligence, 8:679-714, 1986</p>
</dd>
<dt class="label" id="r5f5bcbc11495-2"><span class="brackets">2</span></dt>
<dd><p>William Green’s Canny tutorial
<a class="reference external" href="http://dasl.unlv.edu/daslDrexel/alumni/bGreen/www.pages.drexel.edu/_weg22/can_tut.html">http://dasl.unlv.edu/daslDrexel/alumni/bGreen/www.pages.drexel.edu/_weg22/can_tut.html</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate noisy image of a square</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">im</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="o">-</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">:</span><span class="o">-</span><span class="mi">64</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">im</span> <span class="o">+=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># First trial with the Canny filter, with the default smoothing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges1</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">canny</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Increase the smoothing for better results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges2</span> <span class="o">=</span> <span class="n">feature</span><span class="o">.</span><span class="n">canny</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-canny">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code><a class="headerlink" href="#examples-using-skimage-feature-canny" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The Canny filter is a multi-stage edge detector. It uses a filter based on the derivative of a ..."><div class="figure align-default" id="id64">
<img alt="../_images/sphx_glr_plot_canny_thumb.png" src="../_images/sphx_glr_plot_canny_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/edges/plot_canny.html#sphx-glr-auto-examples-edges-plot-canny-py"><span class="std std-ref">Canny edge detector</span></a></span><a class="headerlink" href="#id64" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a method to detect straight lines [1]_."><div class="figure align-default" id="id65">
<img alt="../_images/sphx_glr_plot_line_hough_transform_thumb.png" src="../_images/sphx_glr_plot_line_hough_transform_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/edges/plot_line_hough_transform.html#sphx-glr-auto-examples-edges-plot-line-hough-transform-py"><span class="std std-ref">Straight line Hough transform</span></a></span><a class="headerlink" href="#id65" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a `method to detect straight lines &lt;http://en.wikip..."><div class="figure align-default" id="id66">
<img alt="../_images/sphx_glr_plot_circular_elliptical_hough_transform_thumb.png" src="../_images/sphx_glr_plot_circular_elliptical_hough_transform_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/edges/plot_circular_elliptical_hough_transform.html#sphx-glr-auto-examples-edges-plot-circular-elliptical-hough-transform-py"><span class="std std-ref">Circular and Elliptical Hough Transforms</span></a></span><a class="headerlink" href="#id66" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to segment objects from a background. We use the ``coins`` ima..."><div class="figure align-default" id="id67">
<img alt="../_images/sphx_glr_plot_coins_segmentation_thumb.png" src="../_images/sphx_glr_plot_coins_segmentation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/xx_applications/plot_coins_segmentation.html#sphx-glr-auto-examples-xx-applications-plot-coins-segmentation-py"><span class="std std-ref">Comparing edge-based and region-based segmentation</span></a></span><a class="headerlink" href="#id67" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="daisy">
<h2>daisy<a class="headerlink" href="#daisy" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.daisy">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">daisy</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">step=4</em>, <em class="sig-param">radius=15</em>, <em class="sig-param">rings=3</em>, <em class="sig-param">histograms=8</em>, <em class="sig-param">orientations=8</em>, <em class="sig-param">normalization='l1'</em>, <em class="sig-param">sigmas=None</em>, <em class="sig-param">ring_radii=None</em>, <em class="sig-param">visualize=False</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/_daisy.py#L9"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.daisy" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract DAISY feature descriptors densely for the given image.</p>
<p>DAISY is a feature descriptor similar to SIFT formulated in a way that
allows for fast dense extraction. Typically, this is practical for
bag-of-features image representations.</p>
<p>The implementation follows Tola et al. <a class="reference internal" href="#r3f18658b3c6d-1" id="id3">[1]</a> but deviate on the following
points:</p>
<blockquote>
<div><ul class="simple">
<li><p>Histogram bin contribution are smoothed with a circular Gaussian
window over the tonal range (the angular range).</p></li>
<li><p>The sigma values of the spatial Gaussian smoothing in this code do not
match the sigma values in the original code by Tola et al. <a class="reference internal" href="#r3f18658b3c6d-2" id="id4">[2]</a>. In
their code, spatial smoothing is applied to both the input image and
the center histogram. However, this smoothing is not documented in <a class="reference internal" href="#r3f18658b3c6d-1" id="id5">[1]</a>
and, therefore, it is omitted.</p></li>
</ul>
</div></blockquote>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N) array</span></dt><dd><p>Input image (grayscale).</p>
</dd>
<dt><strong>step</strong><span class="classifier">int, optional</span></dt><dd><p>Distance between descriptor sampling points.</p>
</dd>
<dt><strong>radius</strong><span class="classifier">int, optional</span></dt><dd><p>Radius (in pixels) of the outermost ring.</p>
</dd>
<dt><strong>rings</strong><span class="classifier">int, optional</span></dt><dd><p>Number of rings.</p>
</dd>
<dt><strong>histograms</strong><span class="classifier">int, optional</span></dt><dd><p>Number of histograms sampled per ring.</p>
</dd>
<dt><strong>orientations</strong><span class="classifier">int, optional</span></dt><dd><p>Number of orientations (bins) per histogram.</p>
</dd>
<dt><strong>normalization</strong><span class="classifier">[ ‘l1’ | ‘l2’ | ‘daisy’ | ‘off’ ], optional</span></dt><dd><p>How to normalize the descriptors</p>
<blockquote>
<div><ul class="simple">
<li><p>‘l1’: L1-normalization of each descriptor.</p></li>
<li><p>‘l2’: L2-normalization of each descriptor.</p></li>
<li><p>‘daisy’: L2-normalization of individual histograms.</p></li>
<li><p>‘off’: Disable normalization.</p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>sigmas</strong><span class="classifier">1D array of float, optional</span></dt><dd><p>Standard deviation of spatial Gaussian smoothing for the center
histogram and for each ring of histograms. The array of sigmas should
be sorted from the center and out. I.e. the first sigma value defines
the spatial smoothing of the center histogram and the last sigma value
defines the spatial smoothing of the outermost ring. Specifying sigmas
overrides the following parameter.</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">rings</span> <span class="pre">=</span> <span class="pre">len(sigmas)</span> <span class="pre">-</span> <span class="pre">1</span></code></p>
</div></blockquote>
</dd>
<dt><strong>ring_radii</strong><span class="classifier">1D array of int, optional</span></dt><dd><p>Radius (in pixels) for each ring. Specifying ring_radii overrides the
following two parameters.</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">rings</span> <span class="pre">=</span> <span class="pre">len(ring_radii)</span></code>
<code class="docutils literal notranslate"><span class="pre">radius</span> <span class="pre">=</span> <span class="pre">ring_radii[-1]</span></code></p>
</div></blockquote>
<p>If both sigmas and ring_radii are given, they must satisfy the
following predicate since no radius is needed for the center
histogram.</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">len(ring_radii)</span> <span class="pre">==</span> <span class="pre">len(sigmas)</span> <span class="pre">+</span> <span class="pre">1</span></code></p>
</div></blockquote>
</dd>
<dt><strong>visualize</strong><span class="classifier">bool, optional</span></dt><dd><p>Generate a visualization of the DAISY descriptors</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>descs</strong><span class="classifier">array</span></dt><dd><p>Grid of DAISY descriptors for the given image as an array
dimensionality  (P, Q, R) where</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">=</span> <span class="pre">ceil((M</span> <span class="pre">-</span> <span class="pre">radius*2)</span> <span class="pre">/</span> <span class="pre">step)</span></code>
<code class="docutils literal notranslate"><span class="pre">Q</span> <span class="pre">=</span> <span class="pre">ceil((N</span> <span class="pre">-</span> <span class="pre">radius*2)</span> <span class="pre">/</span> <span class="pre">step)</span></code>
<code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">=</span> <span class="pre">(rings</span> <span class="pre">*</span> <span class="pre">histograms</span> <span class="pre">+</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">orientations</span></code></p>
</div></blockquote>
</dd>
<dt><strong>descs_img</strong><span class="classifier">(M, N, 3) array (only if visualize==True)</span></dt><dd><p>Visualization of the DAISY descriptors.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r3f18658b3c6d-1"><span class="brackets">1</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Tola et al. “Daisy: An efficient dense descriptor applied to wide-
baseline stereo.” Pattern Analysis and Machine Intelligence, IEEE
Transactions on 32.5 (2010): 815-830.</p>
</dd>
<dt class="label" id="r3f18658b3c6d-2"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p><a class="reference external" href="http://cvlab.epfl.ch/software/daisy">http://cvlab.epfl.ch/software/daisy</a></p>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-daisy">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.daisy</span></code><a class="headerlink" href="#examples-using-skimage-feature-daisy" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The DAISY local image descriptor is based on gradient orientation histograms similar to the SIF..."><div class="figure align-default" id="id68">
<img alt="../_images/sphx_glr_plot_daisy_thumb.png" src="../_images/sphx_glr_plot_daisy_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_daisy.html#sphx-glr-auto-examples-features-detection-plot-daisy-py"><span class="std std-ref">Dense DAISY feature description</span></a></span><a class="headerlink" href="#id68" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="hog">
<h2>hog<a class="headerlink" href="#hog" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hog">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">hog</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">orientations=9</em>, <em class="sig-param">pixels_per_cell=(8</em>, <em class="sig-param">8)</em>, <em class="sig-param">cells_per_block=(3</em>, <em class="sig-param">3)</em>, <em class="sig-param">block_norm=None</em>, <em class="sig-param">visualize=False</em>, <em class="sig-param">visualise=None</em>, <em class="sig-param">transform_sqrt=False</em>, <em class="sig-param">feature_vector=True</em>, <em class="sig-param">multichannel=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/_hog.py#L48"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hog" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract Histogram of Oriented Gradients (HOG) for a given image.</p>
<p>Compute a Histogram of Oriented Gradients (HOG) by</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>(optional) global image normalization</p></li>
<li><p>computing the gradient image in <cite>row</cite> and <cite>col</cite></p></li>
<li><p>computing gradient histograms</p></li>
<li><p>normalizing across blocks</p></li>
<li><p>flattening into a feature vector</p></li>
</ol>
</div></blockquote>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N[, C]) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>orientations</strong><span class="classifier">int, optional</span></dt><dd><p>Number of orientation bins.</p>
</dd>
<dt><strong>pixels_per_cell</strong><span class="classifier">2-tuple (int, int), optional</span></dt><dd><p>Size (in pixels) of a cell.</p>
</dd>
<dt><strong>cells_per_block</strong><span class="classifier">2-tuple (int, int), optional</span></dt><dd><p>Number of cells in each block.</p>
</dd>
<dt><strong>block_norm</strong><span class="classifier">str {‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’}, optional</span></dt><dd><p>Block normalization method:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">L1</span></code></dt><dd><p>Normalization using L1-norm. (default)</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L1-sqrt</span></code></dt><dd><p>Normalization using L1-norm, followed by square root.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L2</span></code></dt><dd><p>Normalization using L2-norm.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">L2-Hys</span></code></dt><dd><p>Normalization using L2-norm, followed by limiting the
maximum values to 0.2 (<cite>Hys</cite> stands for <cite>hysteresis</cite>) and
renormalization using L2-norm.
For details, see <a class="reference internal" href="#ra159ccd8c91f-3" id="id8">[3]</a>, <a class="reference internal" href="#ra159ccd8c91f-4" id="id9">[4]</a>.</p>
</dd>
</dl>
</dd>
<dt><strong>visualize</strong><span class="classifier">bool, optional</span></dt><dd><p>Also return an image of the HOG.  For each cell and orientation bin,
the image contains a line segment that is centered at the cell center,
is perpendicular to the midpoint of the range of angles spanned by the
orientation bin, and has intensity proportional to the corresponding
histogram value.</p>
</dd>
<dt><strong>transform_sqrt</strong><span class="classifier">bool, optional</span></dt><dd><p>Apply power law compression to normalize the image before
processing. DO NOT use this if the image contains negative
values. Also see <cite>notes</cite> section below.</p>
</dd>
<dt><strong>feature_vector</strong><span class="classifier">bool, optional</span></dt><dd><p>Return the data as a feature vector by calling .ravel() on the result
just before returning.</p>
</dd>
<dt><strong>multichannel</strong><span class="classifier">boolean, optional</span></dt><dd><p>If True, the last <cite>image</cite> dimension is considered as a color channel,
otherwise as spatial.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(n_blocks_row, n_blocks_col, n_cells_row, n_cells_col, n_orient) ndarray</span></dt><dd><p>HOG descriptor for the image. If <cite>feature_vector</cite> is True, a 1D
(flattened) array is returned.</p>
</dd>
<dt><strong>hog_image</strong><span class="classifier">(M, N) ndarray, optional</span></dt><dd><p>A visualisation of the HOG image. Only provided if <cite>visualize</cite> is True.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The presented code implements the HOG extraction method from <a class="reference internal" href="#ra159ccd8c91f-2" id="id10">[2]</a> with
the following changes: (I) blocks of (3, 3) cells are used ((2, 2) in the
paper; (II) no smoothing within cells (Gaussian spatial window with sigma=8pix
in the paper); (III) L1 block normalization is used (L2-Hys in the paper).</p>
<p>Power law compression, also known as Gamma correction, is used to reduce
the effects of shadowing and illumination variations. The compression makes
the dark regions lighter. When the kwarg <cite>transform_sqrt</cite> is set to
<code class="docutils literal notranslate"><span class="pre">True</span></code>, the function computes the square root of each color channel
and then applies the hog algorithm to the image.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="ra159ccd8c91f-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">http://en.wikipedia.org/wiki/Histogram_of_oriented_gradients</a></p>
</dd>
<dt class="label" id="ra159ccd8c91f-2"><span class="brackets"><a class="fn-backref" href="#id10">2</a></span></dt>
<dd><p>Dalal, N and Triggs, B, Histograms of Oriented Gradients for
Human Detection, IEEE Computer Society Conference on Computer
Vision and Pattern Recognition 2005 San Diego, CA, USA,
<a class="reference external" href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf">https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf</a>,
DOI:10.1109/CVPR.2005.177</p>
</dd>
<dt class="label" id="ra159ccd8c91f-3"><span class="brackets"><a class="fn-backref" href="#id8">3</a></span></dt>
<dd><p>Lowe, D.G., Distinctive image features from scale-invatiant
keypoints, International Journal of Computer Vision (2004) 60: 91,
<a class="reference external" href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf</a>,
DOI:10.1023/B:VISI.0000029664.99615.94</p>
</dd>
<dt class="label" id="ra159ccd8c91f-4"><span class="brackets"><a class="fn-backref" href="#id9">4</a></span></dt>
<dd><p>Dalal, N, Finding People in Images and Videos,
Human-Computer Interaction [cs.HC], Institut National Polytechnique
de Grenoble - INPG, 2006,
<a class="reference external" href="https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf">https://tel.archives-ouvertes.fr/tel-00390303/file/NavneetDalalThesis.pdf</a></p>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-hog">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.hog</span></code><a class="headerlink" href="#examples-using-skimage-feature-hog" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The Histogram of Oriented Gradient (HOG) feature descriptor is popular for object detection [1]..."><div class="figure align-default" id="id69">
<img alt="../_images/sphx_glr_plot_hog_thumb.png" src="../_images/sphx_glr_plot_hog_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py"><span class="std std-ref">Histogram of Oriented Gradients</span></a></span><a class="headerlink" href="#id69" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="greycomatrix">
<h2>greycomatrix<a class="headerlink" href="#greycomatrix" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.greycomatrix">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">greycomatrix</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">distances</em>, <em class="sig-param">angles</em>, <em class="sig-param">levels=None</em>, <em class="sig-param">symmetric=False</em>, <em class="sig-param">normed=False</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/texture.py#L14"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.greycomatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the grey-level co-occurrence matrix.</p>
<p>A grey level co-occurrence matrix is a histogram of co-occurring
greyscale values at a given offset over an image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">array_like</span></dt><dd><p>Integer typed input image. Only positive valued images are supported.
If type is other than uint8, the argument <cite>levels</cite> needs to be set.</p>
</dd>
<dt><strong>distances</strong><span class="classifier">array_like</span></dt><dd><p>List of pixel pair distance offsets.</p>
</dd>
<dt><strong>angles</strong><span class="classifier">array_like</span></dt><dd><p>List of pixel pair angles in radians.</p>
</dd>
<dt><strong>levels</strong><span class="classifier">int, optional</span></dt><dd><p>The input image should contain integers in [0, <cite>levels</cite>-1],
where levels indicate the number of grey-levels counted
(typically 256 for an 8-bit image). This argument is required for
16-bit images or higher and is typically the maximum of the image.
As the output matrix is at least <cite>levels</cite> x <cite>levels</cite>, it might
be preferable to use binning of the input image rather than
large values for <cite>levels</cite>.</p>
</dd>
<dt><strong>symmetric</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, the output matrix <cite>P[:, :, d, theta]</cite> is symmetric. This
is accomplished by ignoring the order of value pairs, so both
(i, j) and (j, i) are accumulated when (i, j) is encountered
for a given offset. The default is False.</p>
</dd>
<dt><strong>normed</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, normalize each matrix <cite>P[:, :, d, theta]</cite> by dividing
by the total number of accumulated co-occurrences for the given
offset. The elements of the resulting matrix sum to 1. The
default is False.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>P</strong><span class="classifier">4-D ndarray</span></dt><dd><p>The grey-level co-occurrence histogram. The value
<cite>P[i,j,d,theta]</cite> is the number of times that grey-level <cite>j</cite>
occurs at a distance <cite>d</cite> and at an angle <cite>theta</cite> from
grey-level <cite>i</cite>. If <cite>normed</cite> is <cite>False</cite>, the output is of
type uint32, otherwise it is float64. The dimensions are:
levels x levels x number of distances x number of angles.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r4810813e96aa-1"><span class="brackets">1</span></dt>
<dd><p>The GLCM Tutorial Home Page,
<a class="reference external" href="http://www.fp.ucalgary.ca/mhallbey/tutorial.htm">http://www.fp.ucalgary.ca/mhallbey/tutorial.htm</a></p>
</dd>
<dt class="label" id="r4810813e96aa-2"><span class="brackets">2</span></dt>
<dd><p>Pattern Recognition Engineering, Morton Nadler &amp; Eric P.
Smith</p>
</dd>
<dt class="label" id="r4810813e96aa-3"><span class="brackets">3</span></dt>
<dd><p>Wikipedia, <a class="reference external" href="http://en.wikipedia.org/wiki/Co-occurrence_matrix">http://en.wikipedia.org/wiki/Co-occurrence_matrix</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Compute 2 GLCMs: One for a 1-pixel offset to the right, and one
for a 1-pixel offset upwards.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">greycomatrix</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span>
<span class="gp">... </span>                      <span class="n">levels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="go">array([[2, 2, 1, 0],</span>
<span class="go">       [0, 2, 0, 0],</span>
<span class="go">       [0, 0, 3, 1],</span>
<span class="go">       [0, 0, 0, 1]], dtype=uint32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="go">array([[1, 1, 3, 0],</span>
<span class="go">       [0, 1, 1, 0],</span>
<span class="go">       [0, 0, 0, 2],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="go">array([[3, 0, 2, 0],</span>
<span class="go">       [0, 2, 2, 0],</span>
<span class="go">       [0, 0, 1, 2],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="go">array([[2, 0, 0, 0],</span>
<span class="go">       [1, 1, 2, 0],</span>
<span class="go">       [0, 0, 2, 1],</span>
<span class="go">       [0, 0, 0, 0]], dtype=uint32)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-greycomatrix">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycomatrix</span></code><a class="headerlink" href="#examples-using-skimage-feature-greycomatrix" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using grey level co-occurrence matrices (GLCMs)..."><div class="figure align-default" id="id70">
<img alt="../_images/sphx_glr_plot_glcm_thumb.png" src="../_images/sphx_glr_plot_glcm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></span><a class="headerlink" href="#id70" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="greycoprops">
<h2>greycoprops<a class="headerlink" href="#greycoprops" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.greycoprops">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">greycoprops</code><span class="sig-paren">(</span><em class="sig-param">P</em>, <em class="sig-param">prop='contrast'</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/texture.py#L153"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.greycoprops" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate texture properties of a GLCM.</p>
<p>Compute a feature of a grey level co-occurrence matrix to serve as
a compact summary of the matrix. The properties are computed as
follows:</p>
<ul>
<li><p>‘contrast’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1} P_{i,j}(i-j)^2\)</span></p></li>
<li><p>‘dissimilarity’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1}P_{i,j}|i-j|\)</span></p></li>
<li><p>‘homogeneity’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1}\frac{P_{i,j}}{1+(i-j)^2}\)</span></p></li>
<li><p>‘ASM’: <span class="math notranslate nohighlight">\(\sum_{i,j=0}^{levels-1} P_{i,j}^2\)</span></p></li>
<li><p>‘energy’: <span class="math notranslate nohighlight">\(\sqrt{ASM}\)</span></p></li>
<li><dl>
<dt>‘correlation’:</dt><dd><div class="math notranslate nohighlight">
\[\sum_{i,j=0}^{levels-1} P_{i,j}\left[\frac{(i-\mu_i) \
(j-\mu_j)}{\sqrt{(\sigma_i^2)(\sigma_j^2)}}\right]\]</div>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>P</strong><span class="classifier">ndarray</span></dt><dd><p>Input array. <cite>P</cite> is the grey-level co-occurrence histogram
for which to compute the specified property. The value
<cite>P[i,j,d,theta]</cite> is the number of times that grey-level j
occurs at a distance d and at an angle theta from
grey-level i.</p>
</dd>
<dt><strong>prop</strong><span class="classifier">{‘contrast’, ‘dissimilarity’, ‘homogeneity’, ‘energy’,             ‘correlation’, ‘ASM’}, optional</span></dt><dd><p>The property of the GLCM to compute. The default is ‘contrast’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>results</strong><span class="classifier">2-D ndarray</span></dt><dd><p>2-dimensional array. <cite>results[d, a]</cite> is the property ‘prop’ for
the d’th distance and the a’th angle.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="ra999ee4f1c5d-1"><span class="brackets">1</span></dt>
<dd><p>The GLCM Tutorial Home Page,
<a class="reference external" href="http://www.fp.ucalgary.ca/mhallbey/tutorial.htm">http://www.fp.ucalgary.ca/mhallbey/tutorial.htm</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Compute the contrast for GLCMs with distances [1, 2] and angles
[0 degrees, 90 degrees]</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">greycomatrix</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">],</span> <span class="n">levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">symmetric</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrast</span> <span class="o">=</span> <span class="n">greycoprops</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="s1">&#39;contrast&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contrast</span>
<span class="go">array([[ 0.58333333,  1.        ],</span>
<span class="go">       [ 1.25      ,  2.75      ]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-greycoprops">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.greycoprops</span></code><a class="headerlink" href="#examples-using-skimage-feature-greycoprops" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using grey level co-occurrence matrices (GLCMs)..."><div class="figure align-default" id="id71">
<img alt="../_images/sphx_glr_plot_glcm_thumb.png" src="../_images/sphx_glr_plot_glcm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></span><a class="headerlink" href="#id71" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="local-binary-pattern">
<h2>local_binary_pattern<a class="headerlink" href="#local-binary-pattern" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.local_binary_pattern">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">local_binary_pattern</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">P</em>, <em class="sig-param">R</em>, <em class="sig-param">method='default'</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/texture.py#L265"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.local_binary_pattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Gray scale and rotation invariant LBP (Local Binary Patterns).</p>
<p>LBP is an invariant descriptor that can be used for texture classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(N, M) array</span></dt><dd><p>Graylevel image.</p>
</dd>
<dt><strong>P</strong><span class="classifier">int</span></dt><dd><p>Number of circularly symmetric neighbour set points (quantization of
the angular space).</p>
</dd>
<dt><strong>R</strong><span class="classifier">float</span></dt><dd><p>Radius of circle (spatial resolution of the operator).</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘default’, ‘ror’, ‘uniform’, ‘var’}</span></dt><dd><p>Method to determine the pattern.</p>
<ul class="simple">
<li><dl class="simple">
<dt>‘default’: original local binary pattern which is gray scale but not</dt><dd><p>rotation invariant.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘ror’: extension of default implementation which is gray scale and</dt><dd><p>rotation invariant.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘uniform’: improved rotation invariance with uniform patterns and</dt><dd><p>finer quantization of the angular space which is gray scale and
rotation invariant.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘nri_uniform’: non rotation-invariant uniform patterns variant</dt><dd><p>which is only gray scale invariant <a class="reference internal" href="#r648eb9e75080-2" id="id19">[2]</a>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘var’: rotation invariant variance measures of the contrast of local</dt><dd><p>image texture which is rotation but not gray scale invariant.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">(N, M) array</span></dt><dd><p>LBP image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r648eb9e75080-1"><span class="brackets">1</span></dt>
<dd><p>Multiresolution Gray-Scale and Rotation Invariant Texture
Classification with Local Binary Patterns.
Timo Ojala, Matti Pietikainen, Topi Maenpaa.
<a class="reference external" href="http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf">http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf</a>, 2002.</p>
</dd>
<dt class="label" id="r648eb9e75080-2"><span class="brackets"><a class="fn-backref" href="#id19">2</a></span></dt>
<dd><p>Face recognition with local binary patterns.
Timo Ahonen, Abdenour Hadid, Matti Pietikainen,
<a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.214.6851">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.214.6851</a>,
2004.</p>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-local-binary-pattern">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.local_binary_pattern</span></code><a class="headerlink" href="#examples-using-skimage-feature-local-binary-pattern" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on LBP (Local Binary Pattern). LBP ..."><div class="figure align-default" id="id72">
<img alt="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" src="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-local-binary-pattern-py"><span class="std std-ref">Local Binary Pattern for texture classification</span></a></span><a class="headerlink" href="#id72" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="multiblock-lbp">
<h2>multiblock_lbp<a class="headerlink" href="#multiblock-lbp" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.multiblock_lbp">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">multiblock_lbp</code><span class="sig-paren">(</span><em class="sig-param">int_image</em>, <em class="sig-param">r</em>, <em class="sig-param">c</em>, <em class="sig-param">width</em>, <em class="sig-param">height</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/texture.py#L324"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.multiblock_lbp" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-block local binary pattern (MB-LBP).</p>
<p>The features are calculated similarly to local binary patterns (LBPs),
(See <a class="reference internal" href="#skimage.feature.local_binary_pattern" title="skimage.feature.local_binary_pattern"><code class="xref py py-meth docutils literal notranslate"><span class="pre">local_binary_pattern()</span></code></a>) except that summed blocks are
used instead of individual pixel values.</p>
<p>MB-LBP is an extension of LBP that can be computed on multiple scales
in constant time using the integral image. Nine equally-sized rectangles
are used to compute a feature. For each rectangle, the sum of the pixel
intensities is computed. Comparisons of these sums to that of the central
rectangle determine the feature, similarly to LBP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>int_image</strong><span class="classifier">(N, M) array</span></dt><dd><p>Integral image.</p>
</dd>
<dt><strong>r</strong><span class="classifier">int</span></dt><dd><p>Row-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>c</strong><span class="classifier">int</span></dt><dd><p>Column-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>width</strong><span class="classifier">int</span></dt><dd><p>Width of one of the 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
<dt><strong>height</strong><span class="classifier">int</span></dt><dd><p>Height of one of the 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">int</span></dt><dd><p>8-bit MB-LBP feature descriptor.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="ra36744213751-1"><span class="brackets">1</span></dt>
<dd><p>Face Detection Based on Multi-Block LBP
Representation. Lun Zhang, Rufeng Chu, Shiming Xiang, Shengcai Liao,
Stan Z. Li
<a class="reference external" href="http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf">http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf</a></p>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-multiblock-lbp">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.multiblock_lbp</span></code><a class="headerlink" href="#examples-using-skimage-feature-multiblock-lbp" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example shows how to compute multi-block local binary pattern (MB-LBP) features as well as..."><div class="figure align-default" id="id73">
<img alt="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" src="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_multiblock_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-multiblock-local-binary-pattern-py"><span class="std std-ref">Multi-Block Local Binary Pattern for texture classification</span></a></span><a class="headerlink" href="#id73" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="draw-multiblock-lbp">
<h2>draw_multiblock_lbp<a class="headerlink" href="#draw-multiblock-lbp" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.draw_multiblock_lbp">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">draw_multiblock_lbp</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">r</em>, <em class="sig-param">c</em>, <em class="sig-param">width</em>, <em class="sig-param">height</em>, <em class="sig-param">lbp_code=0</em>, <em class="sig-param">color_greater_block=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">color_less_block=(0</em>, <em class="sig-param">0.69</em>, <em class="sig-param">0.96)</em>, <em class="sig-param">alpha=0.5</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/texture.py#L370"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.draw_multiblock_lbp" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-block local binary pattern visualization.</p>
<p>Blocks with higher sums are colored with alpha-blended white rectangles,
whereas blocks with lower sums are colored alpha-blended cyan. Colors
and the <cite>alpha</cite> parameter can be changed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray of float or uint</span></dt><dd><p>Image on which to visualize the pattern.</p>
</dd>
<dt><strong>r</strong><span class="classifier">int</span></dt><dd><p>Row-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>c</strong><span class="classifier">int</span></dt><dd><p>Column-coordinate of top left corner of a rectangle containing feature.</p>
</dd>
<dt><strong>width</strong><span class="classifier">int</span></dt><dd><p>Width of one of 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
<dt><strong>height</strong><span class="classifier">int</span></dt><dd><p>Height of one of 9 equal rectangles that will be used to compute
a feature.</p>
</dd>
<dt><strong>lbp_code</strong><span class="classifier">int</span></dt><dd><p>The descriptor of feature to visualize. If not provided, the
descriptor with 0 value will be used.</p>
</dd>
<dt><strong>color_greater_block</strong><span class="classifier">tuple of 3 floats</span></dt><dd><p>Floats specifying the color for the block that has greater
intensity value. They should be in the range [0, 1].
Corresponding values define (R, G, B) values. Default value
is white (1, 1, 1).</p>
</dd>
<dt><strong>color_greater_block</strong><span class="classifier">tuple of 3 floats</span></dt><dd><p>Floats specifying the color for the block that has greater intensity
value. They should be in the range [0, 1]. Corresponding values define
(R, G, B) values. Default value is cyan (0, 0.69, 0.96).</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float</span></dt><dd><p>Value in the range [0, 1] that specifies opacity of visualization.
1 - fully transparent, 0 - opaque.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">ndarray of float</span></dt><dd><p>Image with MB-LBP visualization.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="re2978af1b6c8-1"><span class="brackets">1</span></dt>
<dd><p>Face Detection Based on Multi-Block LBP
Representation. Lun Zhang, Rufeng Chu, Shiming Xiang, Shengcai Liao,
Stan Z. Li
<a class="reference external" href="http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf">http://www.cbsr.ia.ac.cn/users/scliao/papers/Zhang-ICB07-MBLBP.pdf</a></p>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-draw-multiblock-lbp">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_multiblock_lbp</span></code><a class="headerlink" href="#examples-using-skimage-feature-draw-multiblock-lbp" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example shows how to compute multi-block local binary pattern (MB-LBP) features as well as..."><div class="figure align-default" id="id74">
<img alt="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" src="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_multiblock_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-multiblock-local-binary-pattern-py"><span class="std std-ref">Multi-Block Local Binary Pattern for texture classification</span></a></span><a class="headerlink" href="#id74" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="peak-local-max">
<h2>peak_local_max<a class="headerlink" href="#peak-local-max" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.peak_local_max">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">peak_local_max</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">min_distance=1</em>, <em class="sig-param">threshold_abs=None</em>, <em class="sig-param">threshold_rel=None</em>, <em class="sig-param">exclude_border=True</em>, <em class="sig-param">indices=True</em>, <em class="sig-param">num_peaks=inf</em>, <em class="sig-param">footprint=None</em>, <em class="sig-param">labels=None</em>, <em class="sig-param">num_peaks_per_label=inf</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/peak.py#L25"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.peak_local_max" title="Permalink to this definition">¶</a></dt>
<dd><p>Find peaks in an image as coordinate list or boolean mask.</p>
<p>Peaks are the local maxima in a region of <cite>2 * min_distance + 1</cite>
(i.e. peaks are separated by at least <cite>min_distance</cite>).</p>
<p>If peaks are flat (i.e. multiple adjacent pixels have identical
intensities), the coordinates of all such pixels are returned.</p>
<p>If both <cite>threshold_abs</cite> and <cite>threshold_rel</cite> are provided, the maximum
of the two is chosen as the minimum intensity threshold of peaks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>min_distance</strong><span class="classifier">int, optional</span></dt><dd><p>Minimum number of pixels separating peaks in a region of <cite>2 *
min_distance + 1</cite> (i.e. peaks are separated by at least
<cite>min_distance</cite>).
To find the maximum number of peaks, use <cite>min_distance=1</cite>.</p>
</dd>
<dt><strong>threshold_abs</strong><span class="classifier">float, optional</span></dt><dd><p>Minimum intensity of peaks. By default, the absolute threshold is
the minimum intensity of the image.</p>
</dd>
<dt><strong>threshold_rel</strong><span class="classifier">float, optional</span></dt><dd><p>Minimum intensity of peaks, calculated as <cite>max(image) * threshold_rel</cite>.</p>
</dd>
<dt><strong>exclude_border</strong><span class="classifier">int, optional</span></dt><dd><p>If nonzero, <cite>exclude_border</cite> excludes peaks from
within <cite>exclude_border</cite>-pixels of the border of the image.</p>
</dd>
<dt><strong>indices</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, the output will be an array representing peak
coordinates.  If False, the output will be a boolean array shaped as
<cite>image.shape</cite> with peaks present at True elements.</p>
</dd>
<dt><strong>num_peaks</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of peaks. When the number of peaks exceeds <cite>num_peaks</cite>,
return <cite>num_peaks</cite> peaks based on highest peak intensity.</p>
</dd>
<dt><strong>footprint</strong><span class="classifier">ndarray of bools, optional</span></dt><dd><p>If provided, <cite>footprint == 1</cite> represents the local region within which
to search for peaks at every point in <cite>image</cite>.  Overrides
<cite>min_distance</cite> (also for <cite>exclude_border</cite>).</p>
</dd>
<dt><strong>labels</strong><span class="classifier">ndarray of ints, optional</span></dt><dd><p>If provided, each unique region <cite>labels == value</cite> represents a unique
region to search for peaks. Zero is reserved for background.</p>
</dd>
<dt><strong>num_peaks_per_label</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of peaks for each label.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">ndarray or ndarray of bools</span></dt><dd><ul class="simple">
<li><p>If <cite>indices = True</cite>  : (row, column, …) coordinates of peaks.</p></li>
<li><p>If <cite>indices = False</cite> : Boolean array shaped like <cite>image</cite>, with peaks
represented by True values.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The peak local maximum function returns the coordinates of local peaks
(maxima) in an image. A maximum filter is used for finding local maxima.
This operation dilates the original image. After comparison of the dilated
and original image, this function returns the coordinates or a mask of the
peaks where the dilated image equals the original image.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span>
<span class="go">array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  1.5,  0. ,  1. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[3, 4],</span>
<span class="go">       [3, 2]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[3, 2]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span> <span class="n">exclude_border</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">array([[10, 10, 10]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-peak-local-max">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max</span></code><a class="headerlink" href="#examples-using-skimage-feature-peak-local-max" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The ``peak_local_max`` function returns the coordinates of local peaks (maxima) in an image. A ..."><div class="figure align-default" id="id75">
<img alt="../_images/sphx_glr_plot_peak_local_max_thumb.png" src="../_images/sphx_glr_plot_peak_local_max_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/segmentation/plot_peak_local_max.html#sphx-glr-auto-examples-segmentation-plot-peak-local-max-py"><span class="std std-ref">Finding local maxima</span></a></span><a class="headerlink" href="#id75" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The watershed is a classical algorithm used for **segmentation**, that is, for separating diffe..."><div class="figure align-default" id="id76">
<img alt="../_images/sphx_glr_plot_watershed_thumb.png" src="../_images/sphx_glr_plot_watershed_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/segmentation/plot_watershed.html#sphx-glr-auto-examples-segmentation-plot-watershed-py"><span class="std std-ref">Watershed segmentation</span></a></span><a class="headerlink" href="#id76" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="structure-tensor">
<h2>structure_tensor<a class="headerlink" href="#structure-tensor" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.structure_tensor">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">structure_tensor</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">mode='constant'</em>, <em class="sig-param">cval=0</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L46"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.structure_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute structure tensor using sum of squared differences.</p>
<p>The structure tensor A is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>which is approximated by the weighted sum of squared differences in a local
window around each pixel in the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation used for the Gaussian kernel, which is used as a
weighting function for the local summation of squared differences.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>Axx</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Axy</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Ayy</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the structure tensor for each pixel in the input image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">structure_tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Axx</span><span class="p">,</span> <span class="n">Axy</span><span class="p">,</span> <span class="n">Ayy</span> <span class="o">=</span> <span class="n">structure_tensor</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Axx</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  4.,  0.,  4.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="structure-tensor-eigvals">
<h2>structure_tensor_eigvals<a class="headerlink" href="#structure-tensor-eigvals" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.structure_tensor_eigvals">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">structure_tensor_eigvals</code><span class="sig-paren">(</span><em class="sig-param">Axx</em>, <em class="sig-param">Axy</em>, <em class="sig-param">Ayy</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L262"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.structure_tensor_eigvals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Eigen values of structure tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>Axx</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Axy</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the structure tensor for each pixel in the input image.</p>
</dd>
<dt><strong>Ayy</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the structure tensor for each pixel in the input image.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>l1</strong><span class="classifier">ndarray</span></dt><dd><p>Larger eigen value for each input matrix.</p>
</dd>
<dt><strong>l2</strong><span class="classifier">ndarray</span></dt><dd><p>Smaller eigen value for each input matrix.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">structure_tensor</span><span class="p">,</span> <span class="n">structure_tensor_eigvals</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Axx</span><span class="p">,</span> <span class="n">Axy</span><span class="p">,</span> <span class="n">Ayy</span> <span class="o">=</span> <span class="n">structure_tensor</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">structure_tensor_eigvals</span><span class="p">(</span><span class="n">Axx</span><span class="p">,</span> <span class="n">Axy</span><span class="p">,</span> <span class="n">Ayy</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  2.,  4.,  2.,  0.],</span>
<span class="go">       [ 0.,  4.,  0.,  4.,  0.],</span>
<span class="go">       [ 0.,  2.,  4.,  2.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="hessian-matrix">
<h2>hessian_matrix<a class="headerlink" href="#hessian-matrix" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hessian_matrix">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">hessian_matrix</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">mode='constant'</em>, <em class="sig-param">cval=0</em>, <em class="sig-param">order=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L106"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hessian_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Hessian matrix.</p>
<p>The Hessian matrix is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">H</span> <span class="o">=</span> <span class="p">[</span><span class="n">Hrr</span> <span class="n">Hrc</span><span class="p">]</span>
    <span class="p">[</span><span class="n">Hrc</span> <span class="n">Hcc</span><span class="p">]</span>
</pre></div>
</div>
<p>which is computed by convolving the image with the second derivatives
of the Gaussian kernel in the respective x- and y-directions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float</span></dt><dd><p>Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
<dt><strong>order</strong><span class="classifier">{‘xy’, ‘rc’}, optional</span></dt><dd><p>This parameter allows for the use of reverse or forward order of
the image axes in gradient computation. ‘xy’ indicates the usage
of the last axis initially (Hxx, Hxy, Hyy), whilst ‘rc’ indicates
the use of the first axis initially (Hrr, Hrc, Hcc).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>Hrr</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hrc</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hcc</strong><span class="classifier">ndarray</span></dt><dd><p>Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">hessian_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Hrr</span><span class="p">,</span> <span class="n">Hrc</span><span class="p">,</span> <span class="n">Hcc</span> <span class="o">=</span> <span class="n">hessian_matrix</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">order</span> <span class="o">=</span> <span class="s1">&#39;rc&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Hrc</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0., -1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0., -1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="hessian-matrix-det">
<h2>hessian_matrix_det<a class="headerlink" href="#hessian-matrix-det" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hessian_matrix_det">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">hessian_matrix_det</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">approximate=True</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L211"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hessian_matrix_det" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the approximate Hessian Determinant over an image.</p>
<p>The 2D approximate method uses box filters over integral images to
compute the approximate Hessian Determinant, as described in <a class="reference internal" href="#r48e33a732c34-1" id="id24">[1]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">array</span></dt><dd><p>The image over which to compute Hessian Determinant.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation used for the Gaussian kernel, used for the Hessian
matrix.</p>
</dd>
<dt><strong>approximate</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code> and the image is 2D, use a much faster approximate
computation. This argument has no effect on 3D and higher images.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">array</span></dt><dd><p>The array of the Determinant of Hessians.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>For 2D images when <code class="docutils literal notranslate"><span class="pre">approximate=True</span></code>, the running time of this method
only depends on size of the image. It is independent of <cite>sigma</cite> as one
would expect. The downside is that the result for <cite>sigma</cite> less than <cite>3</cite>
is not accurate, i.e., not similar to the result obtained if someone
computed the Hessian and took its determinant.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r48e33a732c34-1"><span class="brackets"><a class="fn-backref" href="#id24">1</a></span></dt>
<dd><p>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool,
“SURF: Speeded Up Robust Features”
<a class="reference external" href="ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf">ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf</a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="hessian-matrix-eigvals">
<h2>hessian_matrix_eigvals<a class="headerlink" href="#hessian-matrix-eigvals" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.hessian_matrix_eigvals">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">hessian_matrix_eigvals</code><span class="sig-paren">(</span><em class="sig-param">H_elems</em>, <em class="sig-param">Hxy=None</em>, <em class="sig-param">Hyy=None</em>, <em class="sig-param">Hxx=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L299"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.hessian_matrix_eigvals" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Eigenvalues of Hessian matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>H_elems</strong><span class="classifier">list of ndarray</span></dt><dd><p>The upper-diagonal elements of the Hessian matrix, as returned
by <cite>hessian_matrix</cite>.</p>
</dd>
<dt><strong>Hxy</strong><span class="classifier">ndarray, deprecated</span></dt><dd><p>Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hyy</strong><span class="classifier">ndarray, deprecated</span></dt><dd><p>Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
<dt><strong>Hxx</strong><span class="classifier">ndarray, deprecated</span></dt><dd><p>Element of the Hessian matrix for each pixel in the input image.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>eigs</strong><span class="classifier">ndarray</span></dt><dd><p>The eigenvalues of the Hessian matrix, in decreasing order. The
eigenvalues are the leading dimension. That is, <code class="docutils literal notranslate"><span class="pre">eigs[i,</span> <span class="pre">j,</span> <span class="pre">k]</span></code>
contains the ith-largest eigenvalue at position (j, k).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">hessian_matrix</span><span class="p">,</span> <span class="n">hessian_matrix_eigvals</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H_elems</span> <span class="o">=</span> <span class="n">hessian_matrix</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;rc&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hessian_matrix_eigvals</span><span class="p">(</span><span class="n">H_elems</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([[ 0.,  0.,  2.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 2.,  0., -2.,  0.,  2.],</span>
<span class="go">       [ 0.,  1.,  0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  2.,  0.,  0.]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="shape-index">
<h2>shape_index<a class="headerlink" href="#shape-index" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.shape_index">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">shape_index</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">mode='constant'</em>, <em class="sig-param">cval=0</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L352"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.shape_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the shape index.</p>
<p>The shape index, as defined by Koenderink &amp; van Doorn <a class="reference internal" href="#rc8faae48965f-1" id="id26">[1]</a>, is a
single valued measure of local curvature, assuming the image as a 3D plane
with intensities representing heights.</p>
<p>It is derived from the eigen values of the Hessian, and its
value ranges from -1 to 1 (and is undefined (=NaN) in <em>flat</em> regions),
with following ranges representing following shapes:</p>
<table class="docutils align-default" id="id77">
<caption><span class="caption-text">Ranges of the shape index and corresponding shapes.</span><a class="headerlink" href="#id77" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 59%" />
<col style="width: 41%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Interval (s in …)</p></th>
<th class="head"><p>Shape</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>[  -1, -7/8)</p></td>
<td><p>Spherical cup</p></td>
</tr>
<tr class="row-odd"><td><p>[-7/8, -5/8)</p></td>
<td><p>Through</p></td>
</tr>
<tr class="row-even"><td><p>[-5/8, -3/8)</p></td>
<td><p>Rut</p></td>
</tr>
<tr class="row-odd"><td><p>[-3/8, -1/8)</p></td>
<td><p>Saddle rut</p></td>
</tr>
<tr class="row-even"><td><p>[-1/8, +1/8)</p></td>
<td><p>Saddle</p></td>
</tr>
<tr class="row-odd"><td><p>[+1/8, +3/8)</p></td>
<td><p>Saddle ridge</p></td>
</tr>
<tr class="row-even"><td><p>[+3/8, +5/8)</p></td>
<td><p>Ridge</p></td>
</tr>
<tr class="row-odd"><td><p>[+5/8, +7/8)</p></td>
<td><p>Dome</p></td>
</tr>
<tr class="row-even"><td><p>[+7/8,   +1]</p></td>
<td><p>Spherical cap</p></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation used for the Gaussian kernel, which is used for
smoothing the input data before Hessian eigen value calculation.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>s</strong><span class="classifier">ndarray</span></dt><dd><p>Shape index</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rc8faae48965f-1"><span class="brackets"><a class="fn-backref" href="#id26">1</a></span></dt>
<dd><p>Koenderink, J. J. &amp; van Doorn, A. J.,
“Surface shape and curvature scales”,
Image and Vision Computing, 1992, 10, 557-564.
DOI:10.1016/0262-8856(92)90076-F</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">shape_index</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">shape_index</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span>
<span class="go">array([[ nan,  nan, -0.5,  nan,  nan],</span>
<span class="go">       [ nan, -0. ,  nan, -0. ,  nan],</span>
<span class="go">       [-0.5,  nan, -1. ,  nan, -0.5],</span>
<span class="go">       [ nan, -0. ,  nan, -0. ,  nan],</span>
<span class="go">       [ nan,  nan, -0.5,  nan,  nan]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-shape-index">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.shape_index</span></code><a class="headerlink" href="#examples-using-skimage-feature-shape-index" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="The shape index is a single valued measure of local curvature, derived from the eigen values of..."><div class="figure align-default" id="id78">
<img alt="../_images/sphx_glr_plot_shape_index_thumb.png" src="../_images/sphx_glr_plot_shape_index_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_shape_index.html#sphx-glr-auto-examples-features-detection-plot-shape-index-py"><span class="std std-ref">Shape Index</span></a></span><a class="headerlink" href="#id78" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="corner-kitchen-rosenfeld">
<h2>corner_kitchen_rosenfeld<a class="headerlink" href="#corner-kitchen-rosenfeld" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_kitchen_rosenfeld">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_kitchen_rosenfeld</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">mode='constant'</em>, <em class="sig-param">cval=0</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L424"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_kitchen_rosenfeld" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Kitchen and Rosenfeld corner measure response image.</p>
<p>The corner measure is calculated as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">imxx</span> <span class="o">*</span> <span class="n">imy</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">imyy</span> <span class="o">*</span> <span class="n">imx</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">imxy</span> <span class="o">*</span> <span class="n">imx</span> <span class="o">*</span> <span class="n">imy</span><span class="p">)</span>
    <span class="o">/</span> <span class="p">(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Where imx and imy are the first and imxx, imxy, imyy the second
derivatives.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>response</strong><span class="classifier">ndarray</span></dt><dd><p>Kitchen and Rosenfeld response image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="corner-harris">
<h2>corner_harris<a class="headerlink" href="#corner-harris" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_harris">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_harris</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">method='k'</em>, <em class="sig-param">k=0.05</em>, <em class="sig-param">eps=1e-06</em>, <em class="sig-param">sigma=1</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L467"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_harris" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Harris corner measure response image.</p>
<p>This corner detector uses information from the auto-correlation matrix A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="p">(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)</span>   <span class="p">(</span><span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>   <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>Where imx and imy are first derivatives, averaged with a gaussian filter.
The corner measure is then defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">-</span> <span class="n">k</span> <span class="o">*</span> <span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
<p>or:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2</span> <span class="o">*</span> <span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘k’, ‘eps’}, optional</span></dt><dd><p>Method to compute the response image from the auto-correlation matrix.</p>
</dd>
<dt><strong>k</strong><span class="classifier">float, optional</span></dt><dd><p>Sensitivity factor to separate corners from edges, typically in range
<cite>[0, 0.2]</cite>. Small values of k result in detection of sharp corners.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float, optional</span></dt><dd><p>Normalisation factor (Noble’s corner measure).</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>response</strong><span class="classifier">ndarray</span></dt><dd><p>Harris response image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rc19c7843bb6d-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="http://kiwi.cs.dal.ca/~dparks/CornerDetection/harris.htm">http://kiwi.cs.dal.ca/~dparks/CornerDetection/harris.htm</a></p>
</dd>
<dt class="label" id="rc19c7843bb6d-2"><span class="brackets">2</span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Corner_detection">http://en.wikipedia.org/wiki/Corner_detection</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_harris</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">square</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 7],</span>
<span class="go">       [7, 2],</span>
<span class="go">       [7, 7]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-corner-harris">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_harris</span></code><a class="headerlink" href="#examples-using-skimage-feature-corner-harris" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of co..."><div class="figure align-default" id="id79">
<img alt="../_images/sphx_glr_plot_corner_thumb.png" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></span><a class="headerlink" href="#id79" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure align-default" id="id80">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span><a class="headerlink" href="#id80" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure align-default" id="id81">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span><a class="headerlink" href="#id81" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="corner-shi-tomasi">
<h2>corner_shi_tomasi<a class="headerlink" href="#corner-shi-tomasi" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_shi_tomasi">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_shi_tomasi</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L548"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_shi_tomasi" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Shi-Tomasi (Kanade-Tomasi) corner measure response image.</p>
<p>This corner detector uses information from the auto-correlation matrix A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="p">(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)</span>   <span class="p">(</span><span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>   <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>Where imx and imy are first derivatives, averaged with a gaussian filter.
The corner measure is then defined as the smaller eigenvalue of A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">((</span><span class="n">Axx</span> <span class="o">+</span> <span class="n">Ayy</span><span class="p">)</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">((</span><span class="n">Axx</span> <span class="o">-</span> <span class="n">Ayy</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">Axy</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>response</strong><span class="classifier">ndarray</span></dt><dd><p>Shi-Tomasi response image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r26d4c89afc0d-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="http://kiwi.cs.dal.ca/~dparks/CornerDetection/harris.htm">http://kiwi.cs.dal.ca/~dparks/CornerDetection/harris.htm</a></p>
</dd>
<dt class="label" id="r26d4c89afc0d-2"><span class="brackets">2</span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Corner_detection">http://en.wikipedia.org/wiki/Corner_detection</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_shi_tomasi</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_shi_tomasi</span><span class="p">(</span><span class="n">square</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 7],</span>
<span class="go">       [7, 2],</span>
<span class="go">       [7, 7]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-foerstner">
<h2>corner_foerstner<a class="headerlink" href="#corner-foerstner" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_foerstner">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_foerstner</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">sigma=1</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L611"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_foerstner" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Foerstner corner measure response image.</p>
<p>This corner detector uses information from the auto-correlation matrix A:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="p">[(</span><span class="n">imx</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>   <span class="p">(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axx</span> <span class="n">Axy</span><span class="p">]</span>
    <span class="p">[(</span><span class="n">imx</span><span class="o">*</span><span class="n">imy</span><span class="p">)</span>   <span class="p">(</span><span class="n">imy</span><span class="o">**</span><span class="mi">2</span><span class="p">)]</span>   <span class="p">[</span><span class="n">Axy</span> <span class="n">Ayy</span><span class="p">]</span>
</pre></div>
</div>
<p>Where imx and imy are first derivatives, averaged with a gaussian filter.
The corner measure is then defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>           <span class="p">(</span><span class="n">size</span> <span class="n">of</span> <span class="n">error</span> <span class="n">ellipse</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">det</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">/</span> <span class="n">trace</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>    <span class="p">(</span><span class="n">roundness</span> <span class="n">of</span> <span class="n">error</span> <span class="n">ellipse</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation used for the Gaussian kernel, which is used as
weighting function for the auto-correlation matrix.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>w</strong><span class="classifier">ndarray</span></dt><dd><p>Error ellipse sizes.</p>
</dd>
<dt><strong>q</strong><span class="classifier">ndarray</span></dt><dd><p>Roundness of error ellipse.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r9d429c80f73f-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/foerstner87.fast.pdf">http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/foerstner87.fast.pdf</a></p>
</dd>
<dt class="label" id="r9d429c80f73f-2"><span class="brackets">2</span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Corner_detection">http://en.wikipedia.org/wiki/Corner_detection</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_foerstner</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">corner_foerstner</span><span class="p">(</span><span class="n">square</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_thresh</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roundness_thresh</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">foerstner</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">&gt;</span> <span class="n">roundness_thresh</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">w</span> <span class="o">&gt;</span> <span class="n">accuracy_thresh</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">foerstner</span><span class="p">,</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 7],</span>
<span class="go">       [7, 2],</span>
<span class="go">       [7, 7]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-subpix">
<h2>corner_subpix<a class="headerlink" href="#corner-subpix" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_subpix">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_subpix</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">corners</em>, <em class="sig-param">window_size=11</em>, <em class="sig-param">alpha=0.99</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L754"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_subpix" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine subpixel position of corners.</p>
<p>A statistical test decides whether the corner is defined as the
intersection of two edges or a single peak. Depending on the classification
result, the subpixel corner location is determined based on the local
covariance of the grey-values. If the significance level for either
statistical test is not sufficient, the corner cannot be classified, and
the output subpixel position is set to NaN.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>corners</strong><span class="classifier">(N, 2) ndarray</span></dt><dd><p>Corner coordinates <cite>(row, col)</cite>.</p>
</dd>
<dt><strong>window_size</strong><span class="classifier">int, optional</span></dt><dd><p>Search window size for subpixel estimation.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Significance level for corner classification.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>positions</strong><span class="classifier">(N, 2) ndarray</span></dt><dd><p>Subpixel corner positions. NaN for “not classified” corners.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="ra33874b5943a-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/">http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/</a>           foerstner87.fast.pdf</p>
</dd>
<dt class="label" id="ra33874b5943a-2"><span class="brackets">2</span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Corner_detection">http://en.wikipedia.org/wiki/Corner_detection</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_harris</span><span class="p">,</span> <span class="n">corner_peaks</span><span class="p">,</span> <span class="n">corner_subpix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="p">[</span><span class="mi">5</span><span class="p">:,</span> <span class="mi">5</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],</span>
<span class="go">       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coords</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coords_subpix</span> <span class="o">=</span> <span class="n">corner_subpix</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coords_subpix</span>
<span class="go">array([[ 4.5,  4.5]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-corner-subpix">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_subpix</span></code><a class="headerlink" href="#examples-using-skimage-feature-corner-subpix" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of co..."><div class="figure align-default" id="id82">
<img alt="../_images/sphx_glr_plot_corner_thumb.png" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></span><a class="headerlink" href="#id82" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure align-default" id="id83">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span><a class="headerlink" href="#id83" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="corner-peaks">
<h2>corner_peaks<a class="headerlink" href="#corner-peaks" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_peaks">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_peaks</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">min_distance=1</em>, <em class="sig-param">threshold_abs=None</em>, <em class="sig-param">threshold_rel=0.1</em>, <em class="sig-param">exclude_border=True</em>, <em class="sig-param">indices=True</em>, <em class="sig-param">num_peaks=inf</em>, <em class="sig-param">footprint=None</em>, <em class="sig-param">labels=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L929"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_peaks" title="Permalink to this definition">¶</a></dt>
<dd><p>Find corners in corner measure response image.</p>
<p>This differs from <cite>skimage.feature.peak_local_max</cite> in that it suppresses
multiple connected peaks with the same accumulator value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>*</strong><span class="classifier">*</span></dt><dd><p>See <a class="reference internal" href="#skimage.feature.peak_local_max" title="skimage.feature.peak_local_max"><code class="xref py py-meth docutils literal notranslate"><span class="pre">skimage.feature.peak_local_max()</span></code></a>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">peak_local_max</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  1.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  1.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">peak_local_max</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="go">array([[3, 3],</span>
<span class="go">       [3, 2],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [2, 2]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="go">array([[2, 2]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-corner-peaks">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.corner_peaks</span></code><a class="headerlink" href="#examples-using-skimage-feature-corner-peaks" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of co..."><div class="figure align-default" id="id84">
<img alt="../_images/sphx_glr_plot_corner_thumb.png" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></span><a class="headerlink" href="#id84" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure align-default" id="id85">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span><a class="headerlink" href="#id85" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure align-default" id="id86">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span><a class="headerlink" href="#id86" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="corner-moravec">
<h2>corner_moravec<a class="headerlink" href="#corner-moravec" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_moravec">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_moravec</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">window_size=1</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L983"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_moravec" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Moravec corner measure response image.</p>
<p>This is one of the simplest corner detectors and is comparatively fast but
has several limitations (e.g. not rotation invariant).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>window_size</strong><span class="classifier">int, optional</span></dt><dd><p>Window size.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>response</strong><span class="classifier">ndarray</span></dt><dd><p>Moravec response image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rdf16f0a1a068-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="http://kiwi.cs.dal.ca/~dparks/CornerDetection/moravec.htm">http://kiwi.cs.dal.ca/~dparks/CornerDetection/moravec.htm</a></p>
</dd>
<dt class="label" id="rdf16f0a1a068-2"><span class="brackets">2</span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Corner_detection">http://en.wikipedia.org/wiki/Corner_detection</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_moravec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_moravec</span><span class="p">(</span><span class="n">square</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 2, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-fast">
<h2>corner_fast<a class="headerlink" href="#corner-fast" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_fast">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_fast</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">n=12</em>, <em class="sig-param">threshold=0.15</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L691"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_fast" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract FAST corners for a given image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>n</strong><span class="classifier">int</span></dt><dd><p>Minimum number of consecutive pixels out of 16 pixels on the circle
that should all be either brighter or darker w.r.t testpixel.
A point c on the circle is darker w.r.t test pixel p if
<cite>Ic &lt; Ip - threshold</cite> and brighter if <cite>Ic &gt; Ip + threshold</cite>. Also
stands for the n in <cite>FAST-n</cite> corner detector.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Threshold used in deciding whether the pixels on the circle are
brighter, darker or similar w.r.t. the test pixel. Decrease the
threshold when more corners are desired and vice-versa.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>response</strong><span class="classifier">ndarray</span></dt><dd><p>FAST corner response image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r92fff83e7342-1"><span class="brackets">1</span></dt>
<dd><p>Edward Rosten and Tom Drummond
“Machine Learning for high-speed corner detection”,
<a class="reference external" href="http://www.edwardrosten.com/work/rosten_2006_machine.pdf">http://www.edwardrosten.com/work/rosten_2006_machine.pdf</a></p>
</dd>
<dt class="label" id="r92fff83e7342-2"><span class="brackets">2</span></dt>
<dd><p>Wikipedia, “Features from accelerated segment test”,
<a class="reference external" href="https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test">https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">corner_fast</span><span class="p">,</span> <span class="n">corner_peaks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_fast</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[3, 3],</span>
<span class="go">       [3, 8],</span>
<span class="go">       [8, 3],</span>
<span class="go">       [8, 8]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="corner-orientations">
<h2>corner_orientations<a class="headerlink" href="#corner-orientations" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.corner_orientations">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">corner_orientations</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">corners</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/corner.py#L1031"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.corner_orientations" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the orientation of corners.</p>
<p>The orientation of corners is computed using the first order central moment
i.e. the center of mass approach. The corner orientation is the angle of
the vector from the corner coordinate to the intensity centroid in the
local neighborhood around the corner calculated using first order central
moment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D array</span></dt><dd><p>Input grayscale image.</p>
</dd>
<dt><strong>corners</strong><span class="classifier">(N, 2) array</span></dt><dd><p>Corner coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2D array</span></dt><dd><p>Mask defining the local neighborhood of the corner used for the
calculation of the central moment.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>orientations</strong><span class="classifier">(N, 1) array</span></dt><dd><p>Orientations of corners in the range [-pi, pi].</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r0592d7afdba5-1"><span class="brackets">1</span></dt>
<dd><p>Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski
“ORB : An efficient alternative to SIFT and SURF”
<a class="reference external" href="http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf">http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf</a></p>
</dd>
<dt class="label" id="r0592d7afdba5-2"><span class="brackets">2</span></dt>
<dd><p>Paul L. Rosin, “Measuring Corner Properties”
<a class="reference external" href="http://users.cs.cf.ac.uk/Paul.Rosin/corner2.pdf">http://users.cs.cf.ac.uk/Paul.Rosin/corner2.pdf</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.morphology</span> <span class="k">import</span> <span class="n">octagon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="p">(</span><span class="n">corner_fast</span><span class="p">,</span> <span class="n">corner_peaks</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">corner_orientations</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corners</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_fast</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corners</span>
<span class="go">array([[3, 3],</span>
<span class="go">       [3, 8],</span>
<span class="go">       [8, 3],</span>
<span class="go">       [8, 8]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">orientations</span> <span class="o">=</span> <span class="n">corner_orientations</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="n">corners</span><span class="p">,</span> <span class="n">octagon</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">rad2deg</span><span class="p">(</span><span class="n">orientations</span><span class="p">)</span>
<span class="go">array([  45.,  135.,  -45., -135.])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="match-template">
<h2>match_template<a class="headerlink" href="#match-template" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.match_template">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">match_template</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">template</em>, <em class="sig-param">pad_input=False</em>, <em class="sig-param">mode='constant'</em>, <em class="sig-param">constant_values=0</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/template.py#L32"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.match_template" title="Permalink to this definition">¶</a></dt>
<dd><p>Match a template to a 2-D or 3-D image using normalized correlation.</p>
<p>The output is an array with values between -1.0 and 1.0. The value at a
given position corresponds to the correlation coefficient between the image
and the template.</p>
<p>For <cite>pad_input=True</cite> matches correspond to the center and otherwise to the
top-left corner of the template. To find the best match you must search for
peaks in the response (output) image.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N[, D]) array</span></dt><dd><p>2-D or 3-D input image.</p>
</dd>
<dt><strong>template</strong><span class="classifier">(m, n[, d]) array</span></dt><dd><p>Template to locate. It must be <cite>(m &lt;= M, n &lt;= N[, d &lt;= D])</cite>.</p>
</dd>
<dt><strong>pad_input</strong><span class="classifier">bool</span></dt><dd><p>If True, pad <cite>image</cite> so that output is the same size as the image, and
output values correspond to the template center. Otherwise, the output
is an array with shape <cite>(M - m + 1, N - n + 1)</cite> for an <cite>(M, N)</cite> image
and an <cite>(m, n)</cite> template, and matches correspond to origin
(top-left corner) of the template.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">see <cite>numpy.pad</cite>, optional</span></dt><dd><p>Padding mode.</p>
</dd>
<dt><strong>constant_values</strong><span class="classifier">see <cite>numpy.pad</cite>, optional</span></dt><dd><p>Constant values used in conjunction with <code class="docutils literal notranslate"><span class="pre">mode='constant'</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">array</span></dt><dd><p>Response image with correlation coefficients.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Details on the cross-correlation are presented in <a class="reference internal" href="#r7bfca17c0278-1" id="id42">[1]</a>. This implementation
uses FFT convolutions of the image and the template. Reference <a class="reference internal" href="#r7bfca17c0278-2" id="id43">[2]</a>
presents similar derivations but the approximation presented in this
reference is not used in our implementation.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r7bfca17c0278-1"><span class="brackets"><a class="fn-backref" href="#id42">1</a></span></dt>
<dd><p>J. P. Lewis, “Fast Normalized Cross-Correlation”, Industrial Light
and Magic.</p>
</dd>
<dt class="label" id="r7bfca17c0278-2"><span class="brackets"><a class="fn-backref" href="#id43">2</a></span></dt>
<dd><p>Briechle and Hanebeck, “Template Matching using Fast Normalized
Cross Correlation”, Proceedings of the SPIE (2001).
DOI:10.1117/12.421129</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span>
<span class="go">array([[ 0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  1.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0., -1.,  0.],</span>
<span class="go">       [ 0.,  0.,  0.,  0.,  0.,  0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">match_template</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">array([[ 1.   , -0.125,  0.   ,  0.   ],</span>
<span class="go">       [-0.125, -0.125,  0.   ,  0.   ],</span>
<span class="go">       [ 0.   ,  0.   ,  0.125,  0.125],</span>
<span class="go">       [ 0.   ,  0.   ,  0.125, -1.   ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">match_template</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">template</span><span class="p">,</span> <span class="n">pad_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">array([[-0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ],</span>
<span class="go">       [-0.125,  1.   , -0.125,  0.   ,  0.   ,  0.   ],</span>
<span class="go">       [-0.125, -0.125, -0.125,  0.   ,  0.   ,  0.   ],</span>
<span class="go">       [ 0.   ,  0.   ,  0.   ,  0.125,  0.125,  0.125],</span>
<span class="go">       [ 0.   ,  0.   ,  0.   ,  0.125, -1.   ,  0.125],</span>
<span class="go">       [ 0.   ,  0.   ,  0.   ,  0.125,  0.125,  0.125]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-match-template">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_template</span></code><a class="headerlink" href="#examples-using-skimage-feature-match-template" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="We use template matching to identify the occurrence of an image patch (in this case, a sub-imag..."><div class="figure align-default" id="id87">
<img alt="../_images/sphx_glr_plot_template_thumb.png" src="../_images/sphx_glr_plot_template_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_template.html#sphx-glr-auto-examples-features-detection-plot-template-py"><span class="std std-ref">Template Matching</span></a></span><a class="headerlink" href="#id87" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="register-translation">
<h2>register_translation<a class="headerlink" href="#register-translation" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.register_translation">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">register_translation</code><span class="sig-paren">(</span><em class="sig-param">src_image</em>, <em class="sig-param">target_image</em>, <em class="sig-param">upsample_factor=1</em>, <em class="sig-param">space='real'</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/register_translation.py#L109"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.register_translation" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient subpixel image translation registration by cross-correlation.</p>
<p>This code gives the same precision as the FFT upsampled cross-correlation
in a fraction of the computation time and with reduced memory requirements.
It obtains an initial estimate of the cross-correlation peak by an FFT and
then refines the shift estimation by upsampling the DFT only in a small
neighborhood of that estimate by means of a matrix-multiply DFT.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>src_image</strong><span class="classifier">ndarray</span></dt><dd><p>Reference image.</p>
</dd>
<dt><strong>target_image</strong><span class="classifier">ndarray</span></dt><dd><p>Image to register.  Must be same dimensionality as <code class="docutils literal notranslate"><span class="pre">src_image</span></code>.</p>
</dd>
<dt><strong>upsample_factor</strong><span class="classifier">int, optional</span></dt><dd><p>Upsampling factor. Images will be registered to within
<code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">upsample_factor</span></code> of a pixel. For example
<code class="docutils literal notranslate"><span class="pre">upsample_factor</span> <span class="pre">==</span> <span class="pre">20</span></code> means the images will be registered
within 1/20th of a pixel.  Default is 1 (no upsampling)</p>
</dd>
<dt><strong>space</strong><span class="classifier">string, one of “real” or “fourier”, optional</span></dt><dd><p>Defines how the algorithm interprets input data.  “real” means data
will be FFT’d to compute the correlation, while “fourier” data will
bypass FFT of input data.  Case insensitive.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>shifts</strong><span class="classifier">ndarray</span></dt><dd><p>Shift vector (in pixels) required to register <code class="docutils literal notranslate"><span class="pre">target_image</span></code> with
<code class="docutils literal notranslate"><span class="pre">src_image</span></code>.  Axis ordering is consistent with numpy (e.g. Z, Y, X)</p>
</dd>
<dt><strong>error</strong><span class="classifier">float</span></dt><dd><p>Translation invariant normalized RMS error between <code class="docutils literal notranslate"><span class="pre">src_image</span></code> and
<code class="docutils literal notranslate"><span class="pre">target_image</span></code>.</p>
</dd>
<dt><strong>phasediff</strong><span class="classifier">float</span></dt><dd><p>Global phase difference between the two images (should be
zero if images are non-negative).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r690c39d932a8-1"><span class="brackets">1</span></dt>
<dd><p>Manuel Guizar-Sicairos, Samuel T. Thurman, and James R. Fienup,
“Efficient subpixel image registration algorithms,”
Optics Letters 33, 156-158 (2008). DOI:10.1364/OL.33.000156</p>
</dd>
<dt class="label" id="r690c39d932a8-2"><span class="brackets">2</span></dt>
<dd><p>James R. Fienup, “Invariant error metrics for image reconstruction”
Optics Letters 36, 8352-8357 (1997). DOI:10.1364/AO.36.008352</p>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-register-translation">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.register_translation</span></code><a class="headerlink" href="#examples-using-skimage-feature-register-translation" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we use phase correlation to identify the relative shift between two similar-si..."><div class="figure align-default" id="id88">
<img alt="../_images/sphx_glr_plot_register_translation_thumb.png" src="../_images/sphx_glr_plot_register_translation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_register_translation.html#sphx-glr-auto-examples-transform-plot-register-translation-py"><span class="std std-ref">Cross-Correlation (Phase Correlation)</span></a></span><a class="headerlink" href="#id88" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="match-descriptors">
<h2>match_descriptors<a class="headerlink" href="#match-descriptors" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.match_descriptors">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">match_descriptors</code><span class="sig-paren">(</span><em class="sig-param">descriptors1</em>, <em class="sig-param">descriptors2</em>, <em class="sig-param">metric=None</em>, <em class="sig-param">p=2</em>, <em class="sig-param">max_distance=inf</em>, <em class="sig-param">cross_check=True</em>, <em class="sig-param">max_ratio=1.0</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/match.py#L5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.match_descriptors" title="Permalink to this definition">¶</a></dt>
<dd><p>Brute-force matching of descriptors.</p>
<p>For each descriptor in the first set this matcher finds the closest
descriptor in the second set (and vice-versa in the case of enabled
cross-checking).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>descriptors1</strong><span class="classifier">(M, P) array</span></dt><dd><p>Binary descriptors of size P about M keypoints in the first image.</p>
</dd>
<dt><strong>descriptors2</strong><span class="classifier">(N, P) array</span></dt><dd><p>Binary descriptors of size P about N keypoints in the second image.</p>
</dd>
<dt><strong>metric</strong><span class="classifier">{‘euclidean’, ‘cityblock’, ‘minkowski’, ‘hamming’, …} , optional</span></dt><dd><p>The metric to compute the distance between two descriptors. See
<cite>scipy.spatial.distance.cdist</cite> for all possible types. The hamming
distance should be used for binary descriptors. By default the L2-norm
is used for all descriptors of dtype float or double and the Hamming
distance is used for binary descriptors automatically.</p>
</dd>
<dt><strong>p</strong><span class="classifier">int, optional</span></dt><dd><p>The p-norm to apply for <code class="docutils literal notranslate"><span class="pre">metric='minkowski'</span></code>.</p>
</dd>
<dt><strong>max_distance</strong><span class="classifier">float, optional</span></dt><dd><p>Maximum allowed distance between descriptors of two keypoints
in separate images to be regarded as a match.</p>
</dd>
<dt><strong>cross_check</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, the matched keypoints are returned after cross checking i.e. a
matched pair (keypoint1, keypoint2) is returned if keypoint2 is the
best match for keypoint1 in second image and keypoint1 is the best
match for keypoint2 in first image.</p>
</dd>
<dt><strong>max_ratio</strong><span class="classifier">float, optional</span></dt><dd><p>Maximum ratio of distances between first and second closest descriptor
in the second set of descriptors. This threshold is useful to filter
ambiguous matches between the two descriptor sets. The choice of this
value depends on the statistics of the chosen descriptor, e.g.,
for SIFT descriptors a value of 0.8 is usually chosen, see
D.G. Lowe, “Distinctive Image Features from Scale-Invariant Keypoints”,
International Journal of Computer Vision, 2004.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>matches</strong><span class="classifier">(Q, 2) array</span></dt><dd><p>Indices of corresponding matches in first and second set of
descriptors, where <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">0]</span></code> denote the indices in the first
and <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">1]</span></code> the indices in the second set of descriptors.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-match-descriptors">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.match_descriptors</span></code><a class="headerlink" href="#examples-using-skimage-feature-match-descriptors" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the ORB feature detection and binary description algorithm. It uses a..."><div class="figure align-default" id="id89">
<img alt="../_images/sphx_glr_plot_orb_thumb.png" src="../_images/sphx_glr_plot_orb_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_orb.html#sphx-glr-auto-examples-features-detection-plot-orb-py"><span class="std std-ref">ORB feature detector and binary descriptor</span></a></span><a class="headerlink" href="#id89" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure align-default" id="id90">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span><a class="headerlink" href="#id90" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to robustly estimate epipolar geometry between two views using sp..."><div class="figure align-default" id="id91">
<img alt="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" src="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_fundamental_matrix.html#sphx-glr-auto-examples-transform-plot-fundamental-matrix-py"><span class="std std-ref">Fundamental matrix estimation</span></a></span><a class="headerlink" href="#id91" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="plot-matches">
<h2>plot_matches<a class="headerlink" href="#plot-matches" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.plot_matches">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">plot_matches</code><span class="sig-paren">(</span><em class="sig-param">ax</em>, <em class="sig-param">image1</em>, <em class="sig-param">image2</em>, <em class="sig-param">keypoints1</em>, <em class="sig-param">keypoints2</em>, <em class="sig-param">matches</em>, <em class="sig-param">keypoints_color='k'</em>, <em class="sig-param">matches_color=None</em>, <em class="sig-param">only_matches=False</em>, <em class="sig-param">alignment='horizontal'</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/util.py#L43"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.plot_matches" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot matched features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>ax</strong><span class="classifier">matplotlib.axes.Axes</span></dt><dd><p>Matches and image are drawn in this ax.</p>
</dd>
<dt><strong>image1</strong><span class="classifier">(N, M [, 3]) array</span></dt><dd><p>First grayscale or color image.</p>
</dd>
<dt><strong>image2</strong><span class="classifier">(N, M [, 3]) array</span></dt><dd><p>Second grayscale or color image.</p>
</dd>
<dt><strong>keypoints1</strong><span class="classifier">(K1, 2) array</span></dt><dd><p>First keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>keypoints2</strong><span class="classifier">(K2, 2) array</span></dt><dd><p>Second keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>matches</strong><span class="classifier">(Q, 2) array</span></dt><dd><p>Indices of corresponding matches in first and second set of
descriptors, where <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">0]</span></code> denote the indices in the first
and <code class="docutils literal notranslate"><span class="pre">matches[:,</span> <span class="pre">1]</span></code> the indices in the second set of descriptors.</p>
</dd>
<dt><strong>keypoints_color</strong><span class="classifier">matplotlib color, optional</span></dt><dd><p>Color for keypoint locations.</p>
</dd>
<dt><strong>matches_color</strong><span class="classifier">matplotlib color, optional</span></dt><dd><p>Color for lines which connect keypoint matches. By default the
color is chosen randomly.</p>
</dd>
<dt><strong>only_matches</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to only plot matches and not plot the keypoint locations.</p>
</dd>
<dt><strong>alignment</strong><span class="classifier">{‘horizontal’, ‘vertical’}, optional</span></dt><dd><p>Whether to show images side by side, <code class="docutils literal notranslate"><span class="pre">'horizontal'</span></code>, or one above
the other, <code class="docutils literal notranslate"><span class="pre">'vertical'</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-plot-matches">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.plot_matches</span></code><a class="headerlink" href="#examples-using-skimage-feature-plot-matches" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the ORB feature detection and binary description algorithm. It uses a..."><div class="figure align-default" id="id92">
<img alt="../_images/sphx_glr_plot_orb_thumb.png" src="../_images/sphx_glr_plot_orb_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_orb.html#sphx-glr-auto-examples-features-detection-plot-orb-py"><span class="std std-ref">ORB feature detector and binary descriptor</span></a></span><a class="headerlink" href="#id92" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of re..."><div class="figure align-default" id="id93">
<img alt="../_images/sphx_glr_plot_brief_thumb.png" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></span><a class="headerlink" href="#id93" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to robustly estimate epipolar geometry between two views using sp..."><div class="figure align-default" id="id94">
<img alt="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" src="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_fundamental_matrix.html#sphx-glr-auto-examples-transform-plot-fundamental-matrix-py"><span class="std std-ref">Fundamental matrix estimation</span></a></span><a class="headerlink" href="#id94" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from di..."><div class="figure align-default" id="id95">
<img alt="../_images/sphx_glr_plot_matching_thumb.png" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></span><a class="headerlink" href="#id95" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="blob-dog">
<h2>blob_dog<a class="headerlink" href="#blob-dog" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.blob_dog">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">blob_dog</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">min_sigma=1</em>, <em class="sig-param">max_sigma=50</em>, <em class="sig-param">sigma_ratio=1.6</em>, <em class="sig-param">threshold=2.0</em>, <em class="sig-param">overlap=0.5</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/blob.py#L169"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.blob_dog" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds blobs in the given grayscale image.</p>
<p>Blobs are found using the Difference of Gaussian (DoG) method <a class="reference internal" href="#rf5218630e229-1" id="id48">[1]</a>.
For each blob found, the method returns its coordinates and the standard
deviation of the Gaussian kernel that detected the blob.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D or 3D ndarray</span></dt><dd><p>Input grayscale image, blobs are assumed to be light on dark
background (white on black).</p>
</dd>
<dt><strong>min_sigma</strong><span class="classifier">float, optional</span></dt><dd><p>The minimum standard deviation for Gaussian Kernel. Keep this low to
detect smaller blobs.</p>
</dd>
<dt><strong>max_sigma</strong><span class="classifier">float, optional</span></dt><dd><p>The maximum standard deviation for Gaussian Kernel. Keep this high to
detect larger blobs.</p>
</dd>
<dt><strong>sigma_ratio</strong><span class="classifier">float, optional</span></dt><dd><p>The ratio between the standard deviation of Gaussian Kernels used for
computing the Difference of Gaussians</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional.</span></dt><dd><p>The absolute lower bound for scale space maxima. Local maxima smaller
than thresh are ignored. Reduce this to detect blobs with less
intensities.</p>
</dd>
<dt><strong>overlap</strong><span class="classifier">float, optional</span></dt><dd><p>A value between 0 and 1. If the area of two blobs overlaps by a
fraction greater than <cite>threshold</cite>, the smaller blob is eliminated.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>A</strong><span class="classifier">(n, image.ndim + 1) ndarray</span></dt><dd><p>A 2d array with each row representing 3 values for a 2D image,
and 4 values for a 3D image: <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code> or <code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code>
where <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c)</span></code> or <code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c)</span></code> are coordinates of the blob and
<code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the standard deviation of the Gaussian kernel which
detected the blob.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The radius of each blob is approximately <span class="math notranslate nohighlight">\(\sqrt{2}\sigma\)</span> for
a 2-D image and <span class="math notranslate nohighlight">\(\sqrt{3}\sigma\)</span> for a 3-D image.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rf5218630e229-1"><span class="brackets"><a class="fn-backref" href="#id48">1</a></span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach">http://en.wikipedia.org/wiki/Blob_detection#The_difference_of_Gaussians_approach</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="o">.</span><span class="n">blob_dog</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">(),</span> <span class="n">threshold</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_sigma</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="go">array([[ 267.      ,  359.      ,   16.777216],</span>
<span class="go">       [ 267.      ,  115.      ,   10.48576 ],</span>
<span class="go">       [ 263.      ,  302.      ,   16.777216],</span>
<span class="go">       [ 263.      ,  245.      ,   16.777216],</span>
<span class="go">       [ 261.      ,  173.      ,   16.777216],</span>
<span class="go">       [ 260.      ,   46.      ,   16.777216],</span>
<span class="go">       [ 198.      ,  155.      ,   10.48576 ],</span>
<span class="go">       [ 196.      ,   43.      ,   10.48576 ],</span>
<span class="go">       [ 195.      ,  102.      ,   16.777216],</span>
<span class="go">       [ 194.      ,  277.      ,   16.777216],</span>
<span class="go">       [ 193.      ,  213.      ,   16.777216],</span>
<span class="go">       [ 185.      ,  347.      ,   16.777216],</span>
<span class="go">       [ 128.      ,  154.      ,   10.48576 ],</span>
<span class="go">       [ 127.      ,  102.      ,   10.48576 ],</span>
<span class="go">       [ 125.      ,  208.      ,   10.48576 ],</span>
<span class="go">       [ 125.      ,   45.      ,   16.777216],</span>
<span class="go">       [ 124.      ,  337.      ,   10.48576 ],</span>
<span class="go">       [ 120.      ,  272.      ,   16.777216],</span>
<span class="go">       [  58.      ,  100.      ,   10.48576 ],</span>
<span class="go">       [  54.      ,  276.      ,   10.48576 ],</span>
<span class="go">       [  54.      ,   42.      ,   16.777216],</span>
<span class="go">       [  52.      ,  216.      ,   16.777216],</span>
<span class="go">       [  52.      ,  155.      ,   16.777216],</span>
<span class="go">       [  45.      ,  336.      ,   16.777216]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-blob-dog">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code><a class="headerlink" href="#examples-using-skimage-feature-blob-dog" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are dete..."><div class="figure align-default" id="id96">
<img alt="../_images/sphx_glr_plot_blob_thumb.png" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></span><a class="headerlink" href="#id96" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="blob-doh">
<h2>blob_doh<a class="headerlink" href="#blob-doh" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.blob_doh">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">blob_doh</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">min_sigma=1</em>, <em class="sig-param">max_sigma=30</em>, <em class="sig-param">num_sigma=10</em>, <em class="sig-param">threshold=0.01</em>, <em class="sig-param">overlap=0.5</em>, <em class="sig-param">log_scale=False</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/blob.py#L384"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.blob_doh" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds blobs in the given grayscale image.</p>
<p>Blobs are found using the Determinant of Hessian method <a class="reference internal" href="#ra19a7aed16ca-1" id="id50">[1]</a>. For each blob
found, the method returns its coordinates and the standard deviation
of the Gaussian Kernel used for the Hessian matrix whose determinant
detected the blob. Determinant of Hessians is approximated using <a class="reference internal" href="#ra19a7aed16ca-2" id="id51">[2]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D ndarray</span></dt><dd><p>Input grayscale image.Blobs can either be light on dark or vice versa.</p>
</dd>
<dt><strong>min_sigma</strong><span class="classifier">float, optional</span></dt><dd><p>The minimum standard deviation for Gaussian Kernel used to compute
Hessian matrix. Keep this low to detect smaller blobs.</p>
</dd>
<dt><strong>max_sigma</strong><span class="classifier">float, optional</span></dt><dd><p>The maximum standard deviation for Gaussian Kernel used to compute
Hessian matrix. Keep this high to detect larger blobs.</p>
</dd>
<dt><strong>num_sigma</strong><span class="classifier">int, optional</span></dt><dd><p>The number of intermediate values of standard deviations to consider
between <cite>min_sigma</cite> and <cite>max_sigma</cite>.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional.</span></dt><dd><p>The absolute lower bound for scale space maxima. Local maxima smaller
than thresh are ignored. Reduce this to detect less prominent blobs.</p>
</dd>
<dt><strong>overlap</strong><span class="classifier">float, optional</span></dt><dd><p>A value between 0 and 1. If the area of two blobs overlaps by a
fraction greater than <cite>threshold</cite>, the smaller blob is eliminated.</p>
</dd>
<dt><strong>log_scale</strong><span class="classifier">bool, optional</span></dt><dd><p>If set intermediate values of standard deviations are interpolated
using a logarithmic scale to the base <cite>10</cite>. If not, linear
interpolation is used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>A</strong><span class="classifier">(n, 3) ndarray</span></dt><dd><p>A 2d array with each row representing 3 values, <code class="docutils literal notranslate"><span class="pre">(y,x,sigma)</span></code>
where <code class="docutils literal notranslate"><span class="pre">(y,x)</span></code> are coordinates of the blob and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the
standard deviation of the Gaussian kernel of the Hessian Matrix whose
determinant detected the blob.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The radius of each blob is approximately <cite>sigma</cite>.
Computation of Determinant of Hessians is independent of the standard
deviation. Therefore detecting larger blobs won’t take more time. In
methods line <a class="reference internal" href="#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code class="xref py py-meth docutils literal notranslate"><span class="pre">blob_dog()</span></code></a> and <a class="reference internal" href="#skimage.feature.blob_log" title="skimage.feature.blob_log"><code class="xref py py-meth docutils literal notranslate"><span class="pre">blob_log()</span></code></a> the computation
of Gaussians for larger <cite>sigma</cite> takes more time. The downside is that
this method can’t be used for detecting blobs of radius less than <cite>3px</cite>
due to the box filters used in the approximation of Hessian Determinant.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="ra19a7aed16ca-1"><span class="brackets"><a class="fn-backref" href="#id50">1</a></span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian">http://en.wikipedia.org/wiki/Blob_detection#The_determinant_of_the_Hessian</a></p>
</dd>
<dt class="label" id="ra19a7aed16ca-2"><span class="brackets"><a class="fn-backref" href="#id51">2</a></span></dt>
<dd><p>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool,
“SURF: Speeded Up Robust Features”
<a class="reference external" href="ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf">ftp://ftp.vision.ee.ethz.ch/publications/articles/eth_biwi_00517.pdf</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="o">.</span><span class="n">blob_doh</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="go">array([[ 270.        ,  363.        ,   30.        ],</span>
<span class="go">       [ 265.        ,  113.        ,   23.55555556],</span>
<span class="go">       [ 262.        ,  243.        ,   23.55555556],</span>
<span class="go">       [ 260.        ,  173.        ,   30.        ],</span>
<span class="go">       [ 197.        ,  153.        ,   20.33333333],</span>
<span class="go">       [ 197.        ,   44.        ,   20.33333333],</span>
<span class="go">       [ 195.        ,  100.        ,   23.55555556],</span>
<span class="go">       [ 193.        ,  275.        ,   23.55555556],</span>
<span class="go">       [ 192.        ,  212.        ,   23.55555556],</span>
<span class="go">       [ 185.        ,  348.        ,   30.        ],</span>
<span class="go">       [ 156.        ,  302.        ,   30.        ],</span>
<span class="go">       [ 126.        ,  153.        ,   20.33333333],</span>
<span class="go">       [ 126.        ,  101.        ,   20.33333333],</span>
<span class="go">       [ 124.        ,  336.        ,   20.33333333],</span>
<span class="go">       [ 123.        ,  205.        ,   20.33333333],</span>
<span class="go">       [ 123.        ,   44.        ,   23.55555556],</span>
<span class="go">       [ 121.        ,  271.        ,   30.        ]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-blob-doh">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_doh</span></code><a class="headerlink" href="#examples-using-skimage-feature-blob-doh" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are dete..."><div class="figure align-default" id="id97">
<img alt="../_images/sphx_glr_plot_blob_thumb.png" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></span><a class="headerlink" href="#id97" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="blob-log">
<h2>blob_log<a class="headerlink" href="#blob-log" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.blob_log">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">blob_log</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">min_sigma=1</em>, <em class="sig-param">max_sigma=50</em>, <em class="sig-param">num_sigma=10</em>, <em class="sig-param">threshold=0.2</em>, <em class="sig-param">overlap=0.5</em>, <em class="sig-param">log_scale=False</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/blob.py#L279"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.blob_log" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds blobs in the given grayscale image.</p>
<p>Blobs are found using the Laplacian of Gaussian (LoG) method <a class="reference internal" href="#r520e53dd5fa2-1" id="id54">[1]</a>.
For each blob found, the method returns its coordinates and the standard
deviation of the Gaussian kernel that detected the blob.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D or 3D ndarray</span></dt><dd><p>Input grayscale image, blobs are assumed to be light on dark
background (white on black).</p>
</dd>
<dt><strong>min_sigma</strong><span class="classifier">float, optional</span></dt><dd><p>The minimum standard deviation for Gaussian Kernel. Keep this low to
detect smaller blobs.</p>
</dd>
<dt><strong>max_sigma</strong><span class="classifier">float, optional</span></dt><dd><p>The maximum standard deviation for Gaussian Kernel. Keep this high to
detect larger blobs.</p>
</dd>
<dt><strong>num_sigma</strong><span class="classifier">int, optional</span></dt><dd><p>The number of intermediate values of standard deviations to consider
between <cite>min_sigma</cite> and <cite>max_sigma</cite>.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional.</span></dt><dd><p>The absolute lower bound for scale space maxima. Local maxima smaller
than thresh are ignored. Reduce this to detect blobs with less
intensities.</p>
</dd>
<dt><strong>overlap</strong><span class="classifier">float, optional</span></dt><dd><p>A value between 0 and 1. If the area of two blobs overlaps by a
fraction greater than <cite>threshold</cite>, the smaller blob is eliminated.</p>
</dd>
<dt><strong>log_scale</strong><span class="classifier">bool, optional</span></dt><dd><p>If set intermediate values of standard deviations are interpolated
using a logarithmic scale to the base <cite>10</cite>. If not, linear
interpolation is used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>A</strong><span class="classifier">(n, image.ndim + 1) ndarray</span></dt><dd><p>A 2d array with each row representing 3 values for a 2D image,
and 4 values for a 3D image: <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code> or <code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c,</span> <span class="pre">sigma)</span></code>
where <code class="docutils literal notranslate"><span class="pre">(r,</span> <span class="pre">c)</span></code> or <code class="docutils literal notranslate"><span class="pre">(p,</span> <span class="pre">r,</span> <span class="pre">c)</span></code> are coordinates of the blob and
<code class="docutils literal notranslate"><span class="pre">sigma</span></code> is the standard deviation of the Gaussian kernel which
detected the blob.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The radius of each blob is approximately <span class="math notranslate nohighlight">\(\sqrt{2}\sigma\)</span> for
a 2-D image and <span class="math notranslate nohighlight">\(\sqrt{3}\sigma\)</span> for a 3-D image.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r520e53dd5fa2-1"><span class="brackets"><a class="fn-backref" href="#id54">1</a></span></dt>
<dd><p><a class="reference external" href="http://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian">http://en.wikipedia.org/wiki/Blob_detection#The_Laplacian_of_Gaussian</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="k">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">exposure</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">exposure</span><span class="o">.</span><span class="n">equalize_hist</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  <span class="c1"># improves detection</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span><span class="o">.</span><span class="n">blob_log</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">3</span><span class="p">)</span>
<span class="go">array([[ 266.        ,  115.        ,   11.88888889],</span>
<span class="go">       [ 263.        ,  302.        ,   17.33333333],</span>
<span class="go">       [ 263.        ,  244.        ,   17.33333333],</span>
<span class="go">       [ 260.        ,  174.        ,   17.33333333],</span>
<span class="go">       [ 198.        ,  155.        ,   11.88888889],</span>
<span class="go">       [ 198.        ,  103.        ,   11.88888889],</span>
<span class="go">       [ 197.        ,   44.        ,   11.88888889],</span>
<span class="go">       [ 194.        ,  276.        ,   17.33333333],</span>
<span class="go">       [ 194.        ,  213.        ,   17.33333333],</span>
<span class="go">       [ 185.        ,  344.        ,   17.33333333],</span>
<span class="go">       [ 128.        ,  154.        ,   11.88888889],</span>
<span class="go">       [ 127.        ,  102.        ,   11.88888889],</span>
<span class="go">       [ 126.        ,  208.        ,   11.88888889],</span>
<span class="go">       [ 126.        ,   46.        ,   11.88888889],</span>
<span class="go">       [ 124.        ,  336.        ,   11.88888889],</span>
<span class="go">       [ 121.        ,  272.        ,   17.33333333],</span>
<span class="go">       [ 113.        ,  323.        ,    1.        ]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-blob-log">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.blob_log</span></code><a class="headerlink" href="#examples-using-skimage-feature-blob-log" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are dete..."><div class="figure align-default" id="id98">
<img alt="../_images/sphx_glr_plot_blob_thumb.png" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></span><a class="headerlink" href="#id98" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="haar-like-feature">
<h2>haar_like_feature<a class="headerlink" href="#haar-like-feature" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.haar_like_feature">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">haar_like_feature</code><span class="sig-paren">(</span><em class="sig-param">int_image</em>, <em class="sig-param">r</em>, <em class="sig-param">c</em>, <em class="sig-param">width</em>, <em class="sig-param">height</em>, <em class="sig-param">feature_type=None</em>, <em class="sig-param">feature_coord=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/haar.py#L89"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.haar_like_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Haar-like features for a region of interest (ROI) of an
integral image.</p>
<p>Haar-like features have been successfully used for image classification and
object detection <a class="reference internal" href="#rbcb83f52fce4-1" id="id56">[1]</a>. It has been used for real-time face detection
algorithm proposed in <a class="reference internal" href="#rbcb83f52fce4-2" id="id57">[2]</a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>int_image</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Integral image for which the features need to be computed.</p>
</dd>
<dt><strong>r</strong><span class="classifier">int</span></dt><dd><p>Row-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>c</strong><span class="classifier">int</span></dt><dd><p>Column-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>width</strong><span class="classifier">int</span></dt><dd><p>Width of the detection window.</p>
</dd>
<dt><strong>height</strong><span class="classifier">int</span></dt><dd><p>Height of the detection window.</p>
</dd>
<dt><strong>feature_type</strong><span class="classifier">str or list of str or None, optional</span></dt><dd><p>The type of feature to consider:</p>
<ul class="simple">
<li><p>‘type-2-x’: 2 rectangles varying along the x axis;</p></li>
<li><p>‘type-2-y’: 2 rectangles varying along the y axis;</p></li>
<li><p>‘type-3-x’: 3 rectangles varying along the x axis;</p></li>
<li><p>‘type-3-y’: 3 rectangles varying along the y axis;</p></li>
<li><p>‘type-4’: 4 rectangles varying along x and y axis.</p></li>
</ul>
<p>By default all features are extracted.</p>
<p>If using with <cite>feature_coord</cite>, it should correspond to the feature
type of each associated coordinate feature.</p>
</dd>
<dt><strong>feature_coord</strong><span class="classifier">ndarray of list of tuples or None, optional</span></dt><dd><p>The array of coordinates to be extracted. This is useful when you want
to recompute only a subset of features. In this case <cite>feature_type</cite>
needs to be an array containing the type of each feature, as returned
by <a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code class="xref py py-func docutils literal notranslate"><span class="pre">haar_like_feature_coord()</span></code></a>. By default, all coordinates are
computed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>haar_features</strong><span class="classifier">(n_features,) ndarray of int or float</span></dt><dd><p>Resulting Haar-like features. Each value is equal to the subtraction of
sums of the positive and negative rectangles. The data type depends of
the data type of <cite>int_image</cite>: <cite>int</cite> when the data type of <cite>int_image</cite>
is <cite>uint</cite> or <cite>int</cite> and <cite>float</cite> when the data type of <cite>int_image</cite> is
<cite>float</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>When extracting those features in parallel, be aware that the choice of the
backend (i.e. multiprocessing vs threading) will have an impact on the
performance. The rule of thumb is as follows: use multiprocessing when
extracting features for all possible ROI in an image; use threading when
extracting the feature at specific location for a limited number of ROIs.
Refer to the example
<a class="reference internal" href="../auto_examples/xx_applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-xx-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a>
for more insights.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rbcb83f52fce4-1"><span class="brackets"><a class="fn-backref" href="#id56">1</a></span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Haar-like_feature">https://en.wikipedia.org/wiki/Haar-like_feature</a></p>
</dd>
<dt class="label" id="rbcb83f52fce4-2"><span class="brackets"><a class="fn-backref" href="#id57">2</a></span></dt>
<dd><p>Oren, M., Papageorgiou, C., Sinha, P., Osuna, E., &amp; Poggio, T.
(1997, June). Pedestrian detection using wavelet templates.
In Computer Vision and Pattern Recognition, 1997. Proceedings.,
1997 IEEE Computer Society Conference on (pp. 193-199). IEEE.
<a class="reference external" href="http://tinyurl.com/y6ulxfta">http://tinyurl.com/y6ulxfta</a>
DOI: 10.1109/CVPR.1997.609319</p>
</dd>
<dt class="label" id="rbcb83f52fce4-3"><span class="brackets">3</span></dt>
<dd><p>Viola, Paul, and Michael J. Jones. “Robust real-time face
detection.” International journal of computer vision 57.2
(2004): 137-154.
<a class="reference external" href="http://www.merl.com/publications/docs/TR2004-043.pdf">http://www.merl.com/publications/docs/TR2004-043.pdf</a>
DOI: 10.1109/CVPR.2001.990517</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="k">import</span> <span class="n">integral_image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img_ii</span> <span class="o">=</span> <span class="n">integral_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span> <span class="o">=</span> <span class="n">haar_like_feature</span><span class="p">(</span><span class="n">img_ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;type-3-x&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span>
<span class="go">array([-1, -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -4, -1,</span>
<span class="go">       -2, -3, -4, -1, -2, -3, -4, -1, -2, -3, -1, -2, -3, -1, -2, -3, -1,</span>
<span class="go">       -2, -1, -2, -1, -2, -1, -1, -1])</span>
</pre></div>
</div>
<p>You can compute the feature for some pre-computed coordinates.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature_coord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_coord</span><span class="p">,</span> <span class="n">feature_type</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
<span class="gp">... </span>    <span class="o">*</span><span class="p">[</span><span class="n">haar_like_feature_coord</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">feat_t</span><span class="p">)</span>
<span class="gp">... </span>      <span class="k">for</span> <span class="n">feat_t</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;type-2-x&#39;</span><span class="p">,</span> <span class="s1">&#39;type-3-x&#39;</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># only select one feature over two</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_coord</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">feature_coord</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">feature_type</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span> <span class="o">=</span> <span class="n">haar_like_feature</span><span class="p">(</span><span class="n">img_ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">feature_type</span><span class="o">=</span><span class="n">feature_type</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">feature_coord</span><span class="o">=</span><span class="n">feature_coord</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature</span>
<span class="go">array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,</span>
<span class="go">        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,</span>
<span class="go">        0,  0,  0,  0,  0,  0,  0,  0, -1, -3, -1, -3, -1, -3, -1, -3, -1,</span>
<span class="go">       -3, -1, -3, -1, -3, -2, -1, -3, -2, -2, -2, -1])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-haar-like-feature">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature</span></code><a class="headerlink" href="#examples-using-skimage-feature-haar-like-feature" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face dete..."><div class="figure align-default" id="id99">
<img alt="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/xx_applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-xx-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></span><a class="headerlink" href="#id99" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="haar-like-feature-coord">
<h2>haar_like_feature_coord<a class="headerlink" href="#haar-like-feature-coord" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.haar_like_feature_coord">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">haar_like_feature_coord</code><span class="sig-paren">(</span><em class="sig-param">width</em>, <em class="sig-param">height</em>, <em class="sig-param">feature_type=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/haar.py#L38"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.haar_like_feature_coord" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the coordinates of Haar-like features.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>width</strong><span class="classifier">int</span></dt><dd><p>Width of the detection window.</p>
</dd>
<dt><strong>height</strong><span class="classifier">int</span></dt><dd><p>Height of the detection window.</p>
</dd>
<dt><strong>feature_type</strong><span class="classifier">str or list of str or None, optional</span></dt><dd><p>The type of feature to consider:</p>
<ul class="simple">
<li><p>‘type-2-x’: 2 rectangles varying along the x axis;</p></li>
<li><p>‘type-2-y’: 2 rectangles varying along the y axis;</p></li>
<li><p>‘type-3-x’: 3 rectangles varying along the x axis;</p></li>
<li><p>‘type-3-y’: 3 rectangles varying along the y axis;</p></li>
<li><p>‘type-4’: 4 rectangles varying along x and y axis.</p></li>
</ul>
<p>By default all features are extracted.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>feature_coord</strong><span class="classifier">(n_features, n_rectangles, 2, 2), ndarray of list of tuple coord</span></dt><dd><p>Coordinates of the rectangles for each feature.</p>
</dd>
<dt><strong>feature_type</strong><span class="classifier">(n_features,), ndarray of str</span></dt><dd><p>The corresponding type for each feature.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="k">import</span> <span class="n">integral_image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature_coord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat_coord</span><span class="p">,</span> <span class="n">feat_type</span> <span class="o">=</span> <span class="n">haar_like_feature_coord</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;type-4&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat_coord</span> <span class="c1"># doctest: +SKIP</span>
<span class="go">array([ list([[(0, 0), (0, 0)], [(0, 1), (0, 1)],</span>
<span class="go">              [(1, 1), (1, 1)], [(1, 0), (1, 0)]])], dtype=object)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat_type</span>
<span class="go">array([&#39;type-4&#39;], dtype=object)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-haar-like-feature-coord">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.haar_like_feature_coord</span></code><a class="headerlink" href="#examples-using-skimage-feature-haar-like-feature-coord" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Haar-like features are simple digital image features that were introduced in a real-time face d..."><div class="figure align-default" id="id100">
<img alt="../_images/sphx_glr_plot_haar_thumb.png" src="../_images/sphx_glr_plot_haar_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_haar.html#sphx-glr-auto-examples-features-detection-plot-haar-py"><span class="std std-ref">Haar-like feature descriptor</span></a></span><a class="headerlink" href="#id100" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face dete..."><div class="figure align-default" id="id101">
<img alt="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/xx_applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-xx-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></span><a class="headerlink" href="#id101" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="draw-haar-like-feature">
<h2>draw_haar_like_feature<a class="headerlink" href="#draw-haar-like-feature" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="skimage.feature.draw_haar_like_feature">
<code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">draw_haar_like_feature</code><span class="sig-paren">(</span><em class="sig-param">image</em>, <em class="sig-param">r</em>, <em class="sig-param">c</em>, <em class="sig-param">width</em>, <em class="sig-param">height</em>, <em class="sig-param">feature_coord</em>, <em class="sig-param">color_positive_block=(1.0</em>, <em class="sig-param">0.0</em>, <em class="sig-param">0.0)</em>, <em class="sig-param">color_negative_block=(0.0</em>, <em class="sig-param">1.0</em>, <em class="sig-param">0.0)</em>, <em class="sig-param">alpha=0.5</em>, <em class="sig-param">max_n_features=None</em>, <em class="sig-param">random_state=None</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/haar.py#L224"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.draw_haar_like_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualization of Haar-like features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>The region of an integral image for which the features need to be
computed.</p>
</dd>
<dt><strong>r</strong><span class="classifier">int</span></dt><dd><p>Row-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>c</strong><span class="classifier">int</span></dt><dd><p>Column-coordinate of top left corner of the detection window.</p>
</dd>
<dt><strong>width</strong><span class="classifier">int</span></dt><dd><p>Width of the detection window.</p>
</dd>
<dt><strong>height</strong><span class="classifier">int</span></dt><dd><p>Height of the detection window.</p>
</dd>
<dt><strong>feature_coord</strong><span class="classifier">ndarray of list of tuples or None, optional</span></dt><dd><p>The array of coordinates to be extracted. This is useful when you want
to recompute only a subset of features. In this case <cite>feature_type</cite>
needs to be an array containing the type of each feature, as returned
by <a class="reference internal" href="#skimage.feature.haar_like_feature_coord" title="skimage.feature.haar_like_feature_coord"><code class="xref py py-func docutils literal notranslate"><span class="pre">haar_like_feature_coord()</span></code></a>. By default, all coordinates are
computed.</p>
</dd>
<dt><strong>color_positive_rectangle</strong><span class="classifier">tuple of 3 floats</span></dt><dd><p>Floats specifying the color for the positive block. Corresponding
values define (R, G, B) values. Default value is red (1, 0, 0).</p>
</dd>
<dt><strong>color_negative_block</strong><span class="classifier">tuple of 3 floats</span></dt><dd><p>Floats specifying the color for the negative block Corresponding values
define (R, G, B) values. Default value is blue (0, 1, 0).</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float</span></dt><dd><p>Value in the range [0, 1] that specifies opacity of visualization. 1 -
fully transparent, 0 - opaque.</p>
</dd>
<dt><strong>max_n_features</strong><span class="classifier">int, default=None</span></dt><dd><p>The maximum number of features to be returned.
By default, all features are returned.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance or None, optional</span></dt><dd><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>. The random state is used when generating a set of
features smaller than the total number of available features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>features</strong><span class="classifier">(M, N), ndarray</span></dt><dd><p>An image in which the different features will be added.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">haar_like_feature_coord</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">draw_haar_like_feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_coord</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">haar_like_feature_coord</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;type-4&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">draw_haar_like_feature</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
<span class="gp">... </span>                               <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">feature_coord</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="n">max_n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span>
<span class="go">array([[[ 0. ,  0.5,  0. ],</span>
<span class="go">        [ 0.5,  0. ,  0. ]],</span>
<span class="go">&lt;BLANKLINE&gt;</span>
<span class="go">       [[ 0.5,  0. ,  0. ],</span>
<span class="go">        [ 0. ,  0.5,  0. ]]])</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-skimage-feature-draw-haar-like-feature">
<h3>Examples using <code class="docutils literal notranslate"><span class="pre">skimage.feature.draw_haar_like_feature</span></code><a class="headerlink" href="#examples-using-skimage-feature-draw-haar-like-feature" title="Permalink to this headline">¶</a></h3>
<div class="sphx-glr-thumbcontainer" tooltip="Haar-like features are simple digital image features that were introduced in a real-time face d..."><div class="figure align-default" id="id102">
<img alt="../_images/sphx_glr_plot_haar_thumb.png" src="../_images/sphx_glr_plot_haar_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/features_detection/plot_haar.html#sphx-glr-auto-examples-features-detection-plot-haar-py"><span class="std std-ref">Haar-like feature descriptor</span></a></span><a class="headerlink" href="#id102" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face dete..."><div class="figure align-default" id="id103">
<img alt="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/xx_applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-xx-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></span><a class="headerlink" href="#id103" title="Permalink to this image">¶</a></p>
</div>
</div></div>
</div>
<div class="section" id="brief">
<h2><a class="reference internal" href="#skimage.feature.BRIEF" title="skimage.feature.BRIEF"><code class="xref py py-class docutils literal notranslate"><span class="pre">BRIEF</span></code></a><a class="headerlink" href="#brief" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.BRIEF">
<em class="property">class </em><code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">BRIEF</code><span class="sig-paren">(</span><em class="sig-param">descriptor_size=256</em>, <em class="sig-param">patch_size=49</em>, <em class="sig-param">mode='normal'</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">sample_seed=1</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/brief.py#L11"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.BRIEF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.DescriptorExtractor</span></code></p>
<p>BRIEF binary descriptor extractor.</p>
<p>BRIEF (Binary Robust Independent Elementary Features) is an efficient
feature point descriptor. It is highly discriminative even when using
relatively few bits and is computed using simple intensity difference
tests.</p>
<p>For each keypoint, intensity comparisons are carried out for a specifically
distributed number N of pixel-pairs resulting in a binary descriptor of
length N. For binary descriptors the Hamming distance can be used for
feature matching, which leads to lower computational cost in comparison to
the L2 norm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>descriptor_size</strong><span class="classifier">int, optional</span></dt><dd><p>Size of BRIEF descriptor for each keypoint. Sizes 128, 256 and 512
recommended by the authors. Default is 256.</p>
</dd>
<dt><strong>patch_size</strong><span class="classifier">int, optional</span></dt><dd><p>Length of the two dimensional square patch sampling region around
the keypoints. Default is 49.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘normal’, ‘uniform’}, optional</span></dt><dd><p>Probability distribution for sampling location of decision pixel-pairs
around keypoints.</p>
</dd>
<dt><strong>sample_seed</strong><span class="classifier">int, optional</span></dt><dd><p>Seed for the random sampling of the decision pixel-pairs. From a square
window with length <cite>patch_size</cite>, pixel pairs are sampled using the
<cite>mode</cite> parameter to build the descriptors using intensity comparison.
The value of <cite>sample_seed</cite> must be the same for the images to be
matched while building the descriptors.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation of the Gaussian low-pass filter applied to the image
to alleviate noise sensitivity, which is strongly recommended to obtain
discriminative and good descriptors.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="p">(</span><span class="n">corner_harris</span><span class="p">,</span> <span class="n">corner_peaks</span><span class="p">,</span> <span class="n">BRIEF</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">match_descriptors</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square1</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square1</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square2</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square2</span>
<span class="go">array([[0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 1, 1, 1, 1, 1, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">       [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints1</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">square1</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints2</span> <span class="o">=</span> <span class="n">corner_peaks</span><span class="p">(</span><span class="n">corner_harris</span><span class="p">(</span><span class="n">square2</span><span class="p">),</span> <span class="n">min_distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extractor</span> <span class="o">=</span> <span class="n">BRIEF</span><span class="p">(</span><span class="n">patch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">square1</span><span class="p">,</span> <span class="n">keypoints1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descriptors1</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">descriptors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">square2</span><span class="p">,</span> <span class="n">keypoints2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">descriptors2</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">descriptors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span> <span class="o">=</span> <span class="n">match_descriptors</span><span class="p">(</span><span class="n">descriptors1</span><span class="p">,</span> <span class="n">descriptors2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span>
<span class="go">array([[0, 0],</span>
<span class="go">       [1, 1],</span>
<span class="go">       [2, 2],</span>
<span class="go">       [3, 3]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints1</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 5],</span>
<span class="go">       [5, 2],</span>
<span class="go">       [5, 5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">keypoints2</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="go">array([[2, 2],</span>
<span class="go">       [2, 6],</span>
<span class="go">       [6, 2],</span>
<span class="go">       [6, 6]])</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>descriptors</strong><span class="classifier">(Q, <cite>descriptor_size</cite>) array of dtype bool</span></dt><dd><p>2D ndarray of binary descriptors of size <cite>descriptor_size</cite> for Q
keypoints after filtering out border keypoints with value at an
index <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> either being <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code> representing
the outcome of the intensity comparison for i-th keypoint on j-th
decision pixel-pair. It is <code class="docutils literal notranslate"><span class="pre">Q</span> <span class="pre">==</span> <span class="pre">np.sum(mask)</span></code>.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">(N, ) array of dtype bool</span></dt><dd><p>Mask indicating whether a keypoint has been filtered out
(<code class="docutils literal notranslate"><span class="pre">False</span></code>) or is described in the <cite>descriptors</cite> array (<code class="docutils literal notranslate"><span class="pre">True</span></code>).</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="skimage.feature.BRIEF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">descriptor_size=256</em>, <em class="sig-param">patch_size=49</em>, <em class="sig-param">mode='normal'</em>, <em class="sig-param">sigma=1</em>, <em class="sig-param">sample_seed=1</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/brief.py#L114"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.BRIEF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.BRIEF.extract">
<code class="sig-name descname">extract</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">image</em>, <em class="sig-param">keypoints</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/brief.py#L130"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.BRIEF.extract" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract BRIEF binary descriptors for given keypoints in image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D array</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>keypoints</strong><span class="classifier">(N, 2) array</span></dt><dd><p>Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="censure">
<h2><a class="reference internal" href="#skimage.feature.CENSURE" title="skimage.feature.CENSURE"><code class="xref py py-class docutils literal notranslate"><span class="pre">CENSURE</span></code></a><a class="headerlink" href="#censure" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.CENSURE">
<em class="property">class </em><code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">CENSURE</code><span class="sig-paren">(</span><em class="sig-param">min_scale=1</em>, <em class="sig-param">max_scale=7</em>, <em class="sig-param">mode='DoB'</em>, <em class="sig-param">non_max_threshold=0.15</em>, <em class="sig-param">line_threshold=10</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/censure.py#L111"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.CENSURE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.FeatureDetector</span></code></p>
<p>CENSURE keypoint detector.</p>
<dl class="simple">
<dt>min_scale<span class="classifier">int, optional</span></dt><dd><p>Minimum scale to extract keypoints from.</p>
</dd>
<dt>max_scale<span class="classifier">int, optional</span></dt><dd><p>Maximum scale to extract keypoints from. The keypoints will be
extracted from all the scales except the first and the last i.e.
from the scales in the range [min_scale + 1, max_scale - 1]. The filter
sizes for different scales is such that the two adjacent scales
comprise of an octave.</p>
</dd>
<dt>mode<span class="classifier">{‘DoB’, ‘Octagon’, ‘STAR’}, optional</span></dt><dd><p>Type of bi-level filter used to get the scales of the input image.
Possible values are ‘DoB’, ‘Octagon’ and ‘STAR’. The three modes
represent the shape of the bi-level filters i.e. box(square), octagon
and star respectively. For instance, a bi-level octagon filter consists
of a smaller inner octagon and a larger outer octagon with the filter
weights being uniformly negative in both the inner octagon while
uniformly positive in the difference region. Use STAR and Octagon for
better features and DoB for better performance.</p>
</dd>
<dt>non_max_threshold<span class="classifier">float, optional</span></dt><dd><p>Threshold value used to suppress maximas and minimas with a weak
magnitude response obtained after Non-Maximal Suppression.</p>
</dd>
<dt>line_threshold<span class="classifier">float, optional</span></dt><dd><p>Threshold for rejecting interest points which have ratio of principal
curvatures greater than this value.</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="recc8560c357f-1"><span class="brackets">Recc8560c357f-1</span></dt>
<dd><p>Motilal Agrawal, Kurt Konolige and Morten Rufus Blas
“CENSURE: Center Surround Extremas for Realtime Feature
Detection and Matching”,
<a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-540-88693-8_8">https://link.springer.com/chapter/10.1007/978-3-540-88693-8_8</a>
DOI:10.1007/978-3-540-88693-8_8</p>
</dd>
<dt class="label" id="recc8560c357f-2"><span class="brackets">Recc8560c357f-2</span></dt>
<dd><p>Adam Schmidt, Marek Kraft, Michal Fularz and Zuzanna Domagala
“Comparative Assessment of Point Feature Detectors and
Descriptors in the Context of Robot Navigation”
<a class="reference external" href="http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-268aaf28-0faf-4872-a4df-7e2e61cb364c/c/Schmidt_comparative.pdf">http://yadda.icm.edu.pl/yadda/element/bwmeta1.element.baztech-268aaf28-0faf-4872-a4df-7e2e61cb364c/c/Schmidt_comparative.pdf</a>
DOI:10.1.1.465.1117</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="k">import</span> <span class="n">astronaut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="k">import</span> <span class="n">rgb2gray</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">CENSURE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">rgb2gray</span><span class="p">(</span><span class="n">astronaut</span><span class="p">()[</span><span class="mi">100</span><span class="p">:</span><span class="mi">300</span><span class="p">,</span> <span class="mi">100</span><span class="p">:</span><span class="mi">300</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span> <span class="o">=</span> <span class="n">CENSURE</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span><span class="o">.</span><span class="n">keypoints</span>
<span class="go">array([[  4, 148],</span>
<span class="go">       [ 12,  73],</span>
<span class="go">       [ 21, 176],</span>
<span class="go">       [ 91,  22],</span>
<span class="go">       [ 93,  56],</span>
<span class="go">       [ 94,  22],</span>
<span class="go">       [ 95,  54],</span>
<span class="go">       [100,  51],</span>
<span class="go">       [103,  51],</span>
<span class="go">       [106,  67],</span>
<span class="go">       [108,  15],</span>
<span class="go">       [117,  20],</span>
<span class="go">       [122,  60],</span>
<span class="go">       [125,  37],</span>
<span class="go">       [129,  37],</span>
<span class="go">       [133,  76],</span>
<span class="go">       [145,  44],</span>
<span class="go">       [146,  94],</span>
<span class="go">       [150, 114],</span>
<span class="go">       [153,  33],</span>
<span class="go">       [154, 156],</span>
<span class="go">       [155, 151],</span>
<span class="go">       [184,  63]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">censure</span><span class="o">.</span><span class="n">scales</span>
<span class="go">array([2, 6, 6, 2, 4, 3, 2, 3, 2, 6, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 4, 2, 2])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>keypoints</strong><span class="classifier">(N, 2) array</span></dt><dd><p>Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>scales</strong><span class="classifier">(N, ) array</span></dt><dd><p>Corresponding scales.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="skimage.feature.CENSURE.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">min_scale=1</em>, <em class="sig-param">max_scale=7</em>, <em class="sig-param">mode='DoB'</em>, <em class="sig-param">non_max_threshold=0.15</em>, <em class="sig-param">line_threshold=10</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/censure.py#L197"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.CENSURE.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.CENSURE.detect">
<code class="sig-name descname">detect</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">image</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/censure.py#L217"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.CENSURE.detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect CENSURE keypoints along with the corresponding scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D ndarray</span></dt><dd><p>Input image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="orb">
<h2><a class="reference internal" href="#skimage.feature.ORB" title="skimage.feature.ORB"><code class="xref py py-class docutils literal notranslate"><span class="pre">ORB</span></code></a><a class="headerlink" href="#orb" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="skimage.feature.ORB">
<em class="property">class </em><code class="sig-prename descclassname">skimage.feature.</code><code class="sig-name descname">ORB</code><span class="sig-paren">(</span><em class="sig-param">downscale=1.2</em>, <em class="sig-param">n_scales=8</em>, <em class="sig-param">n_keypoints=500</em>, <em class="sig-param">fast_n=9</em>, <em class="sig-param">fast_threshold=0.08</em>, <em class="sig-param">harris_k=0.04</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/orb.py#L22"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.FeatureDetector</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">skimage.feature.util.DescriptorExtractor</span></code></p>
<p>Oriented FAST and rotated BRIEF feature detector and binary descriptor
extractor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>n_keypoints</strong><span class="classifier">int, optional</span></dt><dd><p>Number of keypoints to be returned. The function will return the best
<cite>n_keypoints</cite> according to the Harris corner response if more than
<cite>n_keypoints</cite> are detected. If not, then all the detected keypoints
are returned.</p>
</dd>
<dt><strong>fast_n</strong><span class="classifier">int, optional</span></dt><dd><p>The <cite>n</cite> parameter in <cite>skimage.feature.corner_fast</cite>. Minimum number of
consecutive pixels out of 16 pixels on the circle that should all be
either brighter or darker w.r.t test-pixel. A point c on the circle is
darker w.r.t test pixel p if <code class="docutils literal notranslate"><span class="pre">Ic</span> <span class="pre">&lt;</span> <span class="pre">Ip</span> <span class="pre">-</span> <span class="pre">threshold</span></code> and brighter if
<code class="docutils literal notranslate"><span class="pre">Ic</span> <span class="pre">&gt;</span> <span class="pre">Ip</span> <span class="pre">+</span> <span class="pre">threshold</span></code>. Also stands for the n in <code class="docutils literal notranslate"><span class="pre">FAST-n</span></code> corner
detector.</p>
</dd>
<dt><strong>fast_threshold</strong><span class="classifier">float, optional</span></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">threshold</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">feature.corner_fast</span></code>. Threshold used
to decide whether the pixels on the circle are brighter, darker or
similar w.r.t. the test pixel. Decrease the threshold when more
corners are desired and vice-versa.</p>
</dd>
<dt><strong>harris_k</strong><span class="classifier">float, optional</span></dt><dd><p>The <cite>k</cite> parameter in <cite>skimage.feature.corner_harris</cite>. Sensitivity
factor to separate corners from edges, typically in range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0.2]</span></code>.
Small values of <cite>k</cite> result in detection of sharp corners.</p>
</dd>
<dt><strong>downscale</strong><span class="classifier">float, optional</span></dt><dd><p>Downscale factor for the image pyramid. Default value 1.2 is chosen so
that there are more dense scales which enable robust scale invariance
for a subsequent feature description.</p>
</dd>
<dt><strong>n_scales</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of scales from the bottom of the image pyramid to
extract the features from.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="rb3ecaf5c48ec-1"><span class="brackets">Rb3ecaf5c48ec-1</span></dt>
<dd><p>Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski
“ORB: An efficient alternative to SIFT and SURF”
<a class="reference external" href="http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf">http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.feature</span> <span class="k">import</span> <span class="n">ORB</span><span class="p">,</span> <span class="n">match_descriptors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">img1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">square</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img1</span><span class="p">[</span><span class="mi">40</span><span class="p">:</span><span class="mi">60</span><span class="p">,</span> <span class="mi">40</span><span class="p">:</span><span class="mi">60</span><span class="p">]</span> <span class="o">=</span> <span class="n">square</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img2</span><span class="p">[</span><span class="mi">53</span><span class="p">:</span><span class="mi">73</span><span class="p">,</span> <span class="mi">53</span><span class="p">:</span><span class="mi">73</span><span class="p">]</span> <span class="o">=</span> <span class="n">square</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor1</span> <span class="o">=</span> <span class="n">ORB</span><span class="p">(</span><span class="n">n_keypoints</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor2</span> <span class="o">=</span> <span class="n">ORB</span><span class="p">(</span><span class="n">n_keypoints</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor1</span><span class="o">.</span><span class="n">detect_and_extract</span><span class="p">(</span><span class="n">img1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor2</span><span class="o">.</span><span class="n">detect_and_extract</span><span class="p">(</span><span class="n">img2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span> <span class="o">=</span> <span class="n">match_descriptors</span><span class="p">(</span><span class="n">detector_extractor1</span><span class="o">.</span><span class="n">descriptors</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">detector_extractor2</span><span class="o">.</span><span class="n">descriptors</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matches</span>
<span class="go">array([[0, 0],</span>
<span class="go">       [1, 1],</span>
<span class="go">       [2, 2],</span>
<span class="go">       [3, 3],</span>
<span class="go">       [4, 4]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor1</span><span class="o">.</span><span class="n">keypoints</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="go">array([[ 42.,  40.],</span>
<span class="go">       [ 47.,  58.],</span>
<span class="go">       [ 44.,  40.],</span>
<span class="go">       [ 59.,  42.],</span>
<span class="go">       [ 45.,  44.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">detector_extractor2</span><span class="o">.</span><span class="n">keypoints</span><span class="p">[</span><span class="n">matches</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="go">array([[ 55.,  53.],</span>
<span class="go">       [ 60.,  71.],</span>
<span class="go">       [ 57.,  53.],</span>
<span class="go">       [ 72.,  55.],</span>
<span class="go">       [ 58.,  57.]])</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>keypoints</strong><span class="classifier">(N, 2) array</span></dt><dd><p>Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>scales</strong><span class="classifier">(N, ) array</span></dt><dd><p>Corresponding scales.</p>
</dd>
<dt><strong>orientations</strong><span class="classifier">(N, ) array</span></dt><dd><p>Corresponding orientations in radians.</p>
</dd>
<dt><strong>responses</strong><span class="classifier">(N, ) array</span></dt><dd><p>Corresponding Harris corner responses.</p>
</dd>
<dt><strong>descriptors</strong><span class="classifier">(Q, <cite>descriptor_size</cite>) array of dtype bool</span></dt><dd><p>2D array of binary descriptors of size <cite>descriptor_size</cite> for Q
keypoints after filtering out border keypoints with value at an
index <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> either being <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code> representing
the outcome of the intensity comparison for i-th keypoint on j-th
decision pixel-pair. It is <code class="docutils literal notranslate"><span class="pre">Q</span> <span class="pre">==</span> <span class="pre">np.sum(mask)</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="skimage.feature.ORB.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">downscale=1.2</em>, <em class="sig-param">n_scales=8</em>, <em class="sig-param">n_keypoints=500</em>, <em class="sig-param">fast_n=9</em>, <em class="sig-param">fast_threshold=0.08</em>, <em class="sig-param">harris_k=0.04</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/orb.py#L117"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.ORB.detect">
<code class="sig-name descname">detect</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">image</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/orb.py#L162"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect oriented FAST keypoints along with the corresponding scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D array</span></dt><dd><p>Input image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.ORB.detect_and_extract">
<code class="sig-name descname">detect_and_extract</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">image</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/orb.py#L277"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.detect_and_extract" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect oriented FAST keypoints and extract rBRIEF descriptors.</p>
<p>Note that this is faster than first calling <cite>detect</cite> and then
<cite>extract</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D array</span></dt><dd><p>Input image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="skimage.feature.ORB.extract">
<code class="sig-name descname">extract</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">image</em>, <em class="sig-param">keypoints</em>, <em class="sig-param">scales</em>, <em class="sig-param">orientations</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/scikit-image/scikit-image/blob/v0.14.3/skimage/feature/orb.py#L223"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skimage.feature.ORB.extract" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract rBRIEF binary descriptors for given keypoints in image.</p>
<p>Note that the keypoints must be extracted using the same <cite>downscale</cite>
and <cite>n_scales</cite> parameters. Additionally, if you want to extract both
keypoints and descriptors you should use the faster
<cite>detect_and_extract</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2D array</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>keypoints</strong><span class="classifier">(N, 2) array</span></dt><dd><p>Keypoint coordinates as <code class="docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code>.</p>
</dd>
<dt><strong>scales</strong><span class="classifier">(N, ) array</span></dt><dd><p>Corresponding scales.</p>
</dd>
<dt><strong>orientations</strong><span class="classifier">(N, ) array</span></dt><dd><p>Corresponding orientations in radians.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


        </div>
    </div>
    <div class="well footer">
        <small>
            &copy; Copyright the scikit-image development team.
            Created using <a href="http://getbootstrap.com/">Bootstrap</a> and <a href="http://sphinx-doc.org/">Sphinx</a>.
        </small>
    </div>
</body>
</html>


<!-- Piwik -->
<script type="text/javascript">
  var _paq = _paq || [];
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="//piwik.sciunto.org/piwik/";
    _paq.push(['setTrackerUrl', u+'piwik.php']);
    _paq.push(['setSiteId', 2]);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<noscript><p><img src="//piwik.sciunto.org/piwik/piwik.php?idsite=2" style="border:0;" alt="" /></p></noscript>
<!-- End Piwik Code -->