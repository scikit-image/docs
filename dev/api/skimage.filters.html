
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>skimage.filters &#8212; skimage 0.25.0rc2.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=4340df76" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=16f87d99"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-image.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/skimage.filters';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-image.org/docs/dev/_static/version_switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'dev';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="skimage.filters.rank" href="skimage.filters.rank.html" />
    <link rel="prev" title="skimage.feature" href="skimage.feature.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
     
  

<a class="navbar-brand logo" href="https://scikit-image.org">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="scikit-image's logo, showing a snake's head overlayed with green and orange"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="scikit-image's logo, showing a snake's head overlayed with green and orange"/>`);</script>
  
  
    <p class="title logo__title">scikit-image</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="api.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../release_notes/index.html">
    Release notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-image/scikit-image" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-image/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-box fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="api.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../release_notes/index.html">
    Release notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-image/scikit-image" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-image/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-box fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="skimage.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.color.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.color</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.draw.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.draw</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.exposure.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.exposure</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.feature.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.feature</span></code></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.filters.rank.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters.rank</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.future.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.future</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.graph.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.graph</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.io.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.io</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.measure.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.measure</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.metrics.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.metrics</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.morphology.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.morphology</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.registration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.registration</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.restoration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.restoration</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.segmentation.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.segmentation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.transform.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.transform</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.util.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.util</span></code></a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="api.html" class="nav-link">API reference</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><code...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-skimage.filters">
<span id="skimage-filters"></span><h1><a class="reference internal" href="#module-skimage.filters" title="skimage.filters"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters</span></code></a><a class="headerlink" href="#module-skimage.filters" title="Link to this heading">#</a></h1>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.apply_hysteresis_threshold" title="skimage.filters.apply_hysteresis_threshold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply_hysteresis_threshold</span></code></a></p></td>
<td><p>Apply hysteresis thresholding to <code class="docutils literal notranslate"><span class="pre">image</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.butterworth" title="skimage.filters.butterworth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">butterworth</span></code></a></p></td>
<td><p>Apply a Butterworth filter to enhance high or low frequency features.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.correlate_sparse" title="skimage.filters.correlate_sparse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">correlate_sparse</span></code></a></p></td>
<td><p>Compute valid cross-correlation of <code class="xref py py-obj docutils literal notranslate"><span class="pre">padded_array</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.difference_of_gaussians" title="skimage.filters.difference_of_gaussians"><code class="xref py py-obj docutils literal notranslate"><span class="pre">difference_of_gaussians</span></code></a></p></td>
<td><p>Find features between <code class="docutils literal notranslate"><span class="pre">low_sigma</span></code> and <code class="docutils literal notranslate"><span class="pre">high_sigma</span></code> in size.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.farid" title="skimage.filters.farid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid</span></code></a></p></td>
<td><p>Find the edge magnitude using the Farid transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.farid_h" title="skimage.filters.farid_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid_h</span></code></a></p></td>
<td><p>Find the horizontal edges of an image using the Farid transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.farid_v" title="skimage.filters.farid_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid_v</span></code></a></p></td>
<td><p>Find the vertical edges of an image using the Farid transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.filter_forward" title="skimage.filters.filter_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter_forward</span></code></a></p></td>
<td><p>Apply the given filter to data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.filter_inverse" title="skimage.filters.filter_inverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter_inverse</span></code></a></p></td>
<td><p>Apply the filter in reverse to the given data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.frangi" title="skimage.filters.frangi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">frangi</span></code></a></p></td>
<td><p>Filter an image with the Frangi vesselness filter.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.gabor" title="skimage.filters.gabor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gabor</span></code></a></p></td>
<td><p>Return real and imaginary responses to Gabor filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.gabor_kernel" title="skimage.filters.gabor_kernel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gabor_kernel</span></code></a></p></td>
<td><p>Return complex 2D Gabor filter kernel.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.gaussian" title="skimage.filters.gaussian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gaussian</span></code></a></p></td>
<td><p>Multi-dimensional Gaussian filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.hessian" title="skimage.filters.hessian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hessian</span></code></a></p></td>
<td><p>Filter an image with the Hybrid Hessian filter.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.laplace" title="skimage.filters.laplace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">laplace</span></code></a></p></td>
<td><p>Find the edges of an image using the Laplace operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.median" title="skimage.filters.median"><code class="xref py py-obj docutils literal notranslate"><span class="pre">median</span></code></a></p></td>
<td><p>Return local median of an image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.meijering" title="skimage.filters.meijering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">meijering</span></code></a></p></td>
<td><p>Filter an image with the Meijering neuriteness filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.prewitt" title="skimage.filters.prewitt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt</span></code></a></p></td>
<td><p>Find the edge magnitude using the Prewitt transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.prewitt_h" title="skimage.filters.prewitt_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt_h</span></code></a></p></td>
<td><p>Find the horizontal edges of an image using the Prewitt transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.prewitt_v" title="skimage.filters.prewitt_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt_v</span></code></a></p></td>
<td><p>Find the vertical edges of an image using the Prewitt transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.rank_order" title="skimage.filters.rank_order"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rank_order</span></code></a></p></td>
<td><p>Return an image of the same shape where each pixel is the index of the pixel value in the ascending order of the unique values of <code class="docutils literal notranslate"><span class="pre">image</span></code>, aka the rank-order value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.roberts" title="skimage.filters.roberts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roberts</span></code></a></p></td>
<td><p>Find the edge magnitude using Roberts' cross operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.roberts_neg_diag" title="skimage.filters.roberts_neg_diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roberts_neg_diag</span></code></a></p></td>
<td><p>Find the cross edges of an image using the Roberts' Cross operator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.roberts_pos_diag" title="skimage.filters.roberts_pos_diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roberts_pos_diag</span></code></a></p></td>
<td><p>Find the cross edges of an image using Roberts' cross operator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.sato" title="skimage.filters.sato"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sato</span></code></a></p></td>
<td><p>Filter an image with the Sato tubeness filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.scharr" title="skimage.filters.scharr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr</span></code></a></p></td>
<td><p>Find the edge magnitude using the Scharr transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.scharr_h" title="skimage.filters.scharr_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr_h</span></code></a></p></td>
<td><p>Find the horizontal edges of an image using the Scharr transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.scharr_v" title="skimage.filters.scharr_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr_v</span></code></a></p></td>
<td><p>Find the vertical edges of an image using the Scharr transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.sobel" title="skimage.filters.sobel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel</span></code></a></p></td>
<td><p>Find edges in an image using the Sobel filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.sobel_h" title="skimage.filters.sobel_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel_h</span></code></a></p></td>
<td><p>Find the horizontal edges of an image using the Sobel transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.sobel_v" title="skimage.filters.sobel_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel_v</span></code></a></p></td>
<td><p>Find the vertical edges of an image using the Sobel transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.threshold_isodata" title="skimage.filters.threshold_isodata"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_isodata</span></code></a></p></td>
<td><p>Return threshold value(s) based on ISODATA method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.threshold_li" title="skimage.filters.threshold_li"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_li</span></code></a></p></td>
<td><p>Compute threshold value by Li's iterative Minimum Cross Entropy method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.threshold_local" title="skimage.filters.threshold_local"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_local</span></code></a></p></td>
<td><p>Compute a threshold mask image based on local pixel neighborhood.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.threshold_mean" title="skimage.filters.threshold_mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_mean</span></code></a></p></td>
<td><p>Return threshold value based on the mean of grayscale values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.threshold_minimum" title="skimage.filters.threshold_minimum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_minimum</span></code></a></p></td>
<td><p>Return threshold value based on minimum method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.threshold_multiotsu" title="skimage.filters.threshold_multiotsu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_multiotsu</span></code></a></p></td>
<td><p>Generate <code class="xref py py-obj docutils literal notranslate"><span class="pre">classes</span></code>-1 threshold values to divide gray levels in <code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code>, following Otsu's method for multiple classes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.threshold_niblack" title="skimage.filters.threshold_niblack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_niblack</span></code></a></p></td>
<td><p>Applies Niblack local threshold to an array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.threshold_otsu" title="skimage.filters.threshold_otsu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_otsu</span></code></a></p></td>
<td><p>Return threshold value based on Otsu's method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.threshold_sauvola" title="skimage.filters.threshold_sauvola"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_sauvola</span></code></a></p></td>
<td><p>Applies Sauvola local threshold to an array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.threshold_triangle" title="skimage.filters.threshold_triangle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_triangle</span></code></a></p></td>
<td><p>Return threshold value based on the triangle algorithm.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.threshold_yen" title="skimage.filters.threshold_yen"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_yen</span></code></a></p></td>
<td><p>Return threshold value based on Yen's method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.try_all_threshold" title="skimage.filters.try_all_threshold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">try_all_threshold</span></code></a></p></td>
<td><p>Returns a figure comparing the outputs of different thresholding methods.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.unsharp_mask" title="skimage.filters.unsharp_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unsharp_mask</span></code></a></p></td>
<td><p>Unsharp masking filter.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.wiener" title="skimage.filters.wiener"><code class="xref py py-obj docutils literal notranslate"><span class="pre">wiener</span></code></a></p></td>
<td><p>Minimum Mean Square Error (Wiener) inverse filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.filters.window" title="skimage.filters.window"><code class="xref py py-obj docutils literal notranslate"><span class="pre">window</span></code></a></p></td>
<td><p>Return an n-dimensional window of a given size and dimensionality.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.filters.LPIFilter2D" title="skimage.filters.LPIFilter2D"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LPIFilter2D</span></code></a></p></td>
<td><p>Linear Position-Invariant Filter (2-dimensional)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="skimage.filters.rank.html#module-skimage.filters.rank" title="skimage.filters.rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rank</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.apply_hysteresis_threshold">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">apply_hysteresis_threshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L1186-L1230"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.apply_hysteresis_threshold" title="Link to this definition">#</a></dt>
<dd><p>Apply hysteresis thresholding to <code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
<p>This algorithm finds regions where <code class="docutils literal notranslate"><span class="pre">image</span></code> is greater than <code class="docutils literal notranslate"><span class="pre">high</span></code>
OR <code class="docutils literal notranslate"><span class="pre">image</span></code> is greater than <code class="docutils literal notranslate"><span class="pre">low</span></code> <em>and</em> that region is connected to
a region greater than <code class="docutils literal notranslate"><span class="pre">high</span></code>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>low</strong><span class="classifier">float, or array of same shape as <code class="docutils literal notranslate"><span class="pre">image</span></code></span></dt><dd><p>Lower threshold.</p>
</dd>
<dt><strong>high</strong><span class="classifier">float, or array of same shape as <code class="docutils literal notranslate"><span class="pre">image</span></code></span></dt><dd><p>Higher threshold.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>thresholded</strong><span class="classifier">(M[, …]) array of bool</span></dt><dd><p>Array in which <code class="docutils literal notranslate"><span class="pre">True</span></code> indicates the locations where <code class="docutils literal notranslate"><span class="pre">image</span></code>
was above the hysteresis threshold.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rfd96194f9a6b-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>J. Canny. A computational approach to edge detection.
IEEE Transactions on Pattern Analysis and Machine Intelligence.
1986; vol. 8, pp.679-698.
<a class="reference external" href="https://doi.org/10.1109/TPAMI.1986.4767851">DOI:10.1109/TPAMI.1986.4767851</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">apply_hysteresis_threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">array([0, 1, 1, 1, 0, 0, 0, 1, 1])</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Hysteresis is the lagging of an effect---a kind of inertia. In the context of thresholding, it means that areas above some low threshold are considered to be above the threshold if they are also connected to areas above a higher, more stringent, threshold. They can thus be seen as continuations of these high-confidence areas."><img alt="" src="../_images/sphx_glr_plot_hysteresis_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_hysteresis.html#sphx-glr-auto-examples-filters-plot-hysteresis-py"><span class="std std-ref">Hysteresis thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Hysteresis thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In various image analysis situations, it is useful to think of the pixels of an image, or of a region of an image, as a network or graph, in which each pixel is connected to its neighbors (with or without diagonals). One such situation is finding the geodesic center of an object, which is the point closest to all other points if you are only allowed to travel on the pixels of the object, rather than in a straight line. This point is the one with maximal closeness centrality [1]_ in the network."><img alt="" src="../_images/sphx_glr_plot_pixel_graphs_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_pixel_graphs.html#sphx-glr-auto-examples-applications-plot-pixel-graphs-py"><span class="std std-ref">Use pixel graphs to find an object’s geodesic center</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use pixel graphs to find an object's geodesic center</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.butterworth">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">butterworth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff_frequency_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squared_butterworth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_fft_based.py#L57-L189"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.butterworth" title="Link to this definition">#</a></dt>
<dd><p>Apply a Butterworth filter to enhance high or low frequency features.</p>
<p>This filter is defined in the Fourier domain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M[, N[, …, P]][, C]) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>cutoff_frequency_ratio</strong><span class="classifier">float, optional</span></dt><dd><p>Determines the position of the cut-off relative to the shape of the
FFT. Receives a value between [0, 0.5].</p>
</dd>
<dt><strong>high_pass</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to perform a high pass filter. If False, a low pass filter is
performed.</p>
</dd>
<dt><strong>order</strong><span class="classifier">float, optional</span></dt><dd><p>Order of the filter which affects the slope near the cut-off. Higher
order means steeper slope in frequency space.</p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int, optional</span></dt><dd><p>If there is a channel dimension, provide the index here. If None
(default) then all axes are assumed to be spatial dimensions.</p>
</dd>
<dt><strong>squared_butterworth</strong><span class="classifier">bool, optional</span></dt><dd><p>When True, the square of a Butterworth filter is used. See notes below
for more details.</p>
</dd>
<dt><strong>npad</strong><span class="classifier">int, optional</span></dt><dd><p>Pad each edge of the image by <code class="xref py py-obj docutils literal notranslate"><span class="pre">npad</span></code> pixels using <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.pad.html#numpy.pad" title="(in NumPy v2.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.pad</span></code></a>’s
<code class="docutils literal notranslate"><span class="pre">mode='edge'</span></code> extension.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>result</strong><span class="classifier">ndarray</span></dt><dd><p>The Butterworth-filtered image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>A band-pass filter can be achieved by combining a high-pass and low-pass
filter. The user can increase <code class="xref py py-obj docutils literal notranslate"><span class="pre">npad</span></code> if boundary artifacts are apparent.</p>
<p>The “Butterworth filter” used in image processing textbooks (e.g. <a class="reference internal" href="#r158eb86722ba-1" id="id2">[1]</a>,
<a class="reference internal" href="#r158eb86722ba-2" id="id3">[2]</a>) is often the square of the traditional Butterworth filters as
described by <a class="reference internal" href="#r158eb86722ba-3" id="id4">[3]</a>, <a class="reference internal" href="#r158eb86722ba-4" id="id5">[4]</a>. The squared version will be used here if
<code class="xref py py-obj docutils literal notranslate"><span class="pre">squared_butterworth</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>. The lowpass, squared Butterworth
filter is given by the following expression for the lowpass case:</p>
<div class="math notranslate nohighlight">
\[H_{low}(f) = \frac{1}{1 + \left(\frac{f}{c f_s}\right)^{2n}}\]</div>
<p>with the highpass case given by</p>
<div class="math notranslate nohighlight">
\[H_{hi}(f) = 1 - H_{low}(f)\]</div>
<p>where <span class="math notranslate nohighlight">\(f=\sqrt{\sum_{d=0}^{\mathrm{ndim}} f_{d}^{2}}\)</span> is the
absolute value of the spatial frequency, <span class="math notranslate nohighlight">\(f_s\)</span> is the sampling
frequency, <span class="math notranslate nohighlight">\(c\)</span> the <code class="docutils literal notranslate"><span class="pre">cutoff_frequency_ratio</span></code>, and <span class="math notranslate nohighlight">\(n\)</span> is the
filter <code class="xref py py-obj docutils literal notranslate"><span class="pre">order</span></code> <a class="reference internal" href="#r158eb86722ba-1" id="id6">[1]</a>. When <code class="docutils literal notranslate"><span class="pre">squared_butterworth=False</span></code>, the square root of
the above expressions are used instead.</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">cutoff_frequency_ratio</span></code> is defined in terms of the sampling
frequency, <span class="math notranslate nohighlight">\(f_s\)</span>. The FFT spectrum covers the Nyquist range
(<span class="math notranslate nohighlight">\([-f_s/2, f_s/2]\)</span>) so <code class="docutils literal notranslate"><span class="pre">cutoff_frequency_ratio</span></code> should have a value
between 0 and 0.5. The frequency response (gain) at the cutoff is 0.5 when
<code class="docutils literal notranslate"><span class="pre">squared_butterworth</span></code> is true and <span class="math notranslate nohighlight">\(1/\sqrt{2}\)</span> when it is false.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r158eb86722ba-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p>Russ, John C., et al. The Image Processing Handbook, 3rd. Ed.
1999, CRC Press, LLC.</p>
</div>
<div class="citation" id="r158eb86722ba-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">2</a><span class="fn-bracket">]</span></span>
<p>Birchfield, Stan. Image Processing and Analysis. 2018. Cengage
Learning.</p>
</div>
<div class="citation" id="r158eb86722ba-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">3</a><span class="fn-bracket">]</span></span>
<p>Butterworth, Stephen. “On the theory of filter amplifiers.”
Wireless Engineer 7.6 (1930): 536-541.</p>
</div>
<div class="citation" id="r158eb86722ba-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">4</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Butterworth_filter">https://en.wikipedia.org/wiki/Butterworth_filter</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Apply a high-pass and low-pass Butterworth filter to a grayscale and
color image respectively:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span><span class="p">,</span> <span class="n">astronaut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">butterworth</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">high_pass</span> <span class="o">=</span> <span class="n">butterworth</span><span class="p">(</span><span class="n">camera</span><span class="p">(),</span> <span class="mf">0.07</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">low_pass</span> <span class="o">=</span> <span class="n">butterworth</span><span class="p">(</span><span class="n">astronaut</span><span class="p">(),</span> <span class="mf">0.01</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">channel_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The Butterworth filter is implemented in the frequency domain and is designed to have no passband or stopband ripple. It can be used in either a lowpass or highpass variant. The cutoff_frequency_ratio parameter is used to set the cutoff frequency as a fraction of the sampling frequency. Given that the Nyquist frequency is half the sampling frequency, this means that this parameter should be a positive floating point value &lt; 0.5. The order of the filter can be adjusted to control the transition width, with higher values leading to a sharper transition between the passband and stopband."><img alt="" src="../_images/sphx_glr_plot_butterworth_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_butterworth.html#sphx-glr-auto-examples-filters-plot-butterworth-py"><span class="std std-ref">Butterworth Filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Butterworth Filters</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.correlate_sparse">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">correlate_sparse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_sparse.py#L83-L139"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.correlate_sparse" title="Link to this definition">#</a></dt>
<dd><p>Compute valid cross-correlation of <code class="xref py py-obj docutils literal notranslate"><span class="pre">padded_array</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel</span></code>.</p>
<p>This function is <em>fast</em> when <code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel</span></code> is large with many zeros.</p>
<p>See <code class="docutils literal notranslate"><span class="pre">scipy.ndimage.correlate</span></code> for a description of cross-correlation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray, dtype float, shape (M, N[, …], P)</span></dt><dd><p>The input array. If mode is ‘valid’, this array should already be
padded, as a margin of the same shape as kernel will be stripped
off.</p>
</dd>
<dt><strong>kernel</strong><span class="classifier">ndarray, dtype float, shape (Q, R[, …], S)</span></dt><dd><p>The kernel to be correlated. Must have the same number of
dimensions as <code class="xref py py-obj docutils literal notranslate"><span class="pre">padded_array</span></code>. For high performance, it should
be sparse (few nonzero entries).</p>
</dd>
<dt><strong>mode</strong><span class="classifier">string, optional</span></dt><dd><p>See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.correlate.html#scipy.ndimage.correlate" title="(in SciPy v1.14.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.ndimage.correlate</span></code></a> for valid modes.
Additionally, mode ‘valid’ is accepted, in which case no padding is
applied and the result is the result for the smaller image for which
the kernel is entirely inside the original data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>result</strong><span class="classifier">array of float, shape (M, N[, …], P)</span></dt><dd><p>The result of cross-correlating <code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code> with <code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel</span></code>. If mode
‘valid’ is used, the resulting shape is (M-Q+1, N-R+1[, …], P-S+1).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.difference_of_gaussians">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">difference_of_gaussians</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_gaussian.py#L9-L168"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.difference_of_gaussians" title="Link to this definition">#</a></dt>
<dd><p>Find features between <code class="docutils literal notranslate"><span class="pre">low_sigma</span></code> and <code class="docutils literal notranslate"><span class="pre">high_sigma</span></code> in size.</p>
<p>This function uses the Difference of Gaussians method for applying
band-pass filters to multi-dimensional arrays. The input array is
blurred with two Gaussian kernels of differing sigmas to produce two
intermediate, filtered images. The more-blurred image is then subtracted
from the less-blurred image. The final output image will therefore have
had high-frequency components attenuated by the smaller-sigma Gaussian, and
low frequency components will have been removed due to their presence in
the more-blurred intermediate.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input array to filter.</p>
</dd>
<dt><strong>low_sigma</strong><span class="classifier">scalar or sequence of scalars</span></dt><dd><p>Standard deviation(s) for the Gaussian kernel with the smaller sigmas
across all axes. The standard deviations are given for each axis as a
sequence, or as a single number, in which case the single number is
used as the standard deviation value for all axes.</p>
</dd>
<dt><strong>high_sigma</strong><span class="classifier">scalar or sequence of scalars, optional (default is None)</span></dt><dd><p>Standard deviation(s) for the Gaussian kernel with the larger sigmas
across all axes. The standard deviations are given for each axis as a
sequence, or as a single number, in which case the single number is
used as the standard deviation value for all axes. If None is given
(default), sigmas for all axes are calculated as 1.6 * low_sigma.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘reflect’, ‘constant’, ‘nearest’, ‘mirror’, ‘wrap’}, optional</span></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">mode</span></code> parameter determines how the array borders are
handled, where <code class="docutils literal notranslate"><span class="pre">cval</span></code> is the value when mode is equal to
‘constant’. Default is ‘nearest’.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">scalar, optional</span></dt><dd><p>Value to fill past edges of input if <code class="docutils literal notranslate"><span class="pre">mode</span></code> is ‘constant’. Default
is 0.0</p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><code class="docutils literal notranslate"><span class="pre">channel_axis</span></code> was added in 0.19.</p>
</div>
</dd>
<dt><strong>truncate</strong><span class="classifier">float, optional (default is 4.0)</span></dt><dd><p>Truncate the filter at this many standard deviations.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>filtered_image</strong><span class="classifier">ndarray</span></dt><dd><p>the filtered array.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="skimage.feature.html#skimage.feature.blob_dog" title="skimage.feature.blob_dog"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.blob_dog</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This function will subtract an array filtered with a Gaussian kernel
with sigmas given by <code class="docutils literal notranslate"><span class="pre">high_sigma</span></code> from an array filtered with a
Gaussian kernel with sigmas provided by <code class="docutils literal notranslate"><span class="pre">low_sigma</span></code>. The values for
<code class="docutils literal notranslate"><span class="pre">high_sigma</span></code> must always be greater than or equal to the corresponding
values in <code class="docutils literal notranslate"><span class="pre">low_sigma</span></code>, or a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">high_sigma</span></code> is none, the values for <code class="docutils literal notranslate"><span class="pre">high_sigma</span></code> will be
calculated as 1.6x the corresponding values in <code class="docutils literal notranslate"><span class="pre">low_sigma</span></code>. This ratio
was originally proposed by Marr and Hildreth (1980) <a class="reference internal" href="#r96d4c0941595-1" id="id11">[1]</a> and is commonly
used when approximating the inverted Laplacian of Gaussian, which is used
in edge and blob detection.</p>
<p>Input image is converted according to the conventions of <code class="docutils literal notranslate"><span class="pre">img_as_float</span></code>.</p>
<p>Except for sigma values, all parameters are used for both filters.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r96d4c0941595-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">1</a><span class="fn-bracket">]</span></span>
<p>Marr, D. and Hildreth, E. Theory of Edge Detection. Proc. R. Soc.
Lond. Series B 207, 187-217 (1980).
<a class="reference external" href="https://doi.org/10.1098/rspb.1980.0020">https://doi.org/10.1098/rspb.1980.0020</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Apply a simple Difference of Gaussians filter to a color image:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">astronaut</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">difference_of_gaussians</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filtered_image</span> <span class="o">=</span> <span class="n">difference_of_gaussians</span><span class="p">(</span><span class="n">astronaut</span><span class="p">(),</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>                                         <span class="n">channel_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Apply a Laplacian of Gaussian filter as approximated by the Difference
of Gaussians filter:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">filtered_image</span> <span class="o">=</span> <span class="n">difference_of_gaussians</span><span class="p">(</span><span class="n">astronaut</span><span class="p">(),</span> <span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                                         <span class="n">channel_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Apply a Difference of Gaussians filter to a grayscale image using different
sigma values for each axis:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filtered_image</span> <span class="o">=</span> <span class="n">difference_of_gaussians</span><span class="p">(</span><span class="n">camera</span><span class="p">(),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Phase correlation (``registration.phase_cross_correlation``) is an efficient method for determining translation offset between pairs of similar images. However this approach relies on a near absence of rotation/scaling differences between the images, which are typical in real-world examples."><img alt="" src="../_images/sphx_glr_plot_register_rotation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_register_rotation.html#sphx-glr-auto-examples-registration-plot-register-rotation-py"><span class="std std-ref">Using Polar and Log-Polar Transformations for Registration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using Polar and Log-Polar Transformations for Registration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Band-pass filters attenuate signal frequencies outside of a range (band) of interest. In image analysis, they can be used to denoise images while at the same time reducing low-frequency artifacts such a uneven illumination. Band-pass filters can be used to find image features such as blobs and edges."><img alt="" src="../_images/sphx_glr_plot_dog_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_dog.html#sphx-glr-auto-examples-filters-plot-dog-py"><span class="std std-ref">Band-pass filtering by Difference of Gaussians</span></a></p>
  <div class="sphx-glr-thumbnail-title">Band-pass filtering by Difference of Gaussians</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.farid">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">farid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L719-L786"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.farid" title="Link to this definition">#</a></dt>
<dd><p>Find the edge magnitude using the Farid transform.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">array</span></dt><dd><p>The input image.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">array of bool, optional</span></dt><dd><p>Clip the output image to this mask. (Values where mask=0 will be set
to 0.)</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or sequence of int, optional</span></dt><dd><p>Compute the edge filter along this axis. If not provided, the edge
magnitude is computed. This is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">farid_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">farid</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
                         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)])</span> <span class="o">/</span> <span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
</pre></div>
</div>
<p>The magnitude is also computed if axis is a sequence.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str or sequence of str, optional</span></dt><dd><p>The boundary mode for the convolution. See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve" title="(in SciPy v1.14.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.ndimage.convolve</span></code></a>
for a description of the modes. This can be either a single boundary
mode or one boundary mode per axis.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>When <code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code> is <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>, this is the constant used in values
outside the boundary of the image data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">array of float</span></dt><dd><p>The Farid edge map.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.farid_h" title="skimage.filters.farid_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid_h</span></code></a>, <a class="reference internal" href="#skimage.filters.farid_v" title="skimage.filters.farid_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid_v</span></code></a></dt><dd><p>horizontal and vertical edge detection.</p>
</dd>
<dt><a class="reference internal" href="#skimage.filters.scharr" title="skimage.filters.scharr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr</span></code></a>, <a class="reference internal" href="#skimage.filters.sobel" title="skimage.filters.sobel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel</span></code></a>, <a class="reference internal" href="#skimage.filters.prewitt" title="skimage.filters.prewitt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt</span></code></a>, <a class="reference internal" href="skimage.feature.html#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Take the square root of the sum of the squares of the horizontal and
vertical derivatives to get a magnitude that is somewhat insensitive to
direction. Similar to the Scharr operator, this operator is designed with
a rotation invariance constraint.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r17be61216823-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Farid, H. and Simoncelli, E. P., “Differentiation of discrete
multidimensional signals”, IEEE Transactions on Image Processing
13(4): 496-508, 2004. <a class="reference external" href="https://doi.org/10.1109/TIP.2004.823819">DOI:10.1109/TIP.2004.823819</a></p>
</div>
<div class="citation" id="r17be61216823-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Wikipedia, “Farid and Simoncelli Derivatives.” Available at:
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Image_derivatives#Farid_and_Simoncelli_Derivatives">https://en.wikipedia.org/wiki/Image_derivatives#Farid_and_Simoncelli_Derivatives</a>&gt;</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">camera</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">filters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges</span> <span class="o">=</span> <span class="n">filters</span><span class="o">.</span><span class="n">farid</span><span class="p">(</span><span class="n">camera</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.farid_h">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">farid_h</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L789-L826"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.farid_h" title="Link to this definition">#</a></dt>
<dd><p>Find the horizontal edges of an image using the Farid transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Farid edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The kernel was constructed using the 5-tap weights from [1].</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rcc13081f5169-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Farid, H. and Simoncelli, E. P., “Differentiation of discrete
multidimensional signals”, IEEE Transactions on Image Processing
13(4): 496-508, 2004. <a class="reference external" href="https://doi.org/10.1109/TIP.2004.823819">DOI:10.1109/TIP.2004.823819</a></p>
</div>
<div class="citation" id="rcc13081f5169-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Farid, H. and Simoncelli, E. P. “Optimally rotation-equivariant
directional derivative kernels”, In: 7th International Conference on
Computer Analysis of Images and Patterns, Kiel, Germany. Sep, 1997.</p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.farid_v">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">farid_v</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L829-L863"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.farid_v" title="Link to this definition">#</a></dt>
<dd><p>Find the vertical edges of an image using the Farid transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Farid edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The kernel was constructed using the 5-tap weights from [1].</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rb924cb19b62d-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Farid, H. and Simoncelli, E. P., “Differentiation of discrete
multidimensional signals”, IEEE Transactions on Image Processing
13(4): 496-508, 2004. <a class="reference external" href="https://doi.org/10.1109/TIP.2004.823819">DOI:10.1109/TIP.2004.823819</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.filter_forward">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">filter_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">impulse_response</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predefined_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/lpi_filter.py#L133-L170"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.filter_forward" title="Link to this definition">#</a></dt>
<dd><p>Apply the given filter to data.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>data</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>impulse_response</strong><span class="classifier">callable <code class="xref py py-obj docutils literal notranslate"><span class="pre">f(r,</span> <span class="pre">c,</span> <span class="pre">**filter_params)</span></code></span></dt><dd><p>Impulse response of the filter.  See LPIFilter2D.__init__.</p>
</dd>
<dt><strong>filter_params</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword parameters to the impulse_response function.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Other Parameters<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>predefined_filter</strong><span class="classifier">LPIFilter2D</span></dt><dd><p>If you need to apply the same filter multiple times over different
images, construct the LPIFilter2D and specify it here.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Gaussian filter without normalization:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">filt_func</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">r</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">c</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filtered</span> <span class="o">=</span> <span class="n">filter_forward</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">(),</span> <span class="n">filt_func</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.filter_inverse">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">filter_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">impulse_response</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predefined_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/lpi_filter.py#L173-L215"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.filter_inverse" title="Link to this definition">#</a></dt>
<dd><p>Apply the filter in reverse to the given data.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>data</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>impulse_response</strong><span class="classifier">callable <code class="xref py py-obj docutils literal notranslate"><span class="pre">f(r,</span> <span class="pre">c,</span> <span class="pre">**filter_params)</span></code></span></dt><dd><p>Impulse response of the filter.  See <a class="reference internal" href="#skimage.filters.LPIFilter2D" title="skimage.filters.LPIFilter2D"><code class="xref py py-class docutils literal notranslate"><span class="pre">LPIFilter2D</span></code></a>. This is a required
argument unless a <code class="xref py py-obj docutils literal notranslate"><span class="pre">predifined_filter</span></code> is provided.</p>
</dd>
<dt><strong>filter_params</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword parameters to the impulse_response function.</p>
</dd>
<dt><strong>max_gain</strong><span class="classifier">float, optional</span></dt><dd><p>Limit the filter gain.  Often, the filter contains zeros, which would
cause the inverse filter to have infinite gain.  High gain causes
amplification of artefacts, so a conservative limit is recommended.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Other Parameters<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>predefined_filter</strong><span class="classifier">LPIFilter2D, optional</span></dt><dd><p>If you need to apply the same filter multiple times over different
images, construct the LPIFilter2D and specify it here.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.frangi">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">frangi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">range(1,</span> <span class="pre">10,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">black_ridges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/ridges.py#L174-L304"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.frangi" title="Link to this definition">#</a></dt>
<dd><p>Filter an image with the Frangi vesselness filter.</p>
<p>This filter can be used to detect continuous ridges, e.g. vessels,
wrinkles, rivers. It can be used to calculate the fraction of the
whole image containing such objects.</p>
<p>Defined only for 2-D and 3-D images. Calculates the eigenvalues of the
Hessian to compute the similarity of an image region to vessels, according
to the method described in <a class="reference internal" href="#r9152c279884a-1" id="id18">[1]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, P]) ndarray</span></dt><dd><p>Array with input image data.</p>
</dd>
<dt><strong>sigmas</strong><span class="classifier">iterable of floats, optional</span></dt><dd><p>Sigmas used as scales of filter, i.e.,
np.arange(scale_range[0], scale_range[1], scale_step)</p>
</dd>
<dt><strong>scale_range</strong><span class="classifier">2-tuple of floats, optional</span></dt><dd><p>The range of sigmas used.</p>
</dd>
<dt><strong>scale_step</strong><span class="classifier">float, optional</span></dt><dd><p>Step size between sigmas.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Frangi correction constant that adjusts the filter’s
sensitivity to deviation from a plate-like structure.</p>
</dd>
<dt><strong>beta</strong><span class="classifier">float, optional</span></dt><dd><p>Frangi correction constant that adjusts the filter’s
sensitivity to deviation from a blob-like structure.</p>
</dd>
<dt><strong>gamma</strong><span class="classifier">float, optional</span></dt><dd><p>Frangi correction constant that adjusts the filter’s
sensitivity to areas of high variance/texture/structure.
The default, None, uses half of the maximum Hessian norm.</p>
</dd>
<dt><strong>black_ridges</strong><span class="classifier">boolean, optional</span></dt><dd><p>When True (the default), the filter detects black ridges; when
False, it detects white ridges.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M, N[, P]) ndarray</span></dt><dd><p>Filtered image (maximum of pixels across all scales).</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.meijering" title="skimage.filters.meijering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">meijering</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.sato" title="skimage.filters.sato"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sato</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.hessian" title="skimage.filters.hessian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hessian</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Earlier versions of this filter were implemented by Marc Schrijver,
(November 2001), D. J. Kroon, University of Twente (May 2009) <a class="reference internal" href="#r9152c279884a-2" id="id19">[2]</a>, and
D. G. Ellis (January 2017) <a class="reference internal" href="#r9152c279884a-3" id="id20">[3]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r9152c279884a-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">1</a><span class="fn-bracket">]</span></span>
<p>Frangi, A. F., Niessen, W. J., Vincken, K. L., &amp; Viergever, M. A.
(1998,). Multiscale vessel enhancement filtering. In International
Conference on Medical Image Computing and Computer-Assisted
Intervention (pp. 130-137). Springer Berlin Heidelberg.
<a class="reference external" href="https://doi.org/10.1007/BFb0056195">DOI:10.1007/BFb0056195</a></p>
</div>
<div class="citation" id="r9152c279884a-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">2</a><span class="fn-bracket">]</span></span>
<p>Kroon, D. J.: Hessian based Frangi vesselness filter.</p>
</div>
<div class="citation" id="r9152c279884a-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">3</a><span class="fn-bracket">]</span></span>
<p>Ellis, D. G.: <a class="github reference external" href="https://github.com/ellisdg/frangi3d/tree/master/frangi">ellisdg/frangi3d</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Ridge filters can be used to detect ridge-like structures, such as neurites [1]_, tubes [2]_, vessels [3]_, wrinkles [4]_ or rivers."><img alt="" src="../_images/sphx_glr_plot_ridge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_ridge_filter.html#sphx-glr-auto-examples-edges-plot-ridge-filter-py"><span class="std std-ref">Ridge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Ridge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.gabor">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">gabor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bandwidth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_stds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_gabor.py#L115-L220"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.gabor" title="Link to this definition">#</a></dt>
<dd><p>Return real and imaginary responses to Gabor filter.</p>
<p>The real and imaginary parts of the Gabor filter kernel are applied to the
image and the response is returned as a pair of arrays.</p>
<p>Gabor filter is a linear filter with a Gaussian kernel which is modulated
by a sinusoidal plane wave. Frequency and orientation representations of
the Gabor filter are similar to those of the human visual system.
Gabor filter banks are commonly used in computer vision and image
processing. They are especially suitable for edge detection and texture
classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>frequency</strong><span class="classifier">float</span></dt><dd><p>Spatial frequency of the harmonic function. Specified in pixels.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">float, optional</span></dt><dd><p>Orientation in radians. If 0, the harmonic is in the x-direction.</p>
</dd>
<dt><strong>bandwidth</strong><span class="classifier">float, optional</span></dt><dd><p>The bandwidth captured by the filter. For fixed bandwidth, <code class="docutils literal notranslate"><span class="pre">sigma_x</span></code>
and <code class="docutils literal notranslate"><span class="pre">sigma_y</span></code> will decrease with increasing frequency. This value is
ignored if <code class="docutils literal notranslate"><span class="pre">sigma_x</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma_y</span></code> are set by the user.</p>
</dd>
<dt><strong>sigma_x, sigma_y</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation in x- and y-directions. These directions apply to
the kernel <em>before</em> rotation. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span> <span class="pre">=</span> <span class="pre">pi/2</span></code>, then the kernel is
rotated 90 degrees so that <code class="docutils literal notranslate"><span class="pre">sigma_x</span></code> controls the <em>vertical</em>
direction.</p>
</dd>
<dt><strong>n_stds</strong><span class="classifier">scalar, optional</span></dt><dd><p>The linear size of the kernel is n_stds (3 by default) standard
deviations.</p>
</dd>
<dt><strong>offset</strong><span class="classifier">float, optional</span></dt><dd><p>Phase offset of harmonic function in radians.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘nearest’, ‘reflect’, ‘mirror’, ‘wrap’}, optional</span></dt><dd><p>Mode used to convolve image with a kernel, passed to <code class="xref py py-obj docutils literal notranslate"><span class="pre">ndi.convolve</span></code></p>
</dd>
<dt><strong>cval</strong><span class="classifier">scalar, optional</span></dt><dd><p>Value to fill past edges of input if <code class="docutils literal notranslate"><span class="pre">mode</span></code> of convolution is
‘constant’. The parameter is passed to <code class="xref py py-obj docutils literal notranslate"><span class="pre">ndi.convolve</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>real, imag</strong><span class="classifier">arrays</span></dt><dd><p>Filtered images using the real and imaginary parts of the Gabor filter
kernel. Images are of the same dimensions as the input one.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rc394129659a3-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Gabor_filter">https://en.wikipedia.org/wiki/Gabor_filter</a></p>
</div>
<div class="citation" id="rc394129659a3-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://web.archive.org/web/20180127125930/http://mplab.ucsd.edu/tutorials/gabor.pdf">https://web.archive.org/web/20180127125930/http://mplab.ucsd.edu/tutorials/gabor.pdf</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">gabor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>  
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">coins</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># detecting edges in a coin image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filt_real</span><span class="p">,</span> <span class="n">filt_imag</span> <span class="o">=</span> <span class="n">gabor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fix</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">filt_real</span><span class="p">)</span>      
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>                
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># less sensitivity to finer details with the lower frequency kernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filt_real</span><span class="p">,</span> <span class="n">filt_imag</span> <span class="o">=</span> <span class="n">gabor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">filt_real</span><span class="p">)</span>      
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>                
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.gabor_kernel">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">gabor_kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frequency</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bandwidth=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_x=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma_y=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_stds=3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.complex128'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_gabor.py#L17-L112"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.gabor_kernel" title="Link to this definition">#</a></dt>
<dd><p>Return complex 2D Gabor filter kernel.</p>
<p>Gabor kernel is a Gaussian kernel modulated by a complex harmonic function.
Harmonic function consists of an imaginary sine function and a real
cosine function. Spatial frequency is inversely proportional to the
wavelength of the harmonic and to the standard deviation of a Gaussian
kernel. The bandwidth is also inversely proportional to the standard
deviation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>frequency</strong><span class="classifier">float</span></dt><dd><p>Spatial frequency of the harmonic function. Specified in pixels.</p>
</dd>
<dt><strong>theta</strong><span class="classifier">float, optional</span></dt><dd><p>Orientation in radians. If 0, the harmonic is in the x-direction.</p>
</dd>
<dt><strong>bandwidth</strong><span class="classifier">float, optional</span></dt><dd><p>The bandwidth captured by the filter. For fixed bandwidth, <code class="docutils literal notranslate"><span class="pre">sigma_x</span></code>
and <code class="docutils literal notranslate"><span class="pre">sigma_y</span></code> will decrease with increasing frequency. This value is
ignored if <code class="docutils literal notranslate"><span class="pre">sigma_x</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma_y</span></code> are set by the user.</p>
</dd>
<dt><strong>sigma_x, sigma_y</strong><span class="classifier">float, optional</span></dt><dd><p>Standard deviation in x- and y-directions. These directions apply to
the kernel <em>before</em> rotation. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span> <span class="pre">=</span> <span class="pre">pi/2</span></code>, then the kernel is
rotated 90 degrees so that <code class="docutils literal notranslate"><span class="pre">sigma_x</span></code> controls the <em>vertical</em>
direction.</p>
</dd>
<dt><strong>n_stds</strong><span class="classifier">scalar, optional</span></dt><dd><p>The linear size of the kernel is n_stds (3 by default) standard
deviations</p>
</dd>
<dt><strong>offset</strong><span class="classifier">float, optional</span></dt><dd><p>Phase offset of harmonic function in radians.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">{np.complex64, np.complex128}</span></dt><dd><p>Specifies if the filter is single or double precision complex.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>g</strong><span class="classifier">complex array</span></dt><dd><p>Complex filter kernel.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r5ad457f519cf-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Gabor_filter">https://en.wikipedia.org/wiki/Gabor_filter</a></p>
</div>
<div class="citation" id="r5ad457f519cf-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://web.archive.org/web/20180127125930/http://mplab.ucsd.edu/tutorials/gabor.pdf">https://web.archive.org/web/20180127125930/http://mplab.ucsd.edu/tutorials/gabor.pdf</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">gabor_kernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>  
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gk</span> <span class="o">=</span> <span class="n">gabor_kernel</span><span class="p">(</span><span class="n">frequency</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gk</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>        
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>                
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># more ripples (equivalent to increasing the size of the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Gaussian spread)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gk</span> <span class="o">=</span> <span class="n">gabor_kernel</span><span class="p">(</span><span class="n">frequency</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">suplots</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">gk</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>       
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>               
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on Gabor filter banks. Frequency and orientation representations of the Gabor filter are similar to those of the human visual system."><img alt="" src="../_images/sphx_glr_plot_gabor_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_gabor.html#sphx-glr-auto-examples-features-detection-plot-gabor-py"><span class="std std-ref">Gabor filter banks for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gabor filter banks for texture classification</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.gaussian">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">gaussian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/_shared/filters.py#L19-L136"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.gaussian" title="Link to this definition">#</a></dt>
<dd><p>Multi-dimensional Gaussian filter.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Input image (grayscale or color) to filter.</p>
</dd>
<dt><strong>sigma</strong><span class="classifier">scalar or sequence of scalars, optional</span></dt><dd><p>Standard deviation for Gaussian kernel. The standard
deviations of the Gaussian filter are given for each axis as a
sequence, or as a single number, in which case it is equal for
all axes.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘reflect’, ‘constant’, ‘nearest’, ‘mirror’, ‘wrap’}, optional</span></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">mode</span></code> parameter determines how the array borders are
handled, where <code class="docutils literal notranslate"><span class="pre">cval</span></code> is the value when mode is equal to
‘constant’. Default is ‘nearest’.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">scalar, optional</span></dt><dd><p>Value to fill past edges of input if <code class="docutils literal notranslate"><span class="pre">mode</span></code> is ‘constant’. Default
is 0.0</p>
</dd>
<dt><strong>preserve_range</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, keep the original range of values. Otherwise, the input
<code class="docutils literal notranslate"><span class="pre">image</span></code> is converted according to the conventions of <code class="docutils literal notranslate"><span class="pre">img_as_float</span></code>
(Normalized first to values [-1.0 ; 1.0] or [0 ; 1.0] depending on
dtype of input)</p>
<p>For more information, see:
<a class="reference external" href="https://scikit-image.org/docs/dev/user_guide/data_types.html">https://scikit-image.org/docs/dev/user_guide/data_types.html</a></p>
</dd>
<dt><strong>truncate</strong><span class="classifier">float, optional</span></dt><dd><p>Truncate the filter at this many standard deviations.</p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><code class="xref py py-obj docutils literal notranslate"><span class="pre">channel_axis</span></code> was added in 0.19.</p>
</div>
</dd>
<dt><strong>out</strong><span class="classifier">ndarray, optional</span></dt><dd><p>If given, the filtered image will be stored in this array.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.23: </span><code class="xref py py-obj docutils literal notranslate"><span class="pre">out</span></code> was added in 0.23.</p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>filtered_image</strong><span class="classifier">ndarray</span></dt><dd><p>the filtered array</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function is a wrapper around <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html#scipy.ndimage.gaussian_filter" title="(in SciPy v1.14.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.ndimage.gaussian_filter()</span></code></a>.</p>
<p>Integer arrays are converted to float.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">out</span></code> should be of floating-point data type since <a class="reference internal" href="#skimage.filters.gaussian" title="skimage.filters.gaussian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gaussian</span></code></a> converts the
input <code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code> to float. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">out</span></code> is not provided, another array
will be allocated and returned as the result.</p>
<p>The multi-dimensional filter is implemented as a sequence of
one-dimensional convolution filters. The intermediate arrays are
stored in the same data type as the output. Therefore, for output
types with a limited precision, the results may be imprecise
because intermediate results may be stored with insufficient
precision.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">skimage</span> <span class="k">as</span> <span class="nn">ski</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[0., 0., 0.],</span>
<span class="go">       [0., 1., 0.],</span>
<span class="go">       [0., 0., 0.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ski</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>  <span class="c1"># mild smoothing</span>
<span class="go">array([[0.00163116, 0.03712502, 0.00163116],</span>
<span class="go">       [0.03712502, 0.84496158, 0.03712502],</span>
<span class="go">       [0.00163116, 0.03712502, 0.00163116]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ski</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># more smoothing</span>
<span class="go">array([[0.05855018, 0.09653293, 0.05855018],</span>
<span class="go">       [0.09653293, 0.15915589, 0.09653293],</span>
<span class="go">       [0.05855018, 0.09653293, 0.05855018]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Several modes are possible for handling boundaries</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ski</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">)</span>
<span class="go">array([[0.08767308, 0.12075024, 0.08767308],</span>
<span class="go">       [0.12075024, 0.16630671, 0.12075024],</span>
<span class="go">       [0.08767308, 0.12075024, 0.08767308]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># For RGB images, each is filtered separately</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">ski</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astronaut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filtered_img</span> <span class="o">=</span> <span class="n">ski</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">channel_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The active contour model is a method to fit open or closed splines to lines or edges in an image [1]_. It works by minimising an energy that is in part defined by the image and part by the spline&#x27;s shape: length and smoothness. The minimization is done implicitly in the shape energy and explicitly in the image energy."><img alt="" src="../_images/sphx_glr_plot_active_contours_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_active_contours.html#sphx-glr-auto-examples-edges-plot-active-contours-py"><span class="std std-ref">Active Contour Model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Active Contour Model</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how a set of images can be assembled under the hypothesis of rigid body motions."><img alt="" src="../_images/sphx_glr_plot_stitching_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_stitching.html#sphx-glr-auto-examples-registration-plot-stitching-py"><span class="std std-ref">Assemble images with simple image stitching</span></a></p>
  <div class="sphx-glr-thumbnail-title">Assemble images with simple image stitching</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate the use of different metrics to assess the colocalization of two different image channels."><img alt="" src="../_images/sphx_glr_plot_colocalization_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_colocalization_metrics.html#sphx-glr-auto-examples-applications-plot-colocalization-metrics-py"><span class="std std-ref">Colocalization metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Colocalization metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we identify and track the solid-liquid (S-L) interface in a nickel-based alloy undergoing solidification. Tracking the solidification over time enables the calculation of the solidification velocity. This is important to characterize the solidified structure of the sample and will be used to inform research into additive manufacturing of metals. The image sequence was obtained by the Center for Advanced Non-Ferrous Structural Alloys (CANFSA) using synchrotron x-radiography at the Advanced Photon Source (APS) at Argonne National Laboratory (ANL). This analysis was first presented at a conference [1]_."><img alt="" src="../_images/sphx_glr_plot_solidification_tracking_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_solidification_tracking.html#sphx-glr-auto-examples-applications-plot-solidification-tracking-py"><span class="std std-ref">Track solidification of a metallic alloy</span></a></p>
  <div class="sphx-glr-thumbnail-title">Track solidification of a metallic alloy</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example reproduces a well-established workflow in bioimage data analysis for measuring the fluorescence intensity localized to the nuclear envelope, in a time sequence of cell images (each with two channels and two spatial dimensions) which shows a process of protein re-localization from the cytoplasmic area to the nuclear envelope. This biological application was first presented by Andrea Boni and collaborators in [1]_; it was used in a textbook by Kota Miura [2]_ as well as in other works ([3]_, [4]_). In other words, we port this workflow from ImageJ Macro to Python with scikit-image."><img alt="" src="../_images/sphx_glr_plot_fluorescence_nuclear_envelope_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_fluorescence_nuclear_envelope.html#sphx-glr-auto-examples-applications-plot-fluorescence-nuclear-envelope-py"><span class="std std-ref">Measure fluorescence intensity at the nuclear envelope</span></a></p>
  <div class="sphx-glr-thumbnail-title">Measure fluorescence intensity at the nuclear envelope</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.hessian">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">hessian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">range(1,</span> <span class="pre">10,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">black_ridges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/ridges.py#L307-L393"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.hessian" title="Link to this definition">#</a></dt>
<dd><p>Filter an image with the Hybrid Hessian filter.</p>
<p>This filter can be used to detect continuous edges, e.g. vessels,
wrinkles, rivers. It can be used to calculate the fraction of the whole
image containing such objects.</p>
<p>Defined only for 2-D and 3-D images. Almost equal to Frangi filter, but
uses alternative method of smoothing. Refer to <a class="reference internal" href="#r29057abd4159-1" id="id28">[1]</a> to find the differences
between Frangi and Hessian filters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, P]) ndarray</span></dt><dd><p>Array with input image data.</p>
</dd>
<dt><strong>sigmas</strong><span class="classifier">iterable of floats, optional</span></dt><dd><p>Sigmas used as scales of filter, i.e.,
np.arange(scale_range[0], scale_range[1], scale_step)</p>
</dd>
<dt><strong>scale_range</strong><span class="classifier">2-tuple of floats, optional</span></dt><dd><p>The range of sigmas used.</p>
</dd>
<dt><strong>scale_step</strong><span class="classifier">float, optional</span></dt><dd><p>Step size between sigmas.</p>
</dd>
<dt><strong>beta</strong><span class="classifier">float, optional</span></dt><dd><p>Frangi correction constant that adjusts the filter’s
sensitivity to deviation from a blob-like structure.</p>
</dd>
<dt><strong>gamma</strong><span class="classifier">float, optional</span></dt><dd><p>Frangi correction constant that adjusts the filter’s
sensitivity to areas of high variance/texture/structure.</p>
</dd>
<dt><strong>black_ridges</strong><span class="classifier">boolean, optional</span></dt><dd><p>When True (the default), the filter detects black ridges; when
False, it detects white ridges.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M, N[, P]) ndarray</span></dt><dd><p>Filtered image (maximum of pixels across all scales).</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.meijering" title="skimage.filters.meijering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">meijering</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.sato" title="skimage.filters.sato"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sato</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.frangi" title="skimage.filters.frangi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">frangi</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Written by Marc Schrijver (November 2001)
Re-Written by D. J. Kroon University of Twente (May 2009) <a class="reference internal" href="#r29057abd4159-2" id="id29">[2]</a></p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r29057abd4159-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id28">1</a><span class="fn-bracket">]</span></span>
<p>Ng, C. C., Yap, M. H., Costen, N., &amp; Li, B. (2014,). Automatic
wrinkle detection using hybrid Hessian filter. In Asian Conference on
Computer Vision (pp. 609-622). Springer International Publishing.
<a class="reference external" href="https://doi.org/10.1007/978-3-319-16811-1_40">DOI:10.1007/978-3-319-16811-1_40</a></p>
</div>
<div class="citation" id="r29057abd4159-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">2</a><span class="fn-bracket">]</span></span>
<p>Kroon, D. J.: Hessian based Frangi vesselness filter.</p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Ridge filters can be used to detect ridge-like structures, such as neurites [1]_, tubes [2]_, vessels [3]_, wrinkles [4]_ or rivers."><img alt="" src="../_images/sphx_glr_plot_ridge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_ridge_filter.html#sphx-glr-auto-examples-edges-plot-ridge-filter-py"><span class="std std-ref">Ridge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Ridge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.laplace">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">laplace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ksize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L681-L716"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.laplace" title="Link to this definition">#</a></dt>
<dd><p>Find the edges of an image using the Laplace operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>ksize</strong><span class="classifier">int, optional</span></dt><dd><p>Define the size of the discrete Laplacian operator such that it
will have a size of (ksize,) * image.ndim.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">ndarray, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">ndarray</span></dt><dd><p>The Laplace edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The Laplacian operator is generated using the function
skimage.restoration.uft.laplacian().</p>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.median">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">median</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">footprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">behavior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ndimage'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_median.py#L9-L82"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.median" title="Link to this definition">#</a></dt>
<dd><p>Return local median of an image.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">array-like</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>footprint</strong><span class="classifier">ndarray, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">behavior=='rank'</span></code>, <code class="docutils literal notranslate"><span class="pre">footprint</span></code> is a 2-D array of 1’s and 0’s.
If <code class="docutils literal notranslate"><span class="pre">behavior=='ndimage'</span></code>, <code class="docutils literal notranslate"><span class="pre">footprint</span></code> is a N-D array of 1’s and 0’s
with the same number of dimension than <code class="docutils literal notranslate"><span class="pre">image</span></code>.
If None, <code class="docutils literal notranslate"><span class="pre">footprint</span></code> will be a N-D array with 3 elements for each
dimension (e.g., vector, square, cube, etc.)</p>
</dd>
<dt><strong>out</strong><span class="classifier">ndarray, (same dtype as image), optional</span></dt><dd><p>If None, a new array is allocated.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘reflect’, ‘constant’, ‘nearest’, ‘mirror’,’‘wrap’}, optional</span></dt><dd><p>The mode parameter determines how the array borders are handled, where
<code class="docutils literal notranslate"><span class="pre">cval</span></code> is the value when mode is equal to ‘constant’.
Default is ‘nearest’.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.15: </span><code class="docutils literal notranslate"><span class="pre">mode</span></code> is used when <code class="docutils literal notranslate"><span class="pre">behavior='ndimage'</span></code>.</p>
</div>
</dd>
<dt><strong>cval</strong><span class="classifier">scalar, optional</span></dt><dd><p>Value to fill past edges of input if mode is ‘constant’. Default is 0.0</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.15: </span><code class="docutils literal notranslate"><span class="pre">cval</span></code> was added in 0.15 is used when <code class="docutils literal notranslate"><span class="pre">behavior='ndimage'</span></code>.</p>
</div>
</dd>
<dt><strong>behavior</strong><span class="classifier">{‘ndimage’, ‘rank’}, optional</span></dt><dd><p>Either to use the old behavior (i.e., &lt; 0.15) or the new behavior.
The old behavior will call the <a class="reference internal" href="skimage.filters.rank.html#skimage.filters.rank.median" title="skimage.filters.rank.median"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.filters.rank.median()</span></code></a>.
The new behavior will call the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.median_filter.html#scipy.ndimage.median_filter" title="(in SciPy v1.14.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.ndimage.median_filter()</span></code></a>.
Default is ‘ndimage’.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.15: </span><code class="docutils literal notranslate"><span class="pre">behavior</span></code> is introduced in 0.15</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.16: </span>Default <code class="docutils literal notranslate"><span class="pre">behavior</span></code> has been changed from ‘rank’ to ‘ndimage’</p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">2-D array (same dtype as input image)</span></dt><dd><p>Output image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="skimage.filters.rank.html#skimage.filters.rank.median" title="skimage.filters.rank.median"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.filters.rank.median</span></code></a></dt><dd><p>Rank-based implementation of the median filtering offering more flexibility with additional parameters but dedicated for unsigned integer images.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.morphology</span> <span class="kn">import</span> <span class="n">disk</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">median</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">med</span> <span class="o">=</span> <span class="n">median</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">disk</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.meijering">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">meijering</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">range(1,</span> <span class="pre">10,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">black_ridges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/ridges.py#L20-L100"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.meijering" title="Link to this definition">#</a></dt>
<dd><p>Filter an image with the Meijering neuriteness filter.</p>
<p>This filter can be used to detect continuous ridges, e.g. neurites,
wrinkles, rivers. It can be used to calculate the fraction of the
whole image containing such objects.</p>
<p>Calculates the eigenvalues of the Hessian to compute the similarity of
an image region to neurites, according to the method described in <a class="reference internal" href="#rbd62388c4e81-1" id="id32">[1]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Array with input image data.</p>
</dd>
<dt><strong>sigmas</strong><span class="classifier">iterable of floats, optional</span></dt><dd><p>Sigmas used as scales of filter</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Shaping filter constant, that selects maximally flat elongated
features.  The default, None, selects the optimal value -1/(ndim+1).</p>
</dd>
<dt><strong>black_ridges</strong><span class="classifier">boolean, optional</span></dt><dd><p>When True (the default), the filter detects black ridges; when
False, it detects white ridges.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Filtered image (maximum of pixels across all scales).</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.sato" title="skimage.filters.sato"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sato</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.frangi" title="skimage.filters.frangi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">frangi</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.hessian" title="skimage.filters.hessian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hessian</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rbd62388c4e81-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id32">1</a><span class="fn-bracket">]</span></span>
<p>Meijering, E., Jacob, M., Sarria, J. C., Steiner, P., Hirling, H.,
Unser, M. (2004). Design and validation of a tool for neurite tracing
and analysis in fluorescence microscopy images. Cytometry Part A,
58(2), 167-176.
<a class="reference external" href="https://doi.org/10.1002/cyto.a.20022">DOI:10.1002/cyto.a.20022</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Ridge filters can be used to detect ridge-like structures, such as neurites [1]_, tubes [2]_, vessels [3]_, wrinkles [4]_ or rivers."><img alt="" src="../_images/sphx_glr_plot_ridge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_ridge_filter.html#sphx-glr-auto-examples-edges-plot-ridge-filter-py"><span class="std std-ref">Ridge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Ridge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.prewitt">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">prewitt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L448-L504"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.prewitt" title="Link to this definition">#</a></dt>
<dd><p>Find the edge magnitude using the Prewitt transform.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">array</span></dt><dd><p>The input image.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">array of bool, optional</span></dt><dd><p>Clip the output image to this mask. (Values where mask=0 will be set
to 0.)</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or sequence of int, optional</span></dt><dd><p>Compute the edge filter along this axis. If not provided, the edge
magnitude is computed. This is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">prw_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">prewitt</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
                       <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)])</span> <span class="o">/</span> <span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
</pre></div>
</div>
<p>The magnitude is also computed if axis is a sequence.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str or sequence of str, optional</span></dt><dd><p>The boundary mode for the convolution. See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve" title="(in SciPy v1.14.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.ndimage.convolve</span></code></a>
for a description of the modes. This can be either a single boundary
mode or one boundary mode per axis.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>When <code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code> is <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>, this is the constant used in values
outside the boundary of the image data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">array of float</span></dt><dd><p>The Prewitt edge map.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.prewitt_h" title="skimage.filters.prewitt_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt_h</span></code></a>, <a class="reference internal" href="#skimage.filters.prewitt_v" title="skimage.filters.prewitt_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt_v</span></code></a></dt><dd><p>horizontal and vertical edge detection.</p>
</dd>
<dt><a class="reference internal" href="#skimage.filters.sobel" title="skimage.filters.sobel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel</span></code></a>, <a class="reference internal" href="#skimage.filters.scharr" title="skimage.filters.scharr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr</span></code></a>, <a class="reference internal" href="#skimage.filters.farid" title="skimage.filters.farid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid</span></code></a>, <a class="reference internal" href="skimage.feature.html#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The edge magnitude depends slightly on edge directions, since the
approximation of the gradient operator by the Prewitt operator is not
completely rotation invariant. For a better rotation invariance, the Scharr
operator should be used. The Sobel operator has a better rotation
invariance than the Prewitt operator, but a worse rotation invariance than
the Scharr operator.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">filters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">camera</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges</span> <span class="o">=</span> <span class="n">filters</span><span class="o">.</span><span class="n">prewitt</span><span class="p">(</span><span class="n">camera</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.prewitt_h">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">prewitt_h</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L507-L534"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.prewitt_h" title="Link to this definition">#</a></dt>
<dd><p>Find the horizontal edges of an image using the Prewitt transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Prewitt edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>   <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>   <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
  <span class="mi">0</span>     <span class="mi">0</span>     <span class="mi">0</span>
<span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>  <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>  <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.prewitt_v">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">prewitt_v</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L537-L564"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.prewitt_v" title="Link to this definition">#</a></dt>
<dd><p>Find the vertical edges of an image using the Prewitt transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Prewitt edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="mi">1</span><span class="o">/</span><span class="mi">3</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="mi">1</span><span class="o">/</span><span class="mi">3</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.rank_order">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">rank_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_rank_order.py#L9-L57"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.rank_order" title="Link to this definition">#</a></dt>
<dd><p>Return an image of the same shape where each pixel is the
index of the pixel value in the ascending order of the unique
values of <code class="docutils literal notranslate"><span class="pre">image</span></code>, aka the rank-order value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">ndarray</span></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">ndarray of unsigned integers, of shape image.shape</span></dt><dd><p>New array where each pixel has the rank-order value of the
corresponding pixel in <code class="docutils literal notranslate"><span class="pre">image</span></code>. Pixel values are between 0 and
n - 1, where n is the number of distinct unique values in
<code class="docutils literal notranslate"><span class="pre">image</span></code>. The dtype of this array will be determined by
<code class="docutils literal notranslate"><span class="pre">np.min_scalar_type(image.size)</span></code>.</p>
</dd>
<dt><strong>original_values</strong><span class="classifier">1-D ndarray</span></dt><dd><p>Unique original values of <code class="docutils literal notranslate"><span class="pre">image</span></code>. This will have the same dtype as
<code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[1, 4, 5],</span>
<span class="go">       [4, 4, 1],</span>
<span class="go">       [5, 1, 1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rank_order</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">(array([[0, 1, 2],</span>
<span class="go">       [1, 1, 0],</span>
<span class="go">       [2, 0, 0]], dtype=uint8), array([1, 4, 5]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rank_order</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="go">(array([0, 1, 2, 1], dtype=uint8), array([-1. ,  2.5,  3.1]))</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.roberts">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">roberts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L567-L602"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.roberts" title="Link to this definition">#</a></dt>
<dd><p>Find the edge magnitude using Roberts’ cross operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Roberts’ Cross edge map.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.roberts_pos_diag" title="skimage.filters.roberts_pos_diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roberts_pos_diag</span></code></a>, <a class="reference internal" href="#skimage.filters.roberts_neg_diag" title="skimage.filters.roberts_neg_diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roberts_neg_diag</span></code></a></dt><dd><p>diagonal edge detection.</p>
</dd>
<dt><a class="reference internal" href="#skimage.filters.sobel" title="skimage.filters.sobel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel</span></code></a>, <a class="reference internal" href="#skimage.filters.scharr" title="skimage.filters.scharr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr</span></code></a>, <a class="reference internal" href="#skimage.filters.prewitt" title="skimage.filters.prewitt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt</span></code></a>, <a class="reference internal" href="skimage.feature.html#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">camera</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">filters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges</span> <span class="o">=</span> <span class="n">filters</span><span class="o">.</span><span class="n">roberts</span><span class="p">(</span><span class="n">camera</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.roberts_neg_diag">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">roberts_neg_diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L643-L678"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.roberts_neg_diag" title="Link to this definition">#</a></dt>
<dd><p>Find the cross edges of an image using the Roberts’ Cross operator.</p>
<p>The kernel is applied to the input image to produce separate measurements
of the gradient component one orientation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Robert’s edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="mi">0</span>   <span class="mi">1</span>
<span class="o">-</span><span class="mi">1</span>   <span class="mi">0</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.roberts_pos_diag">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">roberts_pos_diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L605-L640"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.roberts_pos_diag" title="Link to this definition">#</a></dt>
<dd><p>Find the cross edges of an image using Roberts’ cross operator.</p>
<p>The kernel is applied to the input image to produce separate measurements
of the gradient component one orientation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Robert’s edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span>   <span class="mi">0</span>
<span class="mi">0</span>  <span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.sato">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">sato</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">range(1,</span> <span class="pre">10,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">black_ridges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/ridges.py#L103-L171"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.sato" title="Link to this definition">#</a></dt>
<dd><p>Filter an image with the Sato tubeness filter.</p>
<p>This filter can be used to detect continuous ridges, e.g. tubes,
wrinkles, rivers. It can be used to calculate the fraction of the
whole image containing such objects.</p>
<p>Defined only for 2-D and 3-D images. Calculates the eigenvalues of the
Hessian to compute the similarity of an image region to tubes, according to
the method described in <a class="reference internal" href="#r7b0e4f38c6a4-1" id="id34">[1]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, P]) ndarray</span></dt><dd><p>Array with input image data.</p>
</dd>
<dt><strong>sigmas</strong><span class="classifier">iterable of floats, optional</span></dt><dd><p>Sigmas used as scales of filter.</p>
</dd>
<dt><strong>black_ridges</strong><span class="classifier">boolean, optional</span></dt><dd><p>When True (the default), the filter detects black ridges; when
False, it detects white ridges.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘constant’, ‘reflect’, ‘wrap’, ‘nearest’, ‘mirror’}, optional</span></dt><dd><p>How to handle values outside the image borders.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Used in conjunction with mode ‘constant’, the value outside
the image boundaries.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>out</strong><span class="classifier">(M, N[, P]) ndarray</span></dt><dd><p>Filtered image (maximum of pixels across all scales).</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.meijering" title="skimage.filters.meijering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">meijering</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.frangi" title="skimage.filters.frangi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">frangi</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="#skimage.filters.hessian" title="skimage.filters.hessian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hessian</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r7b0e4f38c6a4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id34">1</a><span class="fn-bracket">]</span></span>
<p>Sato, Y., Nakajima, S., Shiraga, N., Atsumi, H., Yoshida, S.,
Koller, T., …, Kikinis, R. (1998). Three-dimensional multi-scale line
filter for segmentation and visualization of curvilinear structures in
medical images. Medical image analysis, 2(2), 143-168.
<a class="reference external" href="https://doi.org/10.1016/S1361-8415(98)80009-1">DOI:10.1016/S1361-8415(98)80009-1</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Ridge filters can be used to detect ridge-like structures, such as neurites [1]_, tubes [2]_, vessels [3]_, wrinkles [4]_ or rivers."><img alt="" src="../_images/sphx_glr_plot_ridge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_ridge_filter.html#sphx-glr-auto-examples-edges-plot-ridge-filter-py"><span class="std std-ref">Ridge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Ridge operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In various image analysis situations, it is useful to think of the pixels of an image, or of a region of an image, as a network or graph, in which each pixel is connected to its neighbors (with or without diagonals). One such situation is finding the geodesic center of an object, which is the point closest to all other points if you are only allowed to travel on the pixels of the object, rather than in a straight line. This point is the one with maximal closeness centrality [1]_ in the network."><img alt="" src="../_images/sphx_glr_plot_pixel_graphs_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_pixel_graphs.html#sphx-glr-auto-examples-applications-plot-pixel-graphs-py"><span class="std std-ref">Use pixel graphs to find an object’s geodesic center</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use pixel graphs to find an object's geodesic center</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.scharr">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">scharr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L317-L376"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.scharr" title="Link to this definition">#</a></dt>
<dd><p>Find the edge magnitude using the Scharr transform.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">array</span></dt><dd><p>The input image.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">array of bool, optional</span></dt><dd><p>Clip the output image to this mask. (Values where mask=0 will be set
to 0.)</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or sequence of int, optional</span></dt><dd><p>Compute the edge filter along this axis. If not provided, the edge
magnitude is computed. This is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sch_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">scharr</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
                       <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)])</span> <span class="o">/</span> <span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
</pre></div>
</div>
<p>The magnitude is also computed if axis is a sequence.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str or sequence of str, optional</span></dt><dd><p>The boundary mode for the convolution. See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve" title="(in SciPy v1.14.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.ndimage.convolve</span></code></a>
for a description of the modes. This can be either a single boundary
mode or one boundary mode per axis.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>When <code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code> is <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>, this is the constant used in values
outside the boundary of the image data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">array of float</span></dt><dd><p>The Scharr edge map.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.scharr_h" title="skimage.filters.scharr_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr_h</span></code></a>, <a class="reference internal" href="#skimage.filters.scharr_v" title="skimage.filters.scharr_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr_v</span></code></a></dt><dd><p>horizontal and vertical edge detection.</p>
</dd>
<dt><a class="reference internal" href="#skimage.filters.sobel" title="skimage.filters.sobel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel</span></code></a>, <a class="reference internal" href="#skimage.filters.prewitt" title="skimage.filters.prewitt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt</span></code></a>, <a class="reference internal" href="#skimage.filters.farid" title="skimage.filters.farid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid</span></code></a>, <a class="reference internal" href="skimage.feature.html#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The Scharr operator has a better rotation invariance than
other edge filters such as the Sobel or the Prewitt operators.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r6247f1470247-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>D. Kroon, 2009, Short Paper University Twente, Numerical
Optimization of Kernel Based Image Derivatives.</p>
</div>
<div class="citation" id="r6247f1470247-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Sobel_operator#Alternative_operators">https://en.wikipedia.org/wiki/Sobel_operator#Alternative_operators</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">filters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">camera</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges</span> <span class="o">=</span> <span class="n">filters</span><span class="o">.</span><span class="n">scharr</span><span class="p">(</span><span class="n">camera</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.scharr_h">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">scharr_h</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L379-L411"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.scharr_h" title="Link to this definition">#</a></dt>
<dd><p>Find the horizontal edges of an image using the Scharr transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Scharr edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="mi">3</span>   <span class="mi">10</span>   <span class="mi">3</span>
 <span class="mi">0</span>    <span class="mi">0</span>   <span class="mi">0</span>
<span class="o">-</span><span class="mi">3</span>  <span class="o">-</span><span class="mi">10</span>  <span class="o">-</span><span class="mi">3</span>
</pre></div>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rd36c6da974bf-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>D. Kroon, 2009, Short Paper University Twente, Numerical
Optimization of Kernel Based Image Derivatives.</p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.scharr_v">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">scharr_v</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L414-L445"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.scharr_v" title="Link to this definition">#</a></dt>
<dd><p>Find the vertical edges of an image using the Scharr transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Scharr edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="mi">3</span>   <span class="mi">0</span>   <span class="o">-</span><span class="mi">3</span>
<span class="mi">10</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">10</span>
 <span class="mi">3</span>   <span class="mi">0</span>   <span class="o">-</span><span class="mi">3</span>
</pre></div>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rb707fee1145e-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>D. Kroon, 2009, Short Paper University Twente, Numerical
Optimization of Kernel Based Image Derivatives.</p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.sobel">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">sobel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L200-L254"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.sobel" title="Link to this definition">#</a></dt>
<dd><p>Find edges in an image using the Sobel filter.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">array</span></dt><dd><p>The input image.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">array of bool, optional</span></dt><dd><p>Clip the output image to this mask. (Values where mask=0 will be set
to 0.)</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or sequence of int, optional</span></dt><dd><p>Compute the edge filter along this axis. If not provided, the edge
magnitude is computed. This is defined as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sobel_mag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">sobel</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
                         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)])</span> <span class="o">/</span> <span class="n">image</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
</pre></div>
</div>
<p>The magnitude is also computed if axis is a sequence.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str or sequence of str, optional</span></dt><dd><p>The boundary mode for the convolution. See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html#scipy.ndimage.convolve" title="(in SciPy v1.14.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.ndimage.convolve</span></code></a>
for a description of the modes. This can be either a single boundary
mode or one boundary mode per axis.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>When <code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code> is <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>, this is the constant used in values
outside the boundary of the image data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">array of float</span></dt><dd><p>The Sobel edge map.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#skimage.filters.sobel_h" title="skimage.filters.sobel_h"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel_h</span></code></a>, <a class="reference internal" href="#skimage.filters.sobel_v" title="skimage.filters.sobel_v"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sobel_v</span></code></a></dt><dd><p>horizontal and vertical edge detection.</p>
</dd>
<dt><a class="reference internal" href="#skimage.filters.scharr" title="skimage.filters.scharr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scharr</span></code></a>, <a class="reference internal" href="#skimage.filters.prewitt" title="skimage.filters.prewitt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prewitt</span></code></a>, <a class="reference internal" href="#skimage.filters.farid" title="skimage.filters.farid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farid</span></code></a>, <a class="reference internal" href="skimage.feature.html#skimage.feature.canny" title="skimage.feature.canny"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.feature.canny</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1e927ecde2f1-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>D. Kroon, 2009, Short Paper University Twente, Numerical
Optimization of Kernel Based Image Derivatives.</p>
</div>
<div class="citation" id="r1e927ecde2f1-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Sobel_operator">https://en.wikipedia.org/wiki/Sobel_operator</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">filters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">camera</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edges</span> <span class="o">=</span> <span class="n">filters</span><span class="o">.</span><span class="n">sobel</span><span class="p">(</span><span class="n">camera</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="There are many filters that are designed to work with gray-scale images but not with color images. To simplify the process of creating functions that can adapt to RGB images, scikit-image provides the adapt_rgb decorator."><img alt="" src="../_images/sphx_glr_plot_adapt_rgb_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_adapt_rgb.html#sphx-glr-auto-examples-color-exposure-plot-adapt-rgb-py"><span class="std std-ref">Adapting gray-scale filters to RGB images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Adapting gray-scale filters to RGB images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Hysteresis is the lagging of an effect---a kind of inertia. In the context of thresholding, it means that areas above some low threshold are considered to be above the threshold if they are also connected to areas above a higher, more stringent, threshold. They can thus be seen as continuations of these high-confidence areas."><img alt="" src="../_images/sphx_glr_plot_hysteresis_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_hysteresis.html#sphx-glr-auto-examples-filters-plot-hysteresis-py"><span class="std std-ref">Hysteresis thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Hysteresis thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Construct a region boundary RAG with the rag_boundary function. The function  :pyskimage.graph.rag_boundary takes an edge_map argument, which gives the significance of a feature (such as edges) being present at each pixel. In a region boundary RAG, the edge weight between two regions is the average value of the corresponding pixels in edge_map along their shared boundary."><img alt="" src="../_images/sphx_glr_plot_rag_boundary_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_boundary.html#sphx-glr-auto-examples-segmentation-plot-rag-boundary-py"><span class="std std-ref">Region Boundary based Region adjacency graphs (RAGs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region Boundary based Region adjacency graphs (RAGs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The watershed transform is commonly used as a starting point for many segmentation algorithms. However, without a judicious choice of seeds, it can produce very uneven fragment sizes, which can be difficult to deal with in downstream analyses."><img alt="" src="../_images/sphx_glr_plot_compact_watershed_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_compact_watershed.html#sphx-glr-auto-examples-segmentation-plot-compact-watershed-py"><span class="std std-ref">Find Regular Segments Using Compact Watershed</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find Regular Segments Using Compact Watershed</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Given several connected components represented by a label image, these connected components can be expanded into background regions using :pyskimage.segmentation.expand_labels. In contrast to :pyskimage.morphology.dilation this method will not let connected components expand into neighboring connected components with lower label number."><img alt="" src="../_images/sphx_glr_plot_expand_labels_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_expand_labels.html#sphx-glr-auto-examples-segmentation-plot-expand-labels-py"><span class="std std-ref">Expand segmentation labels without overlap</span></a></p>
  <div class="sphx-glr-thumbnail-title">Expand segmentation labels without overlap</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to obtain good segmentations, and the definition of &quot;good&quot; often depends on the application, these methods are usually used for obtaining an oversegmentation, also known as superpixels. These superpixels then serve as a basis for more sophisticated algorithms such as conditional random fields (CRF)."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When segmenting an image, you may want to combine multiple alternative segmentations. The :pyskimage.segmentation.join_segmentations function computes the join of two segmentations, in which a pixel is placed in the same segment if and only if it is in the same segment in both segmentations."><img alt="" src="../_images/sphx_glr_plot_join_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_join_segmentations.html#sphx-glr-auto-examples-segmentation-plot-join-segmentations-py"><span class="std std-ref">Find the intersection of two segmentations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find the intersection of two segmentations</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to perform hierarchical merging on region boundary Region Adjacency Graphs (RAGs). Region boundary RAGs can be constructed with the :pyskimage.graph.rag_boundary function. The regions with the lowest edge weights are successively merged until there is no edge with weight less than thresh. The hierarchical merging is done through the :pyskimage.graph.merge_hierarchical function. For an example of how to construct region boundary based RAGs, see plot_rag_boundary."><img alt="" src="../_images/sphx_glr_plot_boundary_merge_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_boundary_merge.html#sphx-glr-auto-examples-segmentation-plot-boundary-merge-py"><span class="std std-ref">Hierarchical Merging of Region Boundary RAGs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Hierarchical Merging of Region Boundary RAGs</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their similarity to an initial seed point [1]_. The conceptual analogy is the &#x27;paint bucket&#x27; tool in many graphic editors."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When trying out different segmentation methods, how do you know which one is best? If you have a ground truth or gold standard segmentation, you can use various metrics to check how close each automated method comes to the truth. In this example we use an easy-to-segment image as an example of how to interpret various segmentation metrics. We will use the adapted Rand error and the variation of information as example metrics, and see how oversegmentation (splitting of true segments into too many sub-segments) and undersegmentation (merging of different true segments into a single segment) affect the different scores."><img alt="" src="../_images/sphx_glr_plot_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_metrics.html#sphx-glr-auto-examples-segmentation-plot-metrics-py"><span class="std std-ref">Evaluating segmentation metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluating segmentation metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to segment objects from a background. We use the coins image from skimage.data, which shows several coins outlined against a darker background."><img alt="" src="../_images/sphx_glr_plot_coins_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_coins_segmentation.html#sphx-glr-auto-examples-applications-plot-coins-segmentation-py"><span class="std std-ref">Comparing edge-based and region-based segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing edge-based and region-based segmentation</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.sobel_h">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">sobel_h</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L257-L284"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.sobel_h" title="Link to this definition">#</a></dt>
<dd><p>Find the horizontal edges of an image using the Sobel transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Sobel edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="mi">1</span>   <span class="mi">2</span>   <span class="mi">1</span>
 <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">0</span>
<span class="o">-</span><span class="mi">1</span>  <span class="o">-</span><span class="mi">2</span>  <span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.sobel_v">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">sobel_v</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/edges.py#L287-L314"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.sobel_v" title="Link to this definition">#</a></dt>
<dd><p>Find the vertical edges of an image using the Sobel transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">2-D array</span></dt><dd><p>Image to process.</p>
</dd>
<dt><strong>mask</strong><span class="classifier">2-D array, optional</span></dt><dd><p>An optional mask to limit the application to a certain area.
Note that pixels surrounding masked regions are also masked to
prevent masked regions from affecting the result.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">2-D array</span></dt><dd><p>The Sobel edge map.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We use the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">1</span>
<span class="mi">2</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">2</span>
<span class="mi">1</span>   <span class="mi">0</span>  <span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_isodata">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_isodata</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L470-L584"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_isodata" title="Link to this definition">#</a></dt>
<dd><p>Return threshold value(s) based on ISODATA method.</p>
<p>Histogram-based threshold, known as Ridler-Calvard method or inter-means.
Threshold values returned satisfy the following equality:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="n">image</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span>
             <span class="n">image</span><span class="p">[</span><span class="n">image</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="mf">2.0</span>
</pre></div>
</div>
<p>That is, returned thresholds are intensities that separate the image into
two groups of pixels, where the threshold intensity is midway between the
mean intensities of these groups.</p>
<p>For integer images, the above equality holds to within one; for floating-
point images, the equality holds to within the histogram bin-width.</p>
<p>Either image or hist must be provided. In case hist is given, the actual
histogram of the image is ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>nbins</strong><span class="classifier">int, optional</span></dt><dd><p>Number of bins used to calculate histogram. This value is ignored for
integer arrays.</p>
</dd>
<dt><strong>return_all</strong><span class="classifier">bool, optional</span></dt><dd><p>If False (default), return only the lowest threshold that satisfies
the above equality. If True, return all valid thresholds.</p>
</dd>
<dt><strong>hist</strong><span class="classifier">array, or 2-tuple of arrays, optional</span></dt><dd><p>Histogram to determine the threshold from and a corresponding array
of bin center intensities. Alternatively, only the histogram can be
passed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float or int or array</span></dt><dd><p>Threshold value(s).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="re728dd270820-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Ridler, TW &amp; Calvard, S (1978), “Picture thresholding using an
iterative selection method”
IEEE Transactions on Systems, Man and Cybernetics 8: 630-632,
<a class="reference external" href="https://doi.org/10.1109/TSMC.1978.4310039">DOI:10.1109/TSMC.1978.4310039</a></p>
</div>
<div class="citation" id="re728dd270820-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Sezgin M. and Sankur B. (2004) “Survey over Image Thresholding
Techniques and Quantitative Performance Evaluation” Journal of
Electronic Imaging, 13(1): 146-165,
<a class="reference external" href="http://www.busim.ee.boun.edu.tr/~sankur/SankurFolder/Threshold_survey.pdf">http://www.busim.ee.boun.edu.tr/~sankur/SankurFolder/Threshold_survey.pdf</a>
<a class="reference external" href="https://doi.org/10.1117/1.1631315">DOI:10.1117/1.1631315</a></p>
</div>
<div class="citation" id="re728dd270820-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>ImageJ AutoThresholder code,
<a class="reference external" href="http://fiji.sc/wiki/index.php/Auto_Threshold">http://fiji.sc/wiki/index.php/Auto_Threshold</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">coins</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">coins</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_isodata</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">thresh</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_li">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_li</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_guess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter_callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L642-L792"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_li" title="Link to this definition">#</a></dt>
<dd><p>Compute threshold value by Li’s iterative Minimum Cross Entropy method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>tolerance</strong><span class="classifier">float, optional</span></dt><dd><p>Finish the computation when the change in the threshold in an iteration
is less than this value. By default, this is half the smallest
difference between intensity values in <code class="docutils literal notranslate"><span class="pre">image</span></code>.</p>
</dd>
<dt><strong>initial_guess</strong><span class="classifier">float or Callable[[array[float]], float], optional</span></dt><dd><p>Li’s iterative method uses gradient descent to find the optimal
threshold. If the image intensity histogram contains more than two
modes (peaks), the gradient descent could get stuck in a local optimum.
An initial guess for the iteration can help the algorithm find the
globally-optimal threshold. A float value defines a specific start
point, while a callable should take in an array of image intensities
and return a float value. Example valid callables include
<code class="docutils literal notranslate"><span class="pre">numpy.mean</span></code> (default), <code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">arr:</span> <span class="pre">numpy.quantile(arr,</span> <span class="pre">0.95)</span></code>,
or even <a class="reference internal" href="#skimage.filters.threshold_otsu" title="skimage.filters.threshold_otsu"><code class="xref py py-func docutils literal notranslate"><span class="pre">skimage.filters.threshold_otsu()</span></code></a>.</p>
</dd>
<dt><strong>iter_callback</strong><span class="classifier">Callable[[float], Any], optional</span></dt><dd><p>A function that will be called on the threshold at every iteration of
the algorithm.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Upper threshold value. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rc1e664efa0df-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Li C.H. and Lee C.K. (1993) “Minimum Cross Entropy Thresholding”
Pattern Recognition, 26(4): 617-625
<a class="reference external" href="https://doi.org/10.1016/0031-3203(93)90115-D">DOI:10.1016/0031-3203(93)90115-D</a></p>
</div>
<div class="citation" id="rc1e664efa0df-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Li C.H. and Tam P.K.S. (1998) “An Iterative Algorithm for Minimum
Cross Entropy Thresholding” Pattern Recognition Letters, 18(8): 771-776
<a class="reference external" href="https://doi.org/10.1016/S0167-8655(98)00057-9">DOI:10.1016/S0167-8655(98)00057-9</a></p>
</div>
<div class="citation" id="rc1e664efa0df-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Sezgin M. and Sankur B. (2004) “Survey over Image Thresholding
Techniques and Quantitative Performance Evaluation” Journal of
Electronic Imaging, 13(1): 146-165
<a class="reference external" href="https://doi.org/10.1117/1.1631315">DOI:10.1117/1.1631315</a></p>
</div>
<div class="citation" id="rc1e664efa0df-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>ImageJ AutoThresholder code, <a class="reference external" href="http://fiji.sc/wiki/index.php/Auto_Threshold">http://fiji.sc/wiki/index.php/Auto_Threshold</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_li</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">thresh</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="scikit-image has several ways of removing objects from N-dimensional images. Here, &quot;objects&quot; (and &quot;holes&quot;) are defined as groups of samples with the same label value which distinct from the background and other objects."><img alt="" src="../_images/sphx_glr_plot_remove_objects_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_remove_objects.html#sphx-glr-auto-examples-features-detection-plot-remove-objects-py"><span class="std std-ref">Removing objects</span></a></p>
  <div class="sphx-glr-thumbnail-title">Removing objects</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In 1993, Li and Lee proposed a new criterion for finding the &quot;optimal&quot; threshold to distinguish between the background and foreground of an image [1]_. They proposed that minimizing the cross-entropy between the foreground and the foreground mean, and the background and the background mean, would give the best threshold in most situations."><img alt="" src="../_images/sphx_glr_plot_threshold_li_thumb.png" />
<p><a class="reference internal" href="../auto_examples/developers/plot_threshold_li.html#sphx-glr-auto-examples-developers-plot-threshold-li-py"><span class="std std-ref">Li thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Li thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_local">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_local</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L177-L277"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_local" title="Link to this definition">#</a></dt>
<dd><p>Compute a threshold mask image based on local pixel neighborhood.</p>
<p>Also known as adaptive or dynamic thresholding. The threshold value is
the weighted mean for the local neighborhood of a pixel subtracted by a
constant. Alternatively the threshold can be determined dynamically by a
given function, using the ‘generic’ method.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>block_size</strong><span class="classifier">int or sequence of int</span></dt><dd><p>Odd size of pixel neighborhood which is used to calculate the
threshold value (e.g. 3, 5, 7, …, 21, …).</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘generic’, ‘gaussian’, ‘mean’, ‘median’}, optional</span></dt><dd><p>Method used to determine adaptive threshold for local neighborhood in
weighted mean image.</p>
<ul class="simple">
<li><p>‘generic’: use custom function (see <code class="docutils literal notranslate"><span class="pre">param</span></code> parameter)</p></li>
<li><p>‘gaussian’: apply gaussian filter (see <code class="docutils literal notranslate"><span class="pre">param</span></code> parameter for custom                      sigma value)</p></li>
<li><p>‘mean’: apply arithmetic mean filter</p></li>
<li><p>‘median’: apply median rank filter</p></li>
</ul>
<p>By default, the ‘gaussian’ method is used.</p>
</dd>
<dt><strong>offset</strong><span class="classifier">float, optional</span></dt><dd><p>Constant subtracted from weighted mean of neighborhood to calculate
the local threshold value. Default offset is 0.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">{‘reflect’, ‘constant’, ‘nearest’, ‘mirror’, ‘wrap’}, optional</span></dt><dd><p>The mode parameter determines how the array borders are handled, where
cval is the value when mode is equal to ‘constant’.
Default is ‘reflect’.</p>
</dd>
<dt><strong>param</strong><span class="classifier">{int, function}, optional</span></dt><dd><p>Either specify sigma for ‘gaussian’ method or function object for
‘generic’ method. This functions takes the flat array of local
neighborhood as a single argument and returns the calculated
threshold for the centre pixel.</p>
</dd>
<dt><strong>cval</strong><span class="classifier">float, optional</span></dt><dd><p>Value to fill past edges of input if mode is ‘constant’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Threshold image. All pixels in the input image higher than the
corresponding pixel in the threshold image are considered foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rf57739a75c82-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Gonzalez, R. C. and Wood, R. E. “Digital Image Processing
(2nd Edition).” Prentice-Hall Inc., 2002: 600–612.
ISBN: 0-201-18075-8</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()[:</span><span class="mi">50</span><span class="p">,</span> <span class="p">:</span><span class="mi">50</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary_image1</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">threshold_local</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">arr</span><span class="p">:</span> <span class="n">arr</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary_image2</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">threshold_local</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;generic&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                        <span class="n">param</span><span class="o">=</span><span class="n">func</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Optical coherence tomography (OCT) is a non-invasive imaging technique used by ophthalmologists to take pictures of the back of a patient&#x27;s eye [1]_. When performing OCT, dust may stick to the reference mirror of the equipment, causing dark spots to appear on the images. The problem is that these dirt spots cover areas of in-vivo tissue, hence hiding data of interest. Our goal here is to restore (reconstruct) the hidden areas based on the pixels near their boundaries."><img alt="" src="../_images/sphx_glr_plot_cornea_spot_inpainting_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_cornea_spot_inpainting.html#sphx-glr-auto-examples-applications-plot-cornea-spot-inpainting-py"><span class="std std-ref">Restore spotted cornea image with inpainting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Restore spotted cornea image with inpainting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_mean">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L886-L914"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_mean" title="Link to this definition">#</a></dt>
<dd><p>Return threshold value based on the mean of grayscale values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Upper threshold value. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r6186ece30463-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>C. A. Glasbey, “An analysis of histogram-based thresholding
algorithms,” CVGIP: Graphical Models and Image Processing,
vol. 55, pp. 532-537, 1993.
<a class="reference external" href="https://doi.org/10.1006/cgip.1993.1040">DOI:10.1006/cgip.1993.1040</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_mean</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">thresh</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_minimum">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_minimum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L795-L883"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_minimum" title="Link to this definition">#</a></dt>
<dd><p>Return threshold value based on minimum method.</p>
<p>The histogram of the input <code class="docutils literal notranslate"><span class="pre">image</span></code> is computed if not provided and
smoothed until there are only two maxima. Then the minimum in between is
the threshold value.</p>
<p>Either image or hist must be provided. In case hist is given, the actual
histogram of the image is ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray, optional</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>nbins</strong><span class="classifier">int, optional</span></dt><dd><p>Number of bins used to calculate histogram. This value is ignored for
integer arrays.</p>
</dd>
<dt><strong>max_num_iter</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of iterations to smooth the histogram.</p>
</dd>
<dt><strong>hist</strong><span class="classifier">array, or 2-tuple of arrays, optional</span></dt><dd><p>Histogram to determine the threshold from and a corresponding array
of bin center intensities. Alternatively, only the histogram can be
passed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Upper threshold value. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>RuntimeError</dt><dd><p>If unable to find two local maxima in the histogram or if the
smoothing takes more than 1e4 iterations.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rd44294765be8-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>C. A. Glasbey, “An analysis of histogram-based thresholding
algorithms,” CVGIP: Graphical Models and Image Processing,
vol. 55, pp. 532-537, 1993.</p>
</div>
<div class="citation" id="rd44294765be8-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Prewitt, JMS &amp; Mendelsohn, ML (1966), “The analysis of cell
images”, Annals of the New York Academy of Sciences 128: 1035-1053
<a class="reference external" href="https://doi.org/10.1111/j.1749-6632.1965.tb11715.x">DOI:10.1111/j.1749-6632.1965.tb11715.x</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_minimum</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">thresh</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we identify and track the solid-liquid (S-L) interface in a nickel-based alloy undergoing solidification. Tracking the solidification over time enables the calculation of the solidification velocity. This is important to characterize the solidified structure of the sample and will be used to inform research into additive manufacturing of metals. The image sequence was obtained by the Center for Advanced Non-Ferrous Structural Alloys (CANFSA) using synchrotron x-radiography at the Advanced Photon Source (APS) at Argonne National Laboratory (ANL). This analysis was first presented at a conference [1]_."><img alt="" src="../_images/sphx_glr_plot_solidification_tracking_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_solidification_tracking.html#sphx-glr-auto-examples-applications-plot-solidification-tracking-py"><span class="std std-ref">Track solidification of a metallic alloy</span></a></p>
  <div class="sphx-glr-thumbnail-title">Track solidification of a metallic alloy</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_multiotsu">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_multiotsu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L1233-L1339"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_multiotsu" title="Link to this definition">#</a></dt>
<dd><p>Generate <code class="xref py py-obj docutils literal notranslate"><span class="pre">classes</span></code>-1 threshold values to divide gray levels in <code class="xref py py-obj docutils literal notranslate"><span class="pre">image</span></code>,
following Otsu’s method for multiple classes.</p>
<p>The threshold values are chosen to maximize the total sum of pairwise
variances between the thresholded graylevel classes. See Notes and <a class="reference internal" href="#r9f5f8b3d5d49-1" id="id53">[1]</a>
for more details.</p>
<p>Either image or hist must be provided. If hist is provided, the actual
histogram of the image is ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray, optional</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>classes</strong><span class="classifier">int, optional</span></dt><dd><p>Number of classes to be thresholded, i.e. the number of resulting
regions.</p>
</dd>
<dt><strong>nbins</strong><span class="classifier">int, optional</span></dt><dd><p>Number of bins used to calculate the histogram. This value is ignored
for integer arrays.</p>
</dd>
<dt><strong>hist</strong><span class="classifier">array, or 2-tuple of arrays, optional</span></dt><dd><p>Histogram from which to determine the threshold, and optionally a
corresponding array of bin center intensities. If no hist provided,
this function will compute it from the image (see notes).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>thresh</strong><span class="classifier">array</span></dt><dd><p>Array containing the threshold values for the desired classes.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">image</span></code> contains less grayscale value then the desired
number of classes.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This implementation relies on a Cython function whose complexity
is <span class="math notranslate nohighlight">\(O\left(\frac{Ch^{C-1}}{(C-1)!}\right)\)</span>, where <span class="math notranslate nohighlight">\(h\)</span>
is the number of histogram bins and <span class="math notranslate nohighlight">\(C\)</span> is the number of
classes desired.</p>
<p>If no hist is given, this function will make use of
<a class="reference internal" href="skimage.exposure.html#skimage.exposure.histogram" title="skimage.exposure.histogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.exposure.histogram</span></code></a>, which behaves differently than
<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.histogram</span></code>. While both allowed, use the former for consistent
behaviour.</p>
<p>The input image must be grayscale.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r9f5f8b3d5d49-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id53">1</a><span class="fn-bracket">]</span></span>
<p>Liao, P-S., Chen, T-S. and Chung, P-C., “A fast algorithm for
multilevel thresholding”, Journal of Information Science and
Engineering 17 (5): 713-727, 2001. Available at:
&lt;<a class="reference external" href="https://ftp.iis.sinica.edu.tw/JISE/2001/200109_01.pdf">https://ftp.iis.sinica.edu.tw/JISE/2001/200109_01.pdf</a>&gt;
<a class="reference external" href="https://doi.org/10.6688/JISE.2001.17.5.1">DOI:10.6688/JISE.2001.17.5.1</a></p>
</div>
<div class="citation" id="r9f5f8b3d5d49-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Tosa, Y., “Multi-Otsu Threshold”, a java plugin for ImageJ.
Available at:
&lt;<a class="reference external" href="http://imagej.net/plugins/download/Multi_OtsuThreshold.java">http://imagej.net/plugins/download/Multi_OtsuThreshold.java</a>&gt;</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">label2rgb</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresholds</span> <span class="o">=</span> <span class="n">threshold_multiotsu</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">thresholds</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regions_colorized</span> <span class="o">=</span> <span class="n">label2rgb</span><span class="p">(</span><span class="n">regions</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The multi-Otsu threshold [1]_ is a thresholding algorithm that is used to separate the pixels of an input image into several different classes, each one obtained according to the intensity of the gray levels within the image."><img alt="" src="../_images/sphx_glr_plot_multiotsu_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_multiotsu.html#sphx-glr-auto-examples-segmentation-plot-multiotsu-py"><span class="std std-ref">Multi-Otsu Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multi-Otsu Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In various image analysis situations, it is useful to think of the pixels of an image, or of a region of an image, as a network or graph, in which each pixel is connected to its neighbors (with or without diagonals). One such situation is finding the geodesic center of an object, which is the point closest to all other points if you are only allowed to travel on the pixels of the object, rather than in a straight line. This point is the one with maximal closeness centrality [1]_ in the network."><img alt="" src="../_images/sphx_glr_plot_pixel_graphs_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_pixel_graphs.html#sphx-glr-auto-examples-applications-plot-pixel-graphs-py"><span class="std std-ref">Use pixel graphs to find an object’s geodesic center</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use pixel graphs to find an object's geodesic center</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we analyze a microscopy image of human cells. We use data provided by Jason Moffat [1]_ through CellProfiler."><img alt="" src="../_images/sphx_glr_plot_human_mitosis_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_human_mitosis.html#sphx-glr-auto-examples-applications-plot-human-mitosis-py"><span class="std std-ref">Segment human cells (in mitosis)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Segment human cells (in mitosis)</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_niblack">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_niblack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L1063-L1123"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_niblack" title="Link to this definition">#</a></dt>
<dd><p>Applies Niblack local threshold to an array.</p>
<p>A threshold T is calculated for every pixel in the image using the
following formula:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">k</span> <span class="o">*</span> <span class="n">s</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>where m(x,y) and s(x,y) are the mean and standard deviation of
pixel (x,y) neighborhood defined by a rectangular window with size w
times w centered around the pixel. k is a configurable parameter
that weights the effect of standard deviation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>window_size</strong><span class="classifier">int, or iterable of int, optional</span></dt><dd><p>Window size specified as a single odd integer (3, 5, 7, …),
or an iterable of length <code class="docutils literal notranslate"><span class="pre">image.ndim</span></code> containing only odd
integers (e.g. <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">5,</span> <span class="pre">5)</span></code>).</p>
</dd>
<dt><strong>k</strong><span class="classifier">float, optional</span></dt><dd><p>Value of parameter k in threshold formula.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Threshold mask. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This algorithm is originally designed for text recognition.</p>
<p>The Bradley threshold is a particular case of the Niblack
one, being equivalent to</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">page</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">threshold_image</span> <span class="o">=</span> <span class="n">threshold_niblack</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">q</span>
</pre></div>
</div>
<p>for some value <code class="docutils literal notranslate"><span class="pre">q</span></code>. By default, Bradley and Roth use <code class="docutils literal notranslate"><span class="pre">q=1</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="re9c5e7c193ed-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>W. Niblack, An introduction to Digital Image Processing,
Prentice-Hall, 1986.</p>
</div>
<div class="citation" id="re9c5e7c193ed-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>D. Bradley and G. Roth, “Adaptive thresholding using Integral
Image”, Journal of Graphics Tools 12(2), pp. 13-21, 2007.
<a class="reference external" href="https://doi.org/10.1080/2151237X.2007.10129236">DOI:10.1080/2151237X.2007.10129236</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">page</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">threshold_image</span> <span class="o">=</span> <span class="n">threshold_niblack</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Niblack and Sauvola thresholds are local thresholding techniques that are useful for images where the background is not uniform, especially for text recognition [1]_, [2]_. Instead of calculating a single global threshold for the entire image, several thresholds are calculated for every pixel by using specific formulae that take into account the mean and standard deviation of the local neighborhood (defined by a window centered around the pixel)."><img alt="" src="../_images/sphx_glr_plot_niblack_sauvola_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_niblack_sauvola.html#sphx-glr-auto-examples-segmentation-plot-niblack-sauvola-py"><span class="std std-ref">Niblack and Sauvola Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Niblack and Sauvola Thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_otsu">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_otsu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L336-L407"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_otsu" title="Link to this definition">#</a></dt>
<dd><p>Return threshold value based on Otsu’s method.</p>
<p>Either image or hist must be provided. If hist is provided, the actual
histogram of the image is ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray, optional</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>nbins</strong><span class="classifier">int, optional</span></dt><dd><p>Number of bins used to calculate histogram. This value is ignored for
integer arrays.</p>
</dd>
<dt><strong>hist</strong><span class="classifier">array, or 2-tuple of arrays, optional</span></dt><dd><p>Histogram from which to determine the threshold, and optionally a
corresponding array of bin center intensities. If no hist provided,
this function will compute it from the image.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Upper threshold value. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The input image must be grayscale.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1bb8cdf6ebea-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Wikipedia, <a class="reference external" href="https://en.wikipedia.org/wiki/Otsu's_Method">https://en.wikipedia.org/wiki/Otsu’s_Method</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_otsu</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&lt;=</span> <span class="n">thresh</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_."><img alt="" src="../_images/sphx_glr_plot_thresholding_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_thresholding.html#sphx-glr-auto-examples-segmentation-plot-thresholding-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Niblack and Sauvola thresholds are local thresholding techniques that are useful for images where the background is not uniform, especially for text recognition [1]_, [2]_. Instead of calculating a single global threshold for the entire image, several thresholds are calculated for every pixel by using specific formulae that take into account the mean and standard deviation of the local neighborhood (defined by a window centered around the pixel)."><img alt="" src="../_images/sphx_glr_plot_niblack_sauvola_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_niblack_sauvola.html#sphx-glr-auto-examples-segmentation-plot-niblack-sauvola-py"><span class="std std-ref">Niblack and Sauvola Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Niblack and Sauvola Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to segment an image with image labelling. The following steps are applied:"><img alt="" src="../_images/sphx_glr_plot_label_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_label.html#sphx-glr-auto-examples-segmentation-plot-label-py"><span class="std std-ref">Label image regions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Label image regions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to measure properties of labelled image regions. We first analyze an image with two ellipses. Below we show how to explore interactively the properties of labelled objects."><img alt="" src="../_images/sphx_glr_plot_regionprops_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_regionprops.html#sphx-glr-auto-examples-segmentation-plot-regionprops-py"><span class="std std-ref">Measure region properties</span></a></p>
  <div class="sphx-glr-thumbnail-title">Measure region properties</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate the use of different metrics to assess the colocalization of two different image channels."><img alt="" src="../_images/sphx_glr_plot_colocalization_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_colocalization_metrics.html#sphx-glr-auto-examples-applications-plot-colocalization-metrics-py"><span class="std std-ref">Colocalization metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Colocalization metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example reproduces a well-established workflow in bioimage data analysis for measuring the fluorescence intensity localized to the nuclear envelope, in a time sequence of cell images (each with two channels and two spatial dimensions) which shows a process of protein re-localization from the cytoplasmic area to the nuclear envelope. This biological application was first presented by Andrea Boni and collaborators in [1]_; it was used in a textbook by Kota Miura [2]_ as well as in other works ([3]_, [4]_). In other words, we port this workflow from ImageJ Macro to Python with scikit-image."><img alt="" src="../_images/sphx_glr_plot_fluorescence_nuclear_envelope_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_fluorescence_nuclear_envelope.html#sphx-glr-auto-examples-applications-plot-fluorescence-nuclear-envelope-py"><span class="std std-ref">Measure fluorescence intensity at the nuclear envelope</span></a></p>
  <div class="sphx-glr-thumbnail-title">Measure fluorescence intensity at the nuclear envelope</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Rank filters are non-linear filters using local gray-level ordering to compute the filtered value. This ensemble of filters share a common base: the local gray-level histogram is computed on the neighborhood of a pixel (defined by a 2D structuring element). If the filtered value is taken as the middle value of the histogram, we get the classical median filter."><img alt="" src="../_images/sphx_glr_plot_rank_filters_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_rank_filters.html#sphx-glr-auto-examples-applications-plot-rank-filters-py"><span class="std std-ref">Rank filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Rank filters</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_sauvola">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_sauvola</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L1126-L1183"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_sauvola" title="Link to this definition">#</a></dt>
<dd><p>Applies Sauvola local threshold to an array. Sauvola is a
modification of Niblack technique.</p>
<p>In the original method a threshold T is calculated for every pixel
in the image using the following formula:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="p">((</span><span class="n">s</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">R</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>where m(x,y) and s(x,y) are the mean and standard deviation of
pixel (x,y) neighborhood defined by a rectangular window with size w
times w centered around the pixel. k is a configurable parameter
that weights the effect of standard deviation.
R is the maximum standard deviation of a grayscale image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>window_size</strong><span class="classifier">int, or iterable of int, optional</span></dt><dd><p>Window size specified as a single odd integer (3, 5, 7, …),
or an iterable of length <code class="docutils literal notranslate"><span class="pre">image.ndim</span></code> containing only odd
integers (e.g. <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">5,</span> <span class="pre">5)</span></code>).</p>
</dd>
<dt><strong>k</strong><span class="classifier">float, optional</span></dt><dd><p>Value of the positive parameter k.</p>
</dd>
<dt><strong>r</strong><span class="classifier">float, optional</span></dt><dd><p>Value of R, the dynamic range of standard deviation.
If None, set to the half of the image dtype range.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Threshold mask. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This algorithm is originally designed for text recognition.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rea1071b48c0e-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>J. Sauvola and M. Pietikainen, “Adaptive document image
binarization,” Pattern Recognition 33(2),
pp. 225-236, 2000.
<a class="reference external" href="https://doi.org/10.1016/S0031-3203(99)00055-2">DOI:10.1016/S0031-3203(99)00055-2</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">page</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t_sauvola</span> <span class="o">=</span> <span class="n">threshold_sauvola</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary_image</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">t_sauvola</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Niblack and Sauvola thresholds are local thresholding techniques that are useful for images where the background is not uniform, especially for text recognition [1]_, [2]_. Instead of calculating a single global threshold for the entire image, several thresholds are calculated for every pixel by using specific formulae that take into account the mean and standard deviation of the local neighborhood (defined by a window centered around the pixel)."><img alt="" src="../_images/sphx_glr_plot_niblack_sauvola_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_niblack_sauvola.html#sphx-glr-auto-examples-segmentation-plot-niblack-sauvola-py"><span class="std std-ref">Niblack and Sauvola Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Niblack and Sauvola Thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_triangle">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_triangle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L917-L995"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_triangle" title="Link to this definition">#</a></dt>
<dd><p>Return threshold value based on the triangle algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>nbins</strong><span class="classifier">int, optional</span></dt><dd><p>Number of bins used to calculate histogram. This value is ignored for
integer arrays.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Upper threshold value. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rb6780315cbfc-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Zack, G. W., Rogers, W. E. and Latt, S. A., 1977,
Automatic Measurement of Sister Chromatid Exchange Frequency,
Journal of Histochemistry and Cytochemistry 25 (7), pp. 741-753
<a class="reference external" href="https://doi.org/10.1177/25.7.70454">DOI:10.1177/25.7.70454</a></p>
</div>
<div class="citation" id="rb6780315cbfc-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>ImageJ AutoThresholder code,
<a class="reference external" href="http://fiji.sc/wiki/index.php/Auto_Threshold">http://fiji.sc/wiki/index.php/Auto_Threshold</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_triangle</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&gt;</span> <span class="n">thresh</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.threshold_yen">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">threshold_yen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nbins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L410-L467"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.threshold_yen" title="Link to this definition">#</a></dt>
<dd><p>Return threshold value based on Yen’s method.
Either image or hist must be provided. In case hist is given, the actual
histogram of the image is ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N[, …]) ndarray</span></dt><dd><p>Grayscale input image.</p>
</dd>
<dt><strong>nbins</strong><span class="classifier">int, optional</span></dt><dd><p>Number of bins used to calculate histogram. This value is ignored for
integer arrays.</p>
</dd>
<dt><strong>hist</strong><span class="classifier">array, or 2-tuple of arrays, optional</span></dt><dd><p>Histogram from which to determine the threshold, and optionally a
corresponding array of bin center intensities.
An alternative use of this function is to pass it only hist.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>threshold</strong><span class="classifier">float</span></dt><dd><p>Upper threshold value. All pixels with an intensity higher than
this value are assumed to be foreground.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rc5144ffaa46d-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Yen J.C., Chang F.J., and Chang S. (1995) “A New Criterion
for Automatic Multilevel Thresholding” IEEE Trans. on Image
Processing, 4(3): 370-378. <a class="reference external" href="https://doi.org/10.1109/83.366472">DOI:10.1109/83.366472</a></p>
</div>
<div class="citation" id="rc5144ffaa46d-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Sezgin M. and Sankur B. (2004) “Survey over Image Thresholding
Techniques and Quantitative Performance Evaluation” Journal of
Electronic Imaging, 13(1): 146-165, <a class="reference external" href="https://doi.org/10.1117/1.1631315">DOI:10.1117/1.1631315</a>
<a class="reference external" href="http://www.busim.ee.boun.edu.tr/~sankur/SankurFolder/Threshold_survey.pdf">http://www.busim.ee.boun.edu.tr/~sankur/SankurFolder/Threshold_survey.pdf</a></p>
</div>
<div class="citation" id="rc5144ffaa46d-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>ImageJ AutoThresholder code, <a class="reference external" href="http://fiji.sc/wiki/index.php/Auto_Threshold">http://fiji.sc/wiki/index.php/Auto_Threshold</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">camera</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">camera</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresh</span> <span class="o">=</span> <span class="n">threshold_yen</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary</span> <span class="o">=</span> <span class="n">image</span> <span class="o">&lt;=</span> <span class="n">thresh</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.try_all_threshold">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">try_all_threshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(8,</span> <span class="pre">5)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/thresholding.py#L108-L174"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.try_all_threshold" title="Link to this definition">#</a></dt>
<dd><p>Returns a figure comparing the outputs of different thresholding methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>figsize</strong><span class="classifier">tuple, optional</span></dt><dd><p>Figure size (in inches).</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, optional</span></dt><dd><p>Print function name for each method.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>fig, ax</strong><span class="classifier">tuple</span></dt><dd><p>Matplotlib figure and axes.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The following algorithms are used:</p>
<ul class="simple">
<li><p>isodata</p></li>
<li><p>li</p></li>
<li><p>mean</p></li>
<li><p>minimum</p></li>
<li><p>otsu</p></li>
<li><p>triangle</p></li>
<li><p>yen</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.data</span> <span class="kn">import</span> <span class="n">text</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">try_all_threshold</span><span class="p">(</span><span class="n">text</span><span class="p">(),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_."><img alt="" src="../_images/sphx_glr_plot_thresholding_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_thresholding.html#sphx-glr-auto-examples-segmentation-plot-thresholding-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.unsharp_mask">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">unsharp_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amount</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_unsharp_mask.py#L19-L141"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.unsharp_mask" title="Link to this definition">#</a></dt>
<dd><p>Unsharp masking filter.</p>
<p>The sharp details are identified as the difference between the original
image and its blurred version. These details are then scaled, and added
back to the original image.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>image</strong><span class="classifier">(M[, …][, C]) ndarray</span></dt><dd><p>Input image.</p>
</dd>
<dt><strong>radius</strong><span class="classifier">scalar or sequence of scalars, optional</span></dt><dd><p>If a scalar is given, then its value is used for all dimensions.
If sequence is given, then there must be exactly one radius
for each dimension except the last dimension for multichannel images.
Note that 0 radius means no blurring, and negative values are
not allowed.</p>
</dd>
<dt><strong>amount</strong><span class="classifier">scalar, optional</span></dt><dd><p>The details will be amplified with this factor. The factor could be 0
or negative. Typically, it is a small positive number, e.g. 1.0.</p>
</dd>
<dt><strong>preserve_range</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to keep the original range of values. Otherwise, the input
image is converted according to the conventions of <code class="docutils literal notranslate"><span class="pre">img_as_float</span></code>.
Also see <a class="reference external" href="https://scikit-image.org/docs/dev/user_guide/data_types.html">https://scikit-image.org/docs/dev/user_guide/data_types.html</a></p>
</dd>
<dt><strong>channel_axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If None, the image is assumed to be a grayscale (single channel) image.
Otherwise, this parameter indicates which axis of the array corresponds
to channels.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.19: </span><code class="docutils literal notranslate"><span class="pre">channel_axis</span></code> was added in 0.19.</p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">(M[, …][, C]) ndarray of float</span></dt><dd><p>Image with unsharp mask applied.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Unsharp masking is an image sharpening technique. It is a linear image
operation, and numerically stable, unlike deconvolution which is an
ill-posed problem. Because of this stability, it is often
preferred over deconvolution.</p>
<p>The main idea is as follows: sharp details are identified as the
difference between the original image and its blurred version.
These details are added back to the original image after a scaling step:</p>
<blockquote>
<div><p>enhanced image = original + amount * (original - blurred)</p>
</div></blockquote>
<p>When applying this filter to several color layers independently,
color bleeding may occur. More visually pleasing result can be
achieved by processing only the brightness/lightness/intensity
channel in a suitable color space such as HSV, HSL, YUV, or YCbCr.</p>
<p>Unsharp masking is described in most introductory digital image
processing books. This implementation is based on <a class="reference internal" href="#re30cac9066b6-1" id="id65">[1]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="re30cac9066b6-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id65">1</a><span class="fn-bracket">]</span></span>
<p>Maria Petrou, Costas Petrou
“Image Processing: The Fundamentals”, (2010), ed ii., page 357,
ISBN 13: 9781119994398  <a class="reference external" href="https://doi.org/10.1002/9781119994398">DOI:10.1002/9781119994398</a></p>
</div>
<div class="citation" id="re30cac9066b6-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Wikipedia. Unsharp masking
<a class="reference external" href="https://en.wikipedia.org/wiki/Unsharp_masking">https://en.wikipedia.org/wiki/Unsharp_masking</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">array</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">120</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">array</span>
<span class="go">array([[100, 100, 100, 100, 100],</span>
<span class="go">       [100, 100, 100, 100, 100],</span>
<span class="go">       [100, 100, 120, 100, 100],</span>
<span class="go">       [100, 100, 100, 100, 100],</span>
<span class="go">       [100, 100, 100, 100, 100]], dtype=uint8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">unsharp_mask</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.39, 0.39, 0.39, 0.39, 0.39],</span>
<span class="go">       [0.39, 0.39, 0.38, 0.39, 0.39],</span>
<span class="go">       [0.39, 0.38, 0.53, 0.38, 0.39],</span>
<span class="go">       [0.39, 0.39, 0.38, 0.39, 0.39],</span>
<span class="go">       [0.39, 0.39, 0.39, 0.39, 0.39]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">array</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">127</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">unsharp_mask</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.79, 0.79, 0.79, 0.79, 0.79],</span>
<span class="go">       [0.79, 0.78, 0.75, 0.78, 0.79],</span>
<span class="go">       [0.79, 0.75, 1.  , 0.75, 0.79],</span>
<span class="go">       [0.79, 0.78, 0.75, 0.78, 0.79],</span>
<span class="go">       [0.79, 0.79, 0.79, 0.79, 0.79]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">unsharp_mask</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">preserve_range</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[100.  , 100.  ,  99.99, 100.  , 100.  ],</span>
<span class="go">       [100.  ,  99.39,  95.48,  99.39, 100.  ],</span>
<span class="go">       [ 99.99,  95.48, 147.59,  95.48,  99.99],</span>
<span class="go">       [100.  ,  99.39,  95.48,  99.39, 100.  ],</span>
<span class="go">       [100.  , 100.  ,  99.99, 100.  , 100.  ]])</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Unsharp masking is a linear image processing technique which sharpens the image. The sharp details are identified as a difference between the original image and its blurred version. These details are then scaled, and added back to the original image:"><img alt="" src="../_images/sphx_glr_plot_unsharp_mask_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_unsharp_mask.html#sphx-glr-auto-examples-filters-plot-unsharp-mask-py"><span class="std std-ref">Unsharp masking</span></a></p>
  <div class="sphx-glr-thumbnail-title">Unsharp masking</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.wiener">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">wiener</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">impulse_response</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predefined_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/lpi_filter.py#L218-L261"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.wiener" title="Link to this definition">#</a></dt>
<dd><p>Minimum Mean Square Error (Wiener) inverse filter.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>data</strong><span class="classifier">(M, N) ndarray</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>K</strong><span class="classifier">float or (M, N) ndarray</span></dt><dd><p>Ratio between power spectrum of noise and undegraded
image.</p>
</dd>
<dt><strong>impulse_response</strong><span class="classifier">callable <code class="xref py py-obj docutils literal notranslate"><span class="pre">f(r,</span> <span class="pre">c,</span> <span class="pre">**filter_params)</span></code></span></dt><dd><p>Impulse response of the filter.  See LPIFilter2D.__init__.</p>
</dd>
<dt><strong>filter_params</strong><span class="classifier">dict, optional</span></dt><dd><p>Additional keyword parameters to the impulse_response function.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Other Parameters<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>predefined_filter</strong><span class="classifier">LPIFilter2D</span></dt><dd><p>If you need to apply the same filter multiple times over different
images, construct the LPIFilter2D and specify it here.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.filters.window">
<span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">window</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">window_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warp_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/_window.py#L10-L131"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.window" title="Link to this definition">#</a></dt>
<dd><p>Return an n-dimensional window of a given size and dimensionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>window_type</strong><span class="classifier">string, float, or tuple</span></dt><dd><p>The type of window to be created. Any window type supported by
<code class="docutils literal notranslate"><span class="pre">scipy.signal.get_window</span></code> is allowed here. See notes below for a
current list, or the SciPy documentation for the version of SciPy
on your machine.</p>
</dd>
<dt><strong>shape</strong><span class="classifier">tuple of int or int</span></dt><dd><p>The shape of the window along each axis. If an integer is provided,
a 1D window is generated.</p>
</dd>
<dt><strong>warp_kwargs</strong><span class="classifier">dict</span></dt><dd><p>Keyword arguments passed to <a class="reference internal" href="skimage.transform.html#skimage.transform.warp" title="skimage.transform.warp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.transform.warp</span></code></a> (e.g.,
<code class="docutils literal notranslate"><span class="pre">warp_kwargs={'order':3}</span></code> to change interpolation method).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>nd_window</strong><span class="classifier">ndarray</span></dt><dd><p>A window of the specified <code class="docutils literal notranslate"><span class="pre">shape</span></code>. <code class="docutils literal notranslate"><span class="pre">dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">np.float64</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function is based on <code class="docutils literal notranslate"><span class="pre">scipy.signal.get_window</span></code> and thus can access
all of the window types available to that function
(e.g., <code class="docutils literal notranslate"><span class="pre">&quot;hann&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;boxcar&quot;</span></code>). Note that certain window types require
parameters that have to be supplied with the window name as a tuple
(e.g., <code class="docutils literal notranslate"><span class="pre">(&quot;tukey&quot;,</span> <span class="pre">0.8)</span></code>). If only a float is supplied, it is interpreted
as the beta parameter of the Kaiser window.</p>
<p>See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.get_window.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.get_window.html</a>
for more details.</p>
<p>Note that this function generates a double precision array of the specified
<code class="docutils literal notranslate"><span class="pre">shape</span></code> and can thus generate very large arrays that consume a large
amount of available memory.</p>
<p>The approach taken here to create nD windows is to first calculate the
Euclidean distance from the center of the intended nD window to each
position in the array. That distance is used to sample, with
interpolation, from a 1D window returned from <code class="docutils literal notranslate"><span class="pre">scipy.signal.get_window</span></code>.
The method of interpolation can be changed with the <code class="docutils literal notranslate"><span class="pre">order</span></code> keyword
argument passed to <a class="reference internal" href="skimage.transform.html#skimage.transform.warp" title="skimage.transform.warp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.transform.warp</span></code></a>.</p>
<p>Some coordinates in the output window will be outside of the original
signal; these will be filled in with zeros.</p>
<p>Window types:
- boxcar
- triang
- blackman
- hamming
- hann
- bartlett
- flattop
- parzen
- bohman
- blackmanharris
- nuttall
- barthann
- kaiser (needs beta)
- gaussian (needs standard deviation)
- general_gaussian (needs power, width)
- slepian (needs width)
- dpss (needs normalized half-bandwidth)
- chebwin (needs attenuation)
- exponential (needs decay scale)
- tukey (needs taper fraction)</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="ra5de09d562a4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Two-dimensional window design, Wikipedia,
<a class="reference external" href="https://en.wikipedia.org/wiki/Two_dimensional_window_design">https://en.wikipedia.org/wiki/Two_dimensional_window_design</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Return a Hann window with shape (512, 512):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">window</span><span class="p">(</span><span class="s1">&#39;hann&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
</pre></div>
</div>
<p>Return a Kaiser window with beta parameter of 16 and shape (256, 256, 35):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">window</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">35</span><span class="p">))</span>
</pre></div>
</div>
<p>Return a Tukey window with an alpha parameter of 0.8 and shape (100, 300):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">window</span><span class="p">((</span><span class="s1">&#39;tukey&#39;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">300</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Phase correlation (``registration.phase_cross_correlation``) is an efficient method for determining translation offset between pairs of similar images. However this approach relies on a near absence of rotation/scaling differences between the images, which are typical in real-world examples."><img alt="" src="../_images/sphx_glr_plot_register_rotation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_register_rotation.html#sphx-glr-auto-examples-registration-plot-register-rotation-py"><span class="std std-ref">Using Polar and Log-Polar Transformations for Registration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using Polar and Log-Polar Transformations for Registration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Fast Fourier transforms (FFTs) assume that the data being transformed represent one period of a periodic signal. Thus the endpoints of the signal to be transformed can behave as discontinuities in the context of the FFT. These discontinuities distort the output of the FFT, resulting in energy from &quot;real&quot; frequency components leaking into wider frequencies."><img alt="" src="../_images/sphx_glr_plot_window_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_window.html#sphx-glr-auto-examples-filters-plot-window-py"><span class="std std-ref">Using window functions with images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using window functions with images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Band-pass filters attenuate signal frequencies outside of a range (band) of interest. In image analysis, they can be used to denoise images while at the same time reducing low-frequency artifacts such a uneven illumination. Band-pass filters can be used to find image features such as blobs and edges."><img alt="" src="../_images/sphx_glr_plot_dog_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_dog.html#sphx-glr-auto-examples-filters-plot-dog-py"><span class="std std-ref">Band-pass filtering by Difference of Gaussians</span></a></p>
  <div class="sphx-glr-thumbnail-title">Band-pass filtering by Difference of Gaussians</div>
</div></div></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="skimage.filters.LPIFilter2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">skimage.filters.</span></span><span class="sig-name descname"><span class="pre">LPIFilter2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">impulse_response</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">filter_params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/lpi_filter.py#L39-L130"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.LPIFilter2D" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Linear Position-Invariant Filter (2-dimensional)</p>
<dl class="py method">
<dt class="sig sig-object py" id="skimage.filters.LPIFilter2D.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">impulse_response</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">filter_params</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/main/skimage/filters/lpi_filter.py#L42-L77"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.filters.LPIFilter2D.__init__" title="Link to this definition">#</a></dt>
<dd><dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>impulse_response</strong><span class="classifier">callable <code class="xref py py-obj docutils literal notranslate"><span class="pre">f(r,</span> <span class="pre">c,</span> <span class="pre">**filter_params)</span></code></span></dt><dd><p>Function that yields the impulse response.  <code class="docutils literal notranslate"><span class="pre">r</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> are
1-dimensional vectors that represent row and column positions, in
other words coordinates are (r[0],c[0]),(r[0],c[1]) etc.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">**filter_params</span></code> are passed through.</p>
<p>In other words, <code class="docutils literal notranslate"><span class="pre">impulse_response</span></code> would be called like this:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">impulse_response</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">filter_params</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filter_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kw1&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;kw2&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;kw3&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">impulse_response</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">filter_params</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Gaussian filter without normalization of coefficients:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">filt_func</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">r</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">c</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">filter</span> <span class="o">=</span> <span class="n">LPIFilter2D</span><span class="p">(</span><span class="n">filt_func</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.apply_hysteresis_threshold"><code class="docutils literal notranslate"><span class="pre">apply_hysteresis_threshold()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.butterworth"><code class="docutils literal notranslate"><span class="pre">butterworth()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.correlate_sparse"><code class="docutils literal notranslate"><span class="pre">correlate_sparse()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.difference_of_gaussians"><code class="docutils literal notranslate"><span class="pre">difference_of_gaussians()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.farid"><code class="docutils literal notranslate"><span class="pre">farid()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.farid_h"><code class="docutils literal notranslate"><span class="pre">farid_h()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.farid_v"><code class="docutils literal notranslate"><span class="pre">farid_v()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.filter_forward"><code class="docutils literal notranslate"><span class="pre">filter_forward()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.filter_inverse"><code class="docutils literal notranslate"><span class="pre">filter_inverse()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.frangi"><code class="docutils literal notranslate"><span class="pre">frangi()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.gabor"><code class="docutils literal notranslate"><span class="pre">gabor()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.gabor_kernel"><code class="docutils literal notranslate"><span class="pre">gabor_kernel()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.gaussian"><code class="docutils literal notranslate"><span class="pre">gaussian()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.hessian"><code class="docutils literal notranslate"><span class="pre">hessian()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.laplace"><code class="docutils literal notranslate"><span class="pre">laplace()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.median"><code class="docutils literal notranslate"><span class="pre">median()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.meijering"><code class="docutils literal notranslate"><span class="pre">meijering()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.prewitt"><code class="docutils literal notranslate"><span class="pre">prewitt()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.prewitt_h"><code class="docutils literal notranslate"><span class="pre">prewitt_h()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.prewitt_v"><code class="docutils literal notranslate"><span class="pre">prewitt_v()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.rank_order"><code class="docutils literal notranslate"><span class="pre">rank_order()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.roberts"><code class="docutils literal notranslate"><span class="pre">roberts()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.roberts_neg_diag"><code class="docutils literal notranslate"><span class="pre">roberts_neg_diag()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.roberts_pos_diag"><code class="docutils literal notranslate"><span class="pre">roberts_pos_diag()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.sato"><code class="docutils literal notranslate"><span class="pre">sato()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.scharr"><code class="docutils literal notranslate"><span class="pre">scharr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.scharr_h"><code class="docutils literal notranslate"><span class="pre">scharr_h()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.scharr_v"><code class="docutils literal notranslate"><span class="pre">scharr_v()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.sobel"><code class="docutils literal notranslate"><span class="pre">sobel()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.sobel_h"><code class="docutils literal notranslate"><span class="pre">sobel_h()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.sobel_v"><code class="docutils literal notranslate"><span class="pre">sobel_v()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_isodata"><code class="docutils literal notranslate"><span class="pre">threshold_isodata()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_li"><code class="docutils literal notranslate"><span class="pre">threshold_li()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_local"><code class="docutils literal notranslate"><span class="pre">threshold_local()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_mean"><code class="docutils literal notranslate"><span class="pre">threshold_mean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_minimum"><code class="docutils literal notranslate"><span class="pre">threshold_minimum()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_multiotsu"><code class="docutils literal notranslate"><span class="pre">threshold_multiotsu()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_niblack"><code class="docutils literal notranslate"><span class="pre">threshold_niblack()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_otsu"><code class="docutils literal notranslate"><span class="pre">threshold_otsu()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_sauvola"><code class="docutils literal notranslate"><span class="pre">threshold_sauvola()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_triangle"><code class="docutils literal notranslate"><span class="pre">threshold_triangle()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.threshold_yen"><code class="docutils literal notranslate"><span class="pre">threshold_yen()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.try_all_threshold"><code class="docutils literal notranslate"><span class="pre">try_all_threshold()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.unsharp_mask"><code class="docutils literal notranslate"><span class="pre">unsharp_mask()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.wiener"><code class="docutils literal notranslate"><span class="pre">wiener()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.window"><code class="docutils literal notranslate"><span class="pre">window()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.LPIFilter2D"><code class="docutils literal notranslate"><span class="pre">LPIFilter2D</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.filters.LPIFilter2D.__init__"><code class="docutils literal notranslate"><span class="pre">LPIFilter2D.__init__()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/api/skimage.filters.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2013-2024, the scikit-image team.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.0.2.
    <br/>
  </p>
</div>
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>