
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>skimage.data &#8212; skimage 0.25.0rc0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=4340df76" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=6a2403d7"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-image.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/skimage.data';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-image.org/docs/dev/_static/version_switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.25.0rc0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="skimage.draw" href="skimage.draw.html" />
    <link rel="prev" title="skimage.color" href="skimage.color.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
     
  

<a class="navbar-brand logo" href="https://scikit-image.org">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="scikit-image's logo, showing a snake's head overlayed with green and orange"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="scikit-image's logo, showing a snake's head overlayed with green and orange"/>`);</script>
  
  
    <p class="title logo__title">scikit-image</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="api.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../release_notes/index.html">
    Release notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-image/scikit-image" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-image/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-box fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide/index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="api.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../release_notes/index.html">
    Release notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-image/scikit-image" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-image/" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-box fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="skimage.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.color.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.color</span></code></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.draw.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.draw</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.exposure.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.exposure</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.feature.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.feature</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.filters.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.filters.rank.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.filters.rank</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.future.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.future</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.graph.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.graph</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.io.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.io</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.measure.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.measure</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.metrics.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.metrics</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.morphology.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.morphology</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.registration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.registration</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.restoration.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.restoration</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.segmentation.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.segmentation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.transform.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.transform</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="skimage.util.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.util</span></code></a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="api.html" class="nav-link">API reference</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><code...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-skimage.data">
<span id="skimage-data"></span><h1><a class="reference internal" href="#module-skimage.data" title="skimage.data"><code class="xref py py-mod docutils literal notranslate"><span class="pre">skimage.data</span></code></a><a class="headerlink" href="#module-skimage.data" title="Link to this heading">#</a></h1>
<p>Test images and datasets.</p>
<p>A curated set of general purpose and scientific images used in tests, examples,
and documentation.</p>
<p>Newer datasets are no longer included as part of the package, but are
downloaded on demand. To make data available offline, use <a class="reference internal" href="#skimage.data.download_all" title="skimage.data.download_all"><code class="xref py py-func docutils literal notranslate"><span class="pre">download_all()</span></code></a>.</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.astronaut" title="skimage.data.astronaut"><code class="xref py py-obj docutils literal notranslate"><span class="pre">astronaut</span></code></a></p></td>
<td><p>Color image of the astronaut Eileen Collins.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.binary_blobs" title="skimage.data.binary_blobs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">binary_blobs</span></code></a></p></td>
<td><p>Generate synthetic binary image with several rounded blob-like objects.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.brain" title="skimage.data.brain"><code class="xref py py-obj docutils literal notranslate"><span class="pre">brain</span></code></a></p></td>
<td><p>Subset of data from the University of North Carolina Volume Rendering Test Data Set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.brick" title="skimage.data.brick"><code class="xref py py-obj docutils literal notranslate"><span class="pre">brick</span></code></a></p></td>
<td><p>Brick wall.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.camera" title="skimage.data.camera"><code class="xref py py-obj docutils literal notranslate"><span class="pre">camera</span></code></a></p></td>
<td><p>Gray-level &quot;camera&quot; image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.cat" title="skimage.data.cat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cat</span></code></a></p></td>
<td><p>Chelsea the cat.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.cell" title="skimage.data.cell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cell</span></code></a></p></td>
<td><p>Cell floating in saline.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.cells3d" title="skimage.data.cells3d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cells3d</span></code></a></p></td>
<td><p>3D fluorescence microscopy image of cells.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.checkerboard" title="skimage.data.checkerboard"><code class="xref py py-obj docutils literal notranslate"><span class="pre">checkerboard</span></code></a></p></td>
<td><p>Checkerboard image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.chelsea" title="skimage.data.chelsea"><code class="xref py py-obj docutils literal notranslate"><span class="pre">chelsea</span></code></a></p></td>
<td><p>Chelsea the cat.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.clock" title="skimage.data.clock"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clock</span></code></a></p></td>
<td><p>Motion blurred clock.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.coffee" title="skimage.data.coffee"><code class="xref py py-obj docutils literal notranslate"><span class="pre">coffee</span></code></a></p></td>
<td><p>Coffee cup.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.coins" title="skimage.data.coins"><code class="xref py py-obj docutils literal notranslate"><span class="pre">coins</span></code></a></p></td>
<td><p>Greek coins from Pompeii.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.colorwheel" title="skimage.data.colorwheel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">colorwheel</span></code></a></p></td>
<td><p>Color Wheel.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.download_all" title="skimage.data.download_all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">download_all</span></code></a></p></td>
<td><p>Download all datasets for use with scikit-image offline.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.eagle" title="skimage.data.eagle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eagle</span></code></a></p></td>
<td><p>A golden eagle.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.file_hash" title="skimage.data.file_hash"><code class="xref py py-obj docutils literal notranslate"><span class="pre">file_hash</span></code></a></p></td>
<td><p>Calculate the hash of a given file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.grass" title="skimage.data.grass"><code class="xref py py-obj docutils literal notranslate"><span class="pre">grass</span></code></a></p></td>
<td><p>Grass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.gravel" title="skimage.data.gravel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gravel</span></code></a></p></td>
<td><p>Gravel</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.horse" title="skimage.data.horse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">horse</span></code></a></p></td>
<td><p>Black and white silhouette of a horse.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.hubble_deep_field" title="skimage.data.hubble_deep_field"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hubble_deep_field</span></code></a></p></td>
<td><p>Hubble eXtreme Deep Field.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.human_mitosis" title="skimage.data.human_mitosis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">human_mitosis</span></code></a></p></td>
<td><p>Image of human cells undergoing mitosis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.immunohistochemistry" title="skimage.data.immunohistochemistry"><code class="xref py py-obj docutils literal notranslate"><span class="pre">immunohistochemistry</span></code></a></p></td>
<td><p>Immunohistochemical (IHC) staining with hematoxylin counterstaining.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.kidney" title="skimage.data.kidney"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kidney</span></code></a></p></td>
<td><p>Mouse kidney tissue.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.lbp_frontal_face_cascade_filename" title="skimage.data.lbp_frontal_face_cascade_filename"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lbp_frontal_face_cascade_filename</span></code></a></p></td>
<td><p>Return the path to the XML file containing the weak classifier cascade.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.lfw_subset" title="skimage.data.lfw_subset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lfw_subset</span></code></a></p></td>
<td><p>Subset of data from the LFW dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.lily" title="skimage.data.lily"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lily</span></code></a></p></td>
<td><p>Lily of the valley plant stem.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.logo" title="skimage.data.logo"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logo</span></code></a></p></td>
<td><p>Scikit-image logo, a RGBA image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.microaneurysms" title="skimage.data.microaneurysms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">microaneurysms</span></code></a></p></td>
<td><p>Gray-level &quot;microaneurysms&quot; image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.moon" title="skimage.data.moon"><code class="xref py py-obj docutils literal notranslate"><span class="pre">moon</span></code></a></p></td>
<td><p>Surface of the moon.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.nickel_solidification" title="skimage.data.nickel_solidification"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nickel_solidification</span></code></a></p></td>
<td><p>Image sequence of synchrotron x-radiographs showing the rapid solidification of a nickel alloy sample.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.page" title="skimage.data.page"><code class="xref py py-obj docutils literal notranslate"><span class="pre">page</span></code></a></p></td>
<td><p>Scanned page.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.palisades_of_vogt" title="skimage.data.palisades_of_vogt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">palisades_of_vogt</span></code></a></p></td>
<td><p>Return image sequence of in-vivo tissue showing the palisades of Vogt.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.protein_transport" title="skimage.data.protein_transport"><code class="xref py py-obj docutils literal notranslate"><span class="pre">protein_transport</span></code></a></p></td>
<td><p>Microscopy image sequence with fluorescence tagging of proteins re-localizing from the cytoplasmic area to the nuclear envelope.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.retina" title="skimage.data.retina"><code class="xref py py-obj docutils literal notranslate"><span class="pre">retina</span></code></a></p></td>
<td><p>Human retina.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.rocket" title="skimage.data.rocket"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rocket</span></code></a></p></td>
<td><p>Launch photo of DSCOVR on Falcon 9 by SpaceX.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.shepp_logan_phantom" title="skimage.data.shepp_logan_phantom"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shepp_logan_phantom</span></code></a></p></td>
<td><p>Shepp Logan Phantom.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.skin" title="skimage.data.skin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skin</span></code></a></p></td>
<td><p>Microscopy image of dermis and epidermis (skin layers).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.stereo_motorcycle" title="skimage.data.stereo_motorcycle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stereo_motorcycle</span></code></a></p></td>
<td><p>Rectified stereo image pair with ground-truth disparities.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#skimage.data.text" title="skimage.data.text"><code class="xref py py-obj docutils literal notranslate"><span class="pre">text</span></code></a></p></td>
<td><p>Gray-level &quot;text&quot; image used for corner detection.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#skimage.data.vortex" title="skimage.data.vortex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vortex</span></code></a></p></td>
<td><p>Case B1 image pair from the first PIV challenge.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.astronaut">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">astronaut</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L382-L401"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.astronaut" title="Link to this definition">#</a></dt>
<dd><p>Color image of the astronaut Eileen Collins.</p>
<p>Photograph of Eileen Collins, an American astronaut. She was selected
as an astronaut in 1992 and first piloted the space shuttle STS-63 in
1995. She retired in 2006 after spending a total of 38 days, 8 hours
and 10 minutes in outer space.</p>
<p>This image was downloaded from the NASA Great Images database
&lt;<a class="reference external" href="https://flic.kr/p/r9qvLn">https://flic.kr/p/r9qvLn</a>&gt;`__.</p>
<p>No known copyright restrictions, released into the public domain.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>astronaut</strong><span class="classifier">(512, 512, 3) uint8 ndarray</span></dt><dd><p>Astronaut image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the use of view_as_blocks from :pyskimage.util.  Block views can be incredibly useful when one wants to perform local operations on non-overlapping image patches."><img alt="" src="../_images/sphx_glr_plot_view_as_blocks_thumb.png" />
<p><a class="reference internal" href="../auto_examples/numpy_operations/plot_view_as_blocks.html#sphx-glr-auto-examples-numpy-operations-plot-view-as-blocks-py"><span class="std std-ref">Block views on images/arrays</span></a></p>
  <div class="sphx-glr-thumbnail-title">Block views on images/arrays</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example converts an image with RGB channels into an image with a single grayscale channel."><img alt="" src="../_images/sphx_glr_plot_rgb_to_gray_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_rgb_to_gray.html#sphx-glr-auto-examples-color-exposure-plot-rgb-to-gray-py"><span class="std std-ref">RGB to grayscale</span></a></p>
  <div class="sphx-glr-thumbnail-title">RGB to grayscale</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="There are many filters that are designed to work with gray-scale images but not with color images. To simplify the process of creating functions that can adapt to RGB images, scikit-image provides the adapt_rgb decorator."><img alt="" src="../_images/sphx_glr_plot_adapt_rgb_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_adapt_rgb.html#sphx-glr-auto-examples-color-exposure-plot-adapt-rgb-py"><span class="std std-ref">Adapting gray-scale filters to RGB images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Adapting gray-scale filters to RGB images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The active contour model is a method to fit open or closed splines to lines or edges in an image [1]_. It works by minimising an energy that is in part defined by the image and part by the spline&#x27;s shape: length and smoothness. The minimization is done implicitly in the shape energy and explicitly in the image energy."><img alt="" src="../_images/sphx_glr_plot_active_contours_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_active_contours.html#sphx-glr-auto-examples-edges-plot-active-contours-py"><span class="std std-ref">Active Contour Model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Active Contour Model</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Rescale operation resizes an image by a given scaling factor. The scaling factor can either be a single floating point value, or multiple values - one along each axis."><img alt="" src="../_images/sphx_glr_plot_rescale_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_rescale.html#sphx-glr-auto-examples-transform-plot-rescale-py"><span class="std std-ref">Rescale, resize, and downscale</span></a></p>
  <div class="sphx-glr-thumbnail-title">Rescale, resize, and downscale</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The pyramid_gaussian function takes an image and yields successive images shrunk by a constant scale factor. Image pyramids are often used, e.g., to implement algorithms for denoising, texture discrimination, and scale-invariant detection."><img alt="" src="../_images/sphx_glr_plot_pyramid_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_pyramid.html#sphx-glr-auto-examples-transform-plot-pyramid-py"><span class="std std-ref">Build image pyramids</span></a></p>
  <div class="sphx-glr-thumbnail-title">Build image pyramids</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the Piecewise Affine Transformation."><img alt="" src="../_images/sphx_glr_plot_piecewise_affine_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_piecewise_affine.html#sphx-glr-auto-examples-transform-plot-piecewise-affine-py"><span class="std std-ref">Piecewise Affine Transformation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Piecewise Affine Transformation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we deconvolve a noisy version of an image using Wiener and unsupervised Wiener algorithms. These algorithms are based on linear models that can&#x27;t restore sharp edge as much as non-linear methods (like TV restoration) but are much faster."><img alt="" src="../_images/sphx_glr_plot_restoration_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_restoration.html#sphx-glr-auto-examples-filters-plot-restoration-py"><span class="std std-ref">Image Deconvolution</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image Deconvolution</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Fast Fourier transforms (FFTs) assume that the data being transformed represent one period of a periodic signal. Thus the endpoints of the signal to be transformed can behave as discontinuities in the context of the FFT. These discontinuities distort the output of the FFT, resulting in energy from &quot;real&quot; frequency components leaking into wider frequencies."><img alt="" src="../_images/sphx_glr_plot_window_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_window.html#sphx-glr-auto-examples-filters-plot-window-py"><span class="std std-ref">Using window functions with images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using window functions with images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The algorithm is based on a PSF (Point Spread Function), where PSF is described as the impulse response of the optical system. The blurred image is sharpened through a number of iterations, which needs to be hand-tuned."><img alt="" src="../_images/sphx_glr_plot_deconvolution_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_deconvolution.html#sphx-glr-auto-examples-filters-plot-deconvolution-py"><span class="std std-ref">Image Deconvolution</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image Deconvolution</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how the metric implemented in measure.blur_effect behaves, both as a function of the strength of blur and of the size of the re-blurring filter. This no-reference perceptual blur metric is described in [1]_."><img alt="" src="../_images/sphx_glr_plot_blur_effect_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_blur_effect.html#sphx-glr-auto-examples-filters-plot-blur-effect-py"><span class="std std-ref">Estimate strength of blur</span></a></p>
  <div class="sphx-glr-thumbnail-title">Estimate strength of blur</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Inpainting [1]_ is the process of reconstructing lost or deteriorated parts of images and videos."><img alt="" src="../_images/sphx_glr_plot_inpaint_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_inpaint.html#sphx-glr-auto-examples-filters-plot-inpaint-py"><span class="std std-ref">Fill in defects with inpainting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Fill in defects with inpainting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we denoise a detail of the astronaut image using the non-local means filter. The non-local means algorithm replaces the value of a pixel by an average of a selection of other pixels values: small patches centered on the other pixels are compared to the patch centered on the pixel of interest, and the average is performed only for pixels that have patches close to the current patch. As a result, this algorithm can restore well textures, that would be blurred by other denoising algorithm."><img alt="" src="../_images/sphx_glr_plot_nonlocal_means_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_nonlocal_means.html#sphx-glr-auto-examples-filters-plot-nonlocal-means-py"><span class="std std-ref">Non-local means denoising for preserving textures</span></a></p>
  <div class="sphx-glr-thumbnail-title">Non-local means denoising for preserving textures</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Histogram of Oriented Gradient (HOG) feature descriptor is popular for object detection [1]_."><img alt="" src="../_images/sphx_glr_plot_hog_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_hog.html#sphx-glr-auto-examples-features-detection-plot-hog-py"><span class="std std-ref">Histogram of Oriented Gradients</span></a></p>
  <div class="sphx-glr-thumbnail-title">Histogram of Oriented Gradients</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The CENSURE feature detector is a scale-invariant center-surround detector (CENSURE) that claims to outperform other detectors and is capable of real-time implementation."><img alt="" src="../_images/sphx_glr_plot_censure_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_censure.html#sphx-glr-auto-examples-features-detection-plot-censure-py"><span class="std std-ref">CENSURE feature detector</span></a></p>
  <div class="sphx-glr-thumbnail-title">CENSURE feature detector</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the ORB feature detection and binary description algorithm. It uses an oriented FAST detection method and the rotated BRIEF descriptors."><img alt="" src="../_images/sphx_glr_plot_orb_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_orb.html#sphx-glr-auto-examples-features-detection-plot-orb-py"><span class="std std-ref">ORB feature detector and binary descriptor</span></a></p>
  <div class="sphx-glr-thumbnail-title">ORB feature detector and binary descriptor</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="How to build a (bio-plausible) sparse dictionary (or &#x27;codebook&#x27;, or &#x27;filterbank&#x27;) for e.g. image classification without any fancy math and with just standard python scientific libraries?"><img alt="" src="../_images/sphx_glr_plot_gabors_from_astronaut_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_gabors_from_astronaut.html#sphx-glr-auto-examples-features-detection-plot-gabors-from-astronaut-py"><span class="std std-ref">Gabors / Primary Visual Cortex “Simple Cells” from an Image</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gabors / Primary Visual Cortex "Simple Cells" from an Image</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the BRIEF binary description algorithm. The descriptor consists of relatively few bits and can be computed using a set of intensity difference tests. The short binary descriptor results in low memory footprint and very efficient matching based on the Hamming distance metric. BRIEF does not provide rotation-invariance. Scale-invariance can be achieved by detecting and extracting features at different scales."><img alt="" src="../_images/sphx_glr_plot_brief_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_brief.html#sphx-glr-auto-examples-features-detection-plot-brief-py"><span class="std std-ref">BRIEF binary descriptor</span></a></p>
  <div class="sphx-glr-thumbnail-title">BRIEF binary descriptor</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the SIFT feature detection and its description algorithm."><img alt="" src="../_images/sphx_glr_plot_sift_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_sift.html#sphx-glr-auto-examples-features-detection-plot-sift-py"><span class="std std-ref">SIFT feature detector and descriptor extractor</span></a></p>
  <div class="sphx-glr-thumbnail-title">SIFT feature detector and descriptor extractor</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares four popular low-level image segmentation methods.  As it is difficult to obtain good segmentations, and the definition of &quot;good&quot; often depends on the application, these methods are usually used for obtaining an oversegmentation, also known as superpixels. These superpixels then serve as a basis for more sophisticated algorithms such as conditional random fields (CRF)."><img alt="" src="../_images/sphx_glr_plot_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_segmentations.html#sphx-glr-auto-examples-segmentation-plot-segmentations-py"><span class="std std-ref">Comparison of segmentation and superpixel algorithms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of segmentation and superpixel algorithms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their similarity to an initial seed point [1]_. The conceptual analogy is the &#x27;paint bucket&#x27; tool in many graphic editors."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This computer vision example shows how to detect faces on an image using object detection framework based on machine learning."><img alt="" src="../_images/sphx_glr_plot_face_detection_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_face_detection.html#sphx-glr-auto-examples-applications-plot-face-detection-py"><span class="std std-ref">Face detection using a cascade classifier</span></a></p>
  <div class="sphx-glr-thumbnail-title">Face detection using a cascade classifier</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.binary_blobs">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">binary_blobs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">blob_size_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">volume_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_binary_blobs.py#L6-L61"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.binary_blobs" title="Link to this definition">#</a></dt>
<dd><p>Generate synthetic binary image with several rounded blob-like objects.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>length</strong><span class="classifier">int, optional</span></dt><dd><p>Linear size of output image.</p>
</dd>
<dt><strong>blob_size_fraction</strong><span class="classifier">float, optional</span></dt><dd><p>Typical linear size of blob, as a fraction of <code class="docutils literal notranslate"><span class="pre">length</span></code>, should be
smaller than 1.</p>
</dd>
<dt><strong>n_dim</strong><span class="classifier">int, optional</span></dt><dd><p>Number of dimensions of output image.</p>
</dd>
<dt><strong>volume_fraction</strong><span class="classifier">float, default 0.5</span></dt><dd><p>Fraction of image pixels covered by the blobs (where the output is 1).
Should be in [0, 1].</p>
</dd>
<dt><strong>rng</strong><span class="classifier">{<a class="reference external" href="https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.Generator" title="(in NumPy v2.1)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.random.Generator</span></code></a>, int}, optional</span></dt><dd><p>Pseudo-random number generator.
By default, a PCG64 generator is used (see <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng" title="(in NumPy v2.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.random.default_rng()</span></code></a>).
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">rng</span></code> is an int, it is used to seed the generator.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>blobs</strong><span class="classifier">ndarray of bools</span></dt><dd><p>Output binary image</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="o">.</span><span class="n">binary_blobs</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">blob_size_fraction</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>  
<span class="go">array([[ True, False,  True,  True,  True],</span>
<span class="go">       [ True,  True,  True, False,  True],</span>
<span class="go">       [False,  True, False,  True,  True],</span>
<span class="go">       [ True, False, False,  True,  True],</span>
<span class="go">       [ True, False, False, False,  True]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blobs</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">binary_blobs</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">blob_size_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Finer structures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blobs</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">binary_blobs</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">blob_size_fraction</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Blobs cover a smaller volume fraction of the image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blobs</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">binary_blobs</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">volume_fraction</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Skeletonization reduces binary objects to 1 pixel wide representations. This can be useful for feature extraction, and/or representing an object&#x27;s topology."><img alt="" src="../_images/sphx_glr_plot_skeleton_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_skeleton.html#sphx-glr-auto-examples-edges-plot-skeleton-py"><span class="std std-ref">Skeletonize</span></a></p>
  <div class="sphx-glr-thumbnail-title">Skeletonize</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The random walker algorithm [1]_  determines the segmentation of an image from a set of markers labeling several phases (2 or more). An anisotropic diffusion equation is solved with tracers initiated at the markers&#x27; position. The local diffusivity coefficient is greater if neighboring pixels have similar values, so that diffusion is difficult across high gradients. The label of each unknown pixel is attributed to the label of the known marker that has the highest probability to be reached first during this diffusion process."><img alt="" src="../_images/sphx_glr_plot_random_walker_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_random_walker_segmentation.html#sphx-glr-auto-examples-segmentation-plot-random-walker-segmentation-py"><span class="std std-ref">Random walker segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Random walker segmentation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This toy example shows how to compute the size of every labelled region in a series of 10 images. We use 2D images and then 3D images. The blob-like regions are generated synthetically. As the volume fraction (i.e., ratio of pixels or voxels covered by the blobs) increases, the number of blobs (regions) decreases, and the size (area or volume) of a single region can get larger and larger. The area (size) values are available in a pandas-compatible format, which makes for convenient data analysis and visualization."><img alt="" src="../_images/sphx_glr_plot_regionprops_table_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_regionprops_table.html#sphx-glr-auto-examples-segmentation-plot-regionprops-table-py"><span class="std std-ref">Explore and visualize region properties with pandas</span></a></p>
  <div class="sphx-glr-thumbnail-title">Explore and visualize region properties with pandas</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate the use of different metrics to assess the colocalization of two different image channels."><img alt="" src="../_images/sphx_glr_plot_colocalization_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_colocalization_metrics.html#sphx-glr-auto-examples-applications-plot-colocalization-metrics-py"><span class="std std-ref">Colocalization metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Colocalization metrics</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.brain">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">brain</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1204-L1223"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.brain" title="Link to this definition">#</a></dt>
<dd><p>Subset of data from the University of North Carolina Volume Rendering
Test Data Set.</p>
<p>The full dataset is available at <a class="reference internal" href="#r77fa297eebeb-1" id="id1">[1]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">(10, 256, 256) uint16 ndarray</span></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The 3D volume consists of 10 layers from the larger volume.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r77fa297eebeb-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://graphics.stanford.edu/data/voldata/">https://graphics.stanford.edu/data/voldata/</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example enhances an image with low contrast, using a method called local histogram equalization, which spreads out the most frequent intensity values in an image."><img alt="" src="../_images/sphx_glr_plot_local_equalize_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_local_equalize.html#sphx-glr-auto-examples-color-exposure-plot-local-equalize-py"><span class="std std-ref">Local Histogram Equalization</span></a></p>
  <div class="sphx-glr-thumbnail-title">Local Histogram Equalization</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Rank filters are non-linear filters using local gray-level ordering to compute the filtered value. This ensemble of filters share a common base: the local gray-level histogram is computed on the neighborhood of a pixel (defined by a 2D structuring element). If the filtered value is taken as the middle value of the histogram, we get the classical median filter."><img alt="" src="../_images/sphx_glr_plot_rank_filters_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_rank_filters.html#sphx-glr-auto-examples-applications-plot-rank-filters-py"><span class="std std-ref">Rank filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Rank filters</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.brick">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">brick</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L404-L467"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.brick" title="Link to this definition">#</a></dt>
<dd><p>Brick wall.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>brick</strong><span class="classifier">(512, 512) uint8 image</span></dt><dd><p>A small section of a brick wall.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The original image was downloaded from
<a class="reference external" href="https://cc0textures.com/view.php?tex=Bricks25">CC0Textures</a> and licensed
under the Creative Commons CC0 License.</p>
<p>A perspective transform was then applied to the image, prior to
rotating it by 90 degrees, cropping and scaling it to obtain the final
image.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on Gabor filter banks. Frequency and orientation representations of the Gabor filter are similar to those of the human visual system."><img alt="" src="../_images/sphx_glr_plot_gabor_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_gabor.html#sphx-glr-auto-examples-features-detection-plot-gabor-py"><span class="std std-ref">Gabor filter banks for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gabor filter banks for texture classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on LBP (Local Binary Pattern). LBP looks at points surrounding a central point and tests whether the surrounding points are greater than or less than the central point (i.e. gives a binary result)."><img alt="" src="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-local-binary-pattern-py"><span class="std std-ref">Local Binary Pattern for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Local Binary Pattern for texture classification</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.camera">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">camera</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L339-L361"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.camera" title="Link to this definition">#</a></dt>
<dd><p>Gray-level “camera” image.</p>
<p>Can be used for segmentation and denoising examples.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>camera</strong><span class="classifier">(512, 512) uint8 ndarray</span></dt><dd><p>Camera image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>No copyright restrictions. CC0 by the photographer (Lav Varshney).</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.18: </span>This image was replaced due to copyright restrictions. For more
information, please see <a class="reference internal" href="#r2f100140753e-1" id="id3">[1]</a>.</p>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r2f100140753e-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">1</a><span class="fn-bracket">]</span></span>
<p><a class="github reference external" href="https://github.com/scikit-image/scikit-image/issues/3927">scikit-image/scikit-image#3927</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script illustrates how to use basic NumPy operations, such as slicing, masking and fancy indexing, in order to modify the pixel values of an image."><img alt="" src="../_images/sphx_glr_plot_camera_numpy_thumb.png" />
<p><a class="reference internal" href="../auto_examples/numpy_operations/plot_camera_numpy.html#sphx-glr-auto-examples-numpy-operations-plot-camera-numpy-py"><span class="std std-ref">Using simple NumPy operations for manipulating images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using simple NumPy operations for manipulating images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="It can be useful to artificially tint an image with some color, either to highlight particular regions of an image or maybe just to liven up a grayscale image. This example demonstrates image-tinting by scaling RGB values and by adjusting colors in the HSV color-space."><img alt="" src="../_images/sphx_glr_plot_tinting_grayscale_images_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_tinting_grayscale_images.html#sphx-glr-auto-examples-color-exposure-plot-tinting-grayscale-images-py"><span class="std std-ref">Tinting gray-scale images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Tinting gray-scale images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a method to detect straight lines [1]_."><img alt="" src="../_images/sphx_glr_plot_line_hough_transform_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_line_hough_transform.html#sphx-glr-auto-examples-edges-plot-line-hough-transform-py"><span class="std std-ref">Straight line Hough transform</span></a></p>
  <div class="sphx-glr-thumbnail-title">Straight line Hough transform</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Edge operators are used in image processing within edge detection algorithms. They are discrete differentiation operators, computing an approximation of the gradient of the image intensity function."><img alt="" src="../_images/sphx_glr_plot_edge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py"><span class="std std-ref">Edge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Edge operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When comparing images, the mean squared error (MSE)--while simple to implement--is not highly indicative of perceived similarity.  Structural similarity aims to address this shortcoming by taking texture into account [1]_, [2]_."><img alt="" src="../_images/sphx_glr_plot_ssim_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_ssim.html#sphx-glr-auto-examples-transform-plot-ssim-py"><span class="std std-ref">Structural similarity index</span></a></p>
  <div class="sphx-glr-thumbnail-title">Structural similarity index</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we use phase cross-correlation to identify the relative shift between two similar-sized images."><img alt="" src="../_images/sphx_glr_plot_register_translation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_register_translation.html#sphx-glr-auto-examples-registration-plot-register-translation-py"><span class="std std-ref">Image Registration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Image Registration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we use the masked normalized cross-correlation to identify the relative shift between two similar images containing invalid data."><img alt="" src="../_images/sphx_glr_plot_masked_register_translation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_masked_register_translation.html#sphx-glr-auto-examples-registration-plot-masked-register-translation-py"><span class="std std-ref">Masked Normalized Cross-Correlation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Masked Normalized Cross-Correlation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In information theory, information entropy is the log-base-2 of the number of possible outcomes for a message."><img alt="" src="../_images/sphx_glr_plot_entropy_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_entropy.html#sphx-glr-auto-examples-filters-plot-entropy-py"><span class="std std-ref">Entropy</span></a></p>
  <div class="sphx-glr-thumbnail-title">Entropy</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Band-pass filters attenuate signal frequencies outside of a range (band) of interest. In image analysis, they can be used to denoise images while at the same time reducing low-frequency artifacts such a uneven illumination. Band-pass filters can be used to find image features such as blobs and edges."><img alt="" src="../_images/sphx_glr_plot_dog_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_dog.html#sphx-glr-auto-examples-filters-plot-dog-py"><span class="std std-ref">Band-pass filtering by Difference of Gaussians</span></a></p>
  <div class="sphx-glr-thumbnail-title">Band-pass filtering by Difference of Gaussians</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Butterworth filter is implemented in the frequency domain and is designed to have no passband or stopband ripple. It can be used in either a lowpass or highpass variant. The cutoff_frequency_ratio parameter is used to set the cutoff frequency as a fraction of the sampling frequency. Given that the Nyquist frequency is half the sampling frequency, this means that this parameter should be a positive floating point value &lt; 0.5. The order of the filter can be adjusted to control the transition width, with higher values leading to a sharper transition between the passband and stopband."><img alt="" src="../_images/sphx_glr_plot_butterworth_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_butterworth.html#sphx-glr-auto-examples-filters-plot-butterworth-py"><span class="std std-ref">Butterworth Filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Butterworth Filters</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The DAISY local image descriptor is based on gradient orientation histograms similar to the SIFT descriptor. It is formulated in a way that allows for fast dense extraction which is useful for e.g. bag-of-features image representations."><img alt="" src="../_images/sphx_glr_plot_daisy_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_daisy.html#sphx-glr-auto-examples-features-detection-plot-daisy-py"><span class="std std-ref">Dense DAISY feature description</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dense DAISY feature description</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates texture classification using gray level co-occurrence matrices (GLCMs) [1]_. A GLCM is a histogram of co-occurring grayscale values at a given offset over an image."><img alt="" src="../_images/sphx_glr_plot_glcm_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py"><span class="std std-ref">GLCM Texture Features</span></a></p>
  <div class="sphx-glr-thumbnail-title">GLCM Texture Features</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_."><img alt="" src="../_images/sphx_glr_plot_thresholding_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_thresholding.html#sphx-glr-auto-examples-segmentation-plot-thresholding-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Chan-Vese segmentation algorithm is designed to segment objects without clearly defined boundaries. This algorithm is based on level sets that are evolved iteratively to minimize an energy, which is defined by weighted values corresponding to the sum of differences intensity from the average value outside the segmented region, the sum of differences from the average value inside the segmented region, and a term which is dependent on the length of the boundary of the segmented region."><img alt="" src="../_images/sphx_glr_plot_chan_vese_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_chan_vese.html#sphx-glr-auto-examples-segmentation-plot-chan-vese-py"><span class="std std-ref">Chan-Vese Segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Chan-Vese Segmentation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The multi-Otsu threshold [1]_ is a thresholding algorithm that is used to separate the pixels of an input image into several different classes, each one obtained according to the intensity of the gray levels within the image."><img alt="" src="../_images/sphx_glr_plot_multiotsu_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_multiotsu.html#sphx-glr-auto-examples-segmentation-plot-multiotsu-py"><span class="std std-ref">Multi-Otsu Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multi-Otsu Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Morphological Snakes [1]_ are a family of methods for image segmentation. Their behavior is similar to that of active contours (for example, Geodesic Active Contours [2]_ or Active Contours without Edges [3]_). However, Morphological Snakes use morphological operators (such as dilation or erosion) over a binary array instead of solving PDEs over a floating point array, which is the standard approach for active contours. This makes Morphological Snakes faster and numerically more stable than their traditional counterpart."><img alt="" src="../_images/sphx_glr_plot_morphsnakes_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_morphsnakes.html#sphx-glr-auto-examples-segmentation-plot-morphsnakes-py"><span class="std std-ref">Morphological Snakes</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Snakes</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their similarity to an initial seed point [1]_. The conceptual analogy is the &#x27;paint bucket&#x27; tool in many graphic editors."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Rank filters are non-linear filters using local gray-level ordering to compute the filtered value. This ensemble of filters share a common base: the local gray-level histogram is computed on the neighborhood of a pixel (defined by a 2D structuring element). If the filtered value is taken as the middle value of the histogram, we get the classical median filter."><img alt="" src="../_images/sphx_glr_plot_rank_filters_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_rank_filters.html#sphx-glr-auto-examples-applications-plot-rank-filters-py"><span class="std std-ref">Rank filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Rank filters</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In 1993, Li and Lee proposed a new criterion for finding the &quot;optimal&quot; threshold to distinguish between the background and foreground of an image [1]_. They proposed that minimizing the cross-entropy between the foreground and the foreground mean, and the background and the background mean, would give the best threshold in most situations."><img alt="" src="../_images/sphx_glr_plot_threshold_li_thumb.png" />
<p><a class="reference internal" href="../auto_examples/developers/plot_threshold_li.html#sphx-glr-auto-examples-developers-plot-threshold-li-py"><span class="std std-ref">Li thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Li thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.cat">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">cat</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L890-L905"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.cat" title="Link to this definition">#</a></dt>
<dd><p>Chelsea the cat.</p>
<p>An example with texture, prominent edges in horizontal and diagonal
directions, as well as features of differing scales.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>chelsea</strong><span class="classifier">(300, 451, 3) uint8 ndarray</span></dt><dd><p>Chelsea image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>No copyright restrictions.  CC0 by the photographer (Stefan van der Walt).</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Scikit-image currently doesn&#x27;t feature a function that allows you to write text onto an image. However, there is a fairly easy workaround using scikit-image&#x27;s optional dependency matplotlib."><img alt="" src="../_images/sphx_glr_plot_text_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_text.html#sphx-glr-auto-examples-applications-plot-text-py"><span class="std std-ref">Render text onto an image</span></a></p>
  <div class="sphx-glr-thumbnail-title">Render text onto an image</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.cell">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">cell</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L665-L693"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.cell" title="Link to this definition">#</a></dt>
<dd><p>Cell floating in saline.</p>
<p>This is a quantitative phase image retrieved from a digital hologram using
the Python library <code class="docutils literal notranslate"><span class="pre">qpformat</span></code>. The image shows a cell with high phase
value, above the background phase.</p>
<p>Because of a banding pattern artifact in the background, this image is a
good test of thresholding algorithms. The pixel spacing is 0.107 µm.</p>
<p>These data were part of a comparison between several refractive index
retrieval techniques for spherical objects as part of <a class="reference internal" href="#r02365d02e4e0-1" id="id5">[1]</a>.</p>
<p>This image is CC0, dedicated to the public domain. You may copy, modify, or
distribute it without asking permission.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cell</strong><span class="classifier">(660, 550) uint8 array</span></dt><dd><p>Image of a cell.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r02365d02e4e0-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">1</a><span class="fn-bracket">]</span></span>
<p>Paul Müller, Mirjam Schürmann, Salvatore Girardo, Gheorghe Cojoc,
and Jochen Guck. “Accurate evaluation of size and refractive index
for spherical objects in quantitative phase imaging.” Optics Express
26(8): 10729-10743 (2018). <a class="reference external" href="https://doi.org/10.1364/OE.26.010729">DOI:10.1364/OE.26.010729</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In 1993, Li and Lee proposed a new criterion for finding the &quot;optimal&quot; threshold to distinguish between the background and foreground of an image [1]_. They proposed that minimizing the cross-entropy between the foreground and the foreground mean, and the background and the background mean, would give the best threshold in most situations."><img alt="" src="../_images/sphx_glr_plot_threshold_li_thumb.png" />
<p><a class="reference internal" href="../auto_examples/developers/plot_threshold_li.html#sphx-glr-auto-examples-developers-plot-threshold-li-py"><span class="std std-ref">Li thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Li thresholding</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.cells3d">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">cells3d</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L607-L633"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.cells3d" title="Link to this definition">#</a></dt>
<dd><p>3D fluorescence microscopy image of cells.</p>
<p>The returned data is a 3D multichannel array with dimensions provided in
<code class="docutils literal notranslate"><span class="pre">(z,</span> <span class="pre">c,</span> <span class="pre">y,</span> <span class="pre">x)</span></code> order. Each voxel has a size of <code class="docutils literal notranslate"><span class="pre">(0.29</span> <span class="pre">0.26</span> <span class="pre">0.26)</span></code>
micrometer. Channel 0 contains cell membranes, channel 1 contains nuclei.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>cells3d: (60, 2, 256, 256) uint16 ndarray</dt><dd><p>The volumetric images of cells taken with an optical microscope.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The data for this was provided by the Allen Institute for Cell Science.</p>
<p>It has been downsampled by a factor of 4 in the row and column dimensions
to reduce computational time.</p>
<p>The microscope reports the following voxel spacing in microns:</p>
<blockquote>
<div><ul class="simple">
<li><p>Original voxel size is <code class="docutils literal notranslate"><span class="pre">(0.290,</span> <span class="pre">0.065,</span> <span class="pre">0.065)</span></code>.</p></li>
<li><p>Scaling factor is <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">4,</span> <span class="pre">4)</span></code> in each dimension.</p></li>
<li><p>After rescaling the voxel size is <code class="docutils literal notranslate"><span class="pre">(0.29</span> <span class="pre">0.26</span> <span class="pre">0.26)</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Most scikit-image functions are compatible with 3D datasets, i.e., images with 3 spatial dimensions (to be distinguished from 2D multichannel images, which are also arrays with three axes). skimage.data.cells3d returns a 3D fluorescence microscopy image of cells. The returned dataset is a 3D multichannel image with dimensions provided in (z, c, y, x) order. Channel 0 contains cell membranes, while channel 1 contains nuclei."><img alt="" src="../_images/sphx_glr_plot_3d_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_3d.html#sphx-glr-auto-examples-data-plot-3d-py"><span class="std std-ref">Datasets with 3 or more spatial dimensions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Datasets with 3 or more spatial dimensions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Adaptive histogram equalization (AHE) can be used to improve the local contrast of an image [1]_. Specifically, AHE can be useful for normalizing intensities across images. This example compares the results of applying global histogram equalization and AHE to a 3D image and a synthetically degraded version of it."><img alt="" src="../_images/sphx_glr_plot_adapt_hist_eq_3d_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_adapt_hist_eq_3d.html#sphx-glr-auto-examples-color-exposure-plot-adapt-hist-eq-3d-py"><span class="std std-ref">3D adaptive histogram equalization</span></a></p>
  <div class="sphx-glr-thumbnail-title">3D adaptive histogram equalization</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The rolling-ball algorithm estimates the background intensity of a grayscale image in case of uneven exposure. It is frequently used in biomedical image processing and was first proposed by Stanley R. Sternberg in 1983 [1]_."><img alt="" src="../_images/sphx_glr_plot_rolling_ball_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rolling_ball.html#sphx-glr-auto-examples-segmentation-plot-rolling-ball-py"><span class="std std-ref">Use rolling-ball algorithm for estimating background intensity</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use rolling-ball algorithm for estimating background intensity</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial is an introduction to three-dimensional image processing. For a quick intro to 3D datasets, please refer to sphx_glr_auto_examples_data_plot_3d.py. Images are represented as numpy arrays. A single-channel, or grayscale, image is a 2D matrix of pixel intensities of shape (n_row, n_col), where n_row (resp. n_col) denotes the number of rows (resp. columns). We can construct a 3D volume as a series of 2D planes, giving 3D images the shape (n_plane, n_row, n_col), where n_plane is the number of planes. A multichannel, or RGB(A), image has an additional channel dimension in the final position containing color information."><img alt="" src="../_images/sphx_glr_plot_3d_image_processing_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_3d_image_processing.html#sphx-glr-auto-examples-applications-plot-3d-image-processing-py"><span class="std std-ref">Explore 3D images (of cells)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Explore 3D images (of cells)</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.checkerboard">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">checkerboard</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L592-L604"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.checkerboard" title="Link to this definition">#</a></dt>
<dd><p>Checkerboard image.</p>
<p>Checkerboards are often used in image calibration, since the
corner-points are easy to locate.  Because of the many parallel
edges, they also visualise distortions particularly well.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>checkerboard</strong><span class="classifier">(200, 200) uint8 ndarray</span></dt><dd><p>Checkerboard image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Image swirling is a non-linear image deformation that creates a whirlpool effect.  This example describes the implementation of this transform in skimage, as well as the underlying warp mechanism."><img alt="" src="../_images/sphx_glr_plot_swirl_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_swirl.html#sphx-glr-auto-examples-transform-plot-swirl-py"><span class="std std-ref">Swirl</span></a></p>
  <div class="sphx-glr-thumbnail-title">Swirl</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="To warp an image, we start with a set of source and target coordinates. The goal is to deform the image such that the source points move to the target locations. Typically, we only know the target positions for a few, select source points. To calculate the target positions for all other pixel positions, we need a model. Various such models exist, such as affine or projective transformations."><img alt="" src="../_images/sphx_glr_plot_tps_deformation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_tps_deformation.html#sphx-glr-auto-examples-transform-plot-tps-deformation-py"><span class="std std-ref">Use thin-plate splines for image warping</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use thin-plate splines for image warping</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this simplified example we first generate two synthetic images as if they were taken from different view points."><img alt="" src="../_images/sphx_glr_plot_matching_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_matching.html#sphx-glr-auto-examples-transform-plot-matching-py"><span class="std std-ref">Robust matching using RANSAC</span></a></p>
  <div class="sphx-glr-thumbnail-title">Robust matching using RANSAC</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Detect corner points using the Harris corner detector and determine the subpixel position of corners ([1]_, [2]_)."><img alt="" src="../_images/sphx_glr_plot_corner_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_corner.html#sphx-glr-auto-examples-features-detection-plot-corner-py"><span class="std std-ref">Corner detection</span></a></p>
  <div class="sphx-glr-thumbnail-title">Corner detection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their similarity to an initial seed point [1]_. The conceptual analogy is the &#x27;paint bucket&#x27; tool in many graphic editors."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.chelsea">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">chelsea</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L890-L905"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.chelsea" title="Link to this definition">#</a></dt>
<dd><p>Chelsea the cat.</p>
<p>An example with texture, prominent edges in horizontal and diagonal
directions, as well as features of differing scales.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>chelsea</strong><span class="classifier">(300, 451, 3) uint8 ndarray</span></dt><dd><p>Chelsea image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>No copyright restrictions.  CC0 by the photographer (Stefan van der Walt).</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the feature of histogram matching. It manipulates the pixels of an input image so that its histogram matches the histogram of the reference image. If the images have multiple channels, the matching is done independently for each channel, as long as the number of channels is equal in the input image and the reference."><img alt="" src="../_images/sphx_glr_plot_histogram_matching_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_histogram_matching.html#sphx-glr-auto-examples-color-exposure-plot-histogram-matching-py"><span class="std std-ref">Histogram matching</span></a></p>
  <div class="sphx-glr-thumbnail-title">Histogram matching</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Homographies are transformations of a Euclidean space that preserve the alignment of points. Specific cases of homographies correspond to the conservation of more properties, such as parallelism (affine transformation), shape (similar transformation) or distances (Euclidean transformation)."><img alt="" src="../_images/sphx_glr_plot_transform_types_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_transform_types.html#sphx-glr-auto-examples-transform-plot-transform-types-py"><span class="std std-ref">Types of homographies</span></a></p>
  <div class="sphx-glr-thumbnail-title">Types of homographies</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to find an optimally calibrated version of any denoising algorithm."><img alt="" src="../_images/sphx_glr_plot_j_invariant_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_j_invariant.html#sphx-glr-auto-examples-filters-plot-j-invariant-py"><span class="std std-ref">Calibrating Denoisers Using J-Invariance</span></a></p>
  <div class="sphx-glr-thumbnail-title">Calibrating Denoisers Using J-Invariance</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we denoise a noisy version of a picture using the total variation, bilateral, and wavelet denoising filters."><img alt="" src="../_images/sphx_glr_plot_denoise_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_denoise.html#sphx-glr-auto-examples-filters-plot-denoise-py"><span class="std std-ref">Denoising a picture</span></a></p>
  <div class="sphx-glr-thumbnail-title">Denoising a picture</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The discrete wavelet transform is not `shift-invariant`_.  Shift invariance can be achieved through an undecimated wavelet transform (also called stationary wavelet transform), at cost of increased redundancy (i.e. more wavelet coefficients than input image pixels).  An alternative way to approximate shift-invariance in the context of image denoising with the discrete wavelet transform is to use the technique known as &quot;cycle spinning&quot;.  This involves averaging the results of the following 3-step procedure for multiple spatial shifts, n:"><img alt="" src="../_images/sphx_glr_plot_cycle_spinning_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_cycle_spinning.html#sphx-glr-auto-examples-filters-plot-cycle-spinning-py"><span class="std std-ref">Shift-invariant wavelet denoising</span></a></p>
  <div class="sphx-glr-thumbnail-title">Shift-invariant wavelet denoising</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Some signals can only be observed modulo 2*pi, and this can also apply to two- and three dimensional images. In these cases phase unwrapping is needed to recover the underlying, unwrapped signal. In this example we will demonstrate an algorithm [1]_ implemented in skimage at work for such a problem. One-, two- and three dimensional images can all be unwrapped using skimage. Here we will demonstrate phase unwrapping in the two dimensional case."><img alt="" src="../_images/sphx_glr_plot_phase_unwrap_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_phase_unwrap.html#sphx-glr-auto-examples-filters-plot-phase-unwrap-py"><span class="std std-ref">Phase Unwrapping</span></a></p>
  <div class="sphx-glr-thumbnail-title">Phase Unwrapping</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Wavelet denoising relies on the wavelet representation of the image. Gaussian noise tends to be represented by small values in the wavelet domain and can be removed by setting coefficients below a given threshold to zero (hard thresholding) or shrinking all coefficients toward zero by a given amount (soft thresholding)."><img alt="" src="../_images/sphx_glr_plot_denoise_wavelet_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_denoise_wavelet.html#sphx-glr-auto-examples-filters-plot-denoise-wavelet-py"><span class="std std-ref">Wavelet denoising</span></a></p>
  <div class="sphx-glr-thumbnail-title">Wavelet denoising</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to find an optimally calibrated version of any denoising algorithm."><img alt="" src="../_images/sphx_glr_plot_j_invariant_tutorial_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_j_invariant_tutorial.html#sphx-glr-auto-examples-filters-plot-j-invariant-tutorial-py"><span class="std std-ref">Full tutorial on calibrating Denoisers Using J-Invariance</span></a></p>
  <div class="sphx-glr-thumbnail-title">Full tutorial on calibrating Denoisers Using J-Invariance</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Flood fill is an algorithm to identify and/or change adjacent values in an image based on their similarity to an initial seed point [1]_. The conceptual analogy is the &#x27;paint bucket&#x27; tool in many graphic editors."><img alt="" src="../_images/sphx_glr_plot_floodfill_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_floodfill.html#sphx-glr-auto-examples-segmentation-plot-floodfill-py"><span class="std std-ref">Flood Fill</span></a></p>
  <div class="sphx-glr-thumbnail-title">Flood Fill</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.clock">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">clock</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L853-L867"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.clock" title="Link to this definition">#</a></dt>
<dd><p>Motion blurred clock.</p>
<p>This photograph of a wall clock was taken while moving the camera in an
approximately horizontal direction.  It may be used to illustrate
inverse filters and deconvolution.</p>
<p>Released into the public domain by the photographer (Stefan van der Walt).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>clock</strong><span class="classifier">(300, 400) uint8 ndarray</span></dt><dd><p>Clock image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.coffee">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">coffee</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L912-L928"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.coffee" title="Link to this definition">#</a></dt>
<dd><p>Coffee cup.</p>
<p>This photograph is courtesy of Pikolo Espresso Bar.
It contains several elliptical shapes as well as varying texture (smooth
porcelain to coarse wood grain).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>coffee</strong><span class="classifier">(400, 600, 3) uint8 ndarray</span></dt><dd><p>Coffee image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>No copyright restrictions.  CC0 by the photographer (Rachel Michetti).</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how RGB to HSV (Hue, Saturation, Value) conversion [1]_ can be used to facilitate segmentation processes."><img alt="" src="../_images/sphx_glr_plot_rgb_to_hsv_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_rgb_to_hsv.html#sphx-glr-auto-examples-color-exposure-plot-rgb-to-hsv-py"><span class="std std-ref">RGB to HSV</span></a></p>
  <div class="sphx-glr-thumbnail-title">RGB to HSV</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the feature of histogram matching. It manipulates the pixels of an input image so that its histogram matches the histogram of the reference image. If the images have multiple channels, the matching is done independently for each channel, as long as the number of channels is equal in the input image and the reference."><img alt="" src="../_images/sphx_glr_plot_histogram_matching_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_histogram_matching.html#sphx-glr-auto-examples-color-exposure-plot-histogram-matching-py"><span class="std std-ref">Histogram matching</span></a></p>
  <div class="sphx-glr-thumbnail-title">Histogram matching</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a method to detect straight lines but it can also be used to detect circles or ellipses. The algorithm assumes that the edge is detected and it is robust against noise or missing points."><img alt="" src="../_images/sphx_glr_plot_circular_elliptical_hough_transform_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_circular_elliptical_hough_transform.html#sphx-glr-auto-examples-edges-plot-circular-elliptical-hough-transform-py"><span class="std std-ref">Circular and Elliptical Hough Transforms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Circular and Elliptical Hough Transforms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Construct a region boundary RAG with the rag_boundary function. The function  :pyskimage.graph.rag_boundary takes an edge_map argument, which gives the significance of a feature (such as edges) being present at each pixel. In a region boundary RAG, the edge weight between two regions is the average value of the corresponding pixels in edge_map along their shared boundary."><img alt="" src="../_images/sphx_glr_plot_rag_boundary_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_boundary.html#sphx-glr-auto-examples-segmentation-plot-rag-boundary-py"><span class="std std-ref">Region Boundary based Region adjacency graphs (RAGs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region Boundary based Region adjacency graphs (RAGs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and merges regions which are similar in color. We construct a RAG and define edges as the difference in mean color. We then join regions with similar mean color."><img alt="" src="../_images/sphx_glr_plot_rag_mean_color_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_mean_color.html#sphx-glr-auto-examples-segmentation-plot-rag-mean-color-py"><span class="std std-ref">Region adjacency graph (RAG) Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region adjacency graph (RAG) Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and recursively performs a Normalized Cut on it [1]_."><img alt="" src="../_images/sphx_glr_plot_ncut_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_ncut.html#sphx-glr-auto-examples-segmentation-plot-ncut-py"><span class="std std-ref">Normalized Cut</span></a></p>
  <div class="sphx-glr-thumbnail-title">Normalized Cut</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and draws it with the rag_draw method."><img alt="" src="../_images/sphx_glr_plot_rag_draw_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_draw.html#sphx-glr-auto-examples-segmentation-plot-rag-draw-py"><span class="std std-ref">Drawing Region Adjacency Graphs (RAGs)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Drawing Region Adjacency Graphs (RAGs)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a Region Adjacency Graph (RAG) and progressively merges regions that are similar in color. Merging two adjacent regions produces a new region with all the pixels from the merged regions. Regions are merged until no highly similar region pairs remain."><img alt="" src="../_images/sphx_glr_plot_rag_merge_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rag_merge.html#sphx-glr-auto-examples-segmentation-plot-rag-merge-py"><span class="std std-ref">Region adjacency graph (RAG) Merging</span></a></p>
  <div class="sphx-glr-thumbnail-title">Region adjacency graph (RAG) Merging</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to perform hierarchical merging on region boundary Region Adjacency Graphs (RAGs). Region boundary RAGs can be constructed with the :pyskimage.graph.rag_boundary function. The regions with the lowest edge weights are successively merged until there is no edge with weight less than thresh. The hierarchical merging is done through the :pyskimage.graph.merge_hierarchical function. For an example of how to construct region boundary based RAGs, see plot_rag_boundary."><img alt="" src="../_images/sphx_glr_plot_boundary_merge_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_boundary_merge.html#sphx-glr-auto-examples-segmentation-plot-boundary-merge-py"><span class="std std-ref">Hierarchical Merging of Region Boundary RAGs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Hierarchical Merging of Region Boundary RAGs</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.coins">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">coins</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L696-L718"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.coins" title="Link to this definition">#</a></dt>
<dd><p>Greek coins from Pompeii.</p>
<p>This image shows several coins outlined against a gray background.
It is especially useful in, e.g. segmentation tests, where
individual objects need to be identified against a background.
The background shares enough grey levels with the coins that a
simple segmentation is not sufficient.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>coins</strong><span class="classifier">(303, 384) uint8 ndarray</span></dt><dd><p>Coins image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was downloaded from the
<a class="reference external" href="https://www.brooklynmuseum.org/opencollection/archives/image/51611">Brooklyn Museum Collection</a>.</p>
<p>No known copyright restrictions.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Here, we use morphological reconstruction to create a background image, which we can subtract from the original image to isolate bright features (regional maxima)."><img alt="" src="../_images/sphx_glr_plot_regional_maxima_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_regional_maxima.html#sphx-glr-auto-examples-color-exposure-plot-regional-maxima-py"><span class="std std-ref">Filtering regional maxima</span></a></p>
  <div class="sphx-glr-thumbnail-title">Filtering regional maxima</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Hough transform in its simplest form is a method to detect straight lines but it can also be used to detect circles or ellipses. The algorithm assumes that the edge is detected and it is robust against noise or missing points."><img alt="" src="../_images/sphx_glr_plot_circular_elliptical_hough_transform_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_circular_elliptical_hough_transform.html#sphx-glr-auto-examples-edges-plot-circular-elliptical-hough-transform-py"><span class="std std-ref">Circular and Elliptical Hough Transforms</span></a></p>
  <div class="sphx-glr-thumbnail-title">Circular and Elliptical Hough Transforms</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Hysteresis is the lagging of an effect---a kind of inertia. In the context of thresholding, it means that areas above some low threshold are considered to be above the threshold if they are also connected to areas above a higher, more stringent, threshold. They can thus be seen as continuations of these high-confidence areas."><img alt="" src="../_images/sphx_glr_plot_hysteresis_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_hysteresis.html#sphx-glr-auto-examples-filters-plot-hysteresis-py"><span class="std std-ref">Hysteresis thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Hysteresis thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares the following mean filters of the rank filter package:"><img alt="" src="../_images/sphx_glr_plot_rank_mean_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_rank_mean.html#sphx-glr-auto-examples-filters-plot-rank-mean-py"><span class="std std-ref">Mean filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Mean filters</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We use template matching to identify the occurrence of an image patch (in this case, a sub-image centered on a single coin). Here, we return a single match (the exact same coin), so the maximum value in the match_template result corresponds to the coin location. The other coins look similar, and thus have local maxima; if you expect multiple matches, you should use a proper peak-finding function."><img alt="" src="../_images/sphx_glr_plot_template_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_template.html#sphx-glr-auto-examples-features-detection-plot-template-py"><span class="std std-ref">Template Matching</span></a></p>
  <div class="sphx-glr-thumbnail-title">Template Matching</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to compute multi-block local binary pattern (MB-LBP) features as well as how to visualize them."><img alt="" src="../_images/sphx_glr_plot_multiblock_local_binary_pattern_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_multiblock_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-multiblock-local-binary-pattern-py"><span class="std std-ref">Multi-Block Local Binary Pattern for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multi-Block Local Binary Pattern for texture classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Histogram matching can be used for object detection in images [1]_. This example extracts a single coin from the skimage.data.coins image and uses histogram matching to attempt to locate it within the original image."><img alt="" src="../_images/sphx_glr_plot_windowed_histogram_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_windowed_histogram.html#sphx-glr-auto-examples-features-detection-plot-windowed-histogram-py"><span class="std std-ref">Sliding window histogram</span></a></p>
  <div class="sphx-glr-thumbnail-title">Sliding window histogram</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The watershed transform is commonly used as a starting point for many segmentation algorithms. However, without a judicious choice of seeds, it can produce very uneven fragment sizes, which can be difficult to deal with in downstream analyses."><img alt="" src="../_images/sphx_glr_plot_compact_watershed_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_compact_watershed.html#sphx-glr-auto-examples-segmentation-plot-compact-watershed-py"><span class="std std-ref">Find Regular Segments Using Compact Watershed</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find Regular Segments Using Compact Watershed</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The peak_local_max function returns the coordinates of local peaks (maxima) in an image. Internally, a maximum filter is used for finding local maxima. This operation dilates the original image and merges neighboring local maxima closer than the size of the dilation. Locations where the original image is equal to the dilated image are returned as local maxima."><img alt="" src="../_images/sphx_glr_plot_peak_local_max_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_peak_local_max.html#sphx-glr-auto-examples-segmentation-plot-peak-local-max-py"><span class="std std-ref">Finding local maxima</span></a></p>
  <div class="sphx-glr-thumbnail-title">Finding local maxima</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Given several connected components represented by a label image, these connected components can be expanded into background regions using :pyskimage.segmentation.expand_labels. In contrast to :pyskimage.morphology.dilation this method will not let connected components expand into neighboring connected components with lower label number."><img alt="" src="../_images/sphx_glr_plot_expand_labels_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_expand_labels.html#sphx-glr-auto-examples-segmentation-plot-expand-labels-py"><span class="std std-ref">Expand segmentation labels without overlap</span></a></p>
  <div class="sphx-glr-thumbnail-title">Expand segmentation labels without overlap</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to segment an image with image labelling. The following steps are applied:"><img alt="" src="../_images/sphx_glr_plot_label_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_label.html#sphx-glr-auto-examples-segmentation-plot-label-py"><span class="std std-ref">Label image regions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Label image regions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When segmenting an image, you may want to combine multiple alternative segmentations. The :pyskimage.segmentation.join_segmentations function computes the join of two segmentations, in which a pixel is placed in the same segment if and only if it is in the same segment in both segmentations."><img alt="" src="../_images/sphx_glr_plot_join_segmentations_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_join_segmentations.html#sphx-glr-auto-examples-segmentation-plot-join-segmentations-py"><span class="std std-ref">Find the intersection of two segmentations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Find the intersection of two segmentations</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Morphological Snakes [1]_ are a family of methods for image segmentation. Their behavior is similar to that of active contours (for example, Geodesic Active Contours [2]_ or Active Contours without Edges [3]_). However, Morphological Snakes use morphological operators (such as dilation or erosion) over a binary array instead of solving PDEs over a floating point array, which is the standard approach for active contours. This makes Morphological Snakes faster and numerically more stable than their traditional counterpart."><img alt="" src="../_images/sphx_glr_plot_morphsnakes_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_morphsnakes.html#sphx-glr-auto-examples-segmentation-plot-morphsnakes-py"><span class="std std-ref">Morphological Snakes</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Snakes</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to measure properties of labelled image regions. We first analyze an image with two ellipses. Below we show how to explore interactively the properties of labelled objects."><img alt="" src="../_images/sphx_glr_plot_regionprops_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_regionprops.html#sphx-glr-auto-examples-segmentation-plot-regionprops-py"><span class="std std-ref">Measure region properties</span></a></p>
  <div class="sphx-glr-thumbnail-title">Measure region properties</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="When trying out different segmentation methods, how do you know which one is best? If you have a ground truth or gold standard segmentation, you can use various metrics to check how close each automated method comes to the truth. In this example we use an easy-to-segment image as an example of how to interpret various segmentation metrics. We will use the adapted Rand error and the variation of information as example metrics, and see how oversegmentation (splitting of true segments into too many sub-segments) and undersegmentation (merging of different true segments into a single segment) affect the different scores."><img alt="" src="../_images/sphx_glr_plot_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_metrics.html#sphx-glr-auto-examples-segmentation-plot-metrics-py"><span class="std std-ref">Evaluating segmentation metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluating segmentation metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The rolling-ball algorithm estimates the background intensity of a grayscale image in case of uneven exposure. It is frequently used in biomedical image processing and was first proposed by Stanley R. Sternberg in 1983 [1]_."><img alt="" src="../_images/sphx_glr_plot_rolling_ball_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rolling_ball.html#sphx-glr-auto-examples-segmentation-plot-rolling-ball-py"><span class="std std-ref">Use rolling-ball algorithm for estimating background intensity</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use rolling-ball algorithm for estimating background intensity</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Image comparison is particularly useful when performing image processing tasks such as exposure manipulations, filtering, and restoration."><img alt="" src="../_images/sphx_glr_plot_image_comparison_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_image_comparison.html#sphx-glr-auto-examples-applications-plot-image-comparison-py"><span class="std std-ref">Visual image comparison</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visual image comparison</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to segment objects from a background. We use the coins image from skimage.data, which shows several coins outlined against a darker background."><img alt="" src="../_images/sphx_glr_plot_coins_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_coins_segmentation.html#sphx-glr-auto-examples-applications-plot-coins-segmentation-py"><span class="std std-ref">Comparing edge-based and region-based segmentation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing edge-based and region-based segmentation</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.colorwheel">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">colorwheel</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L999-L1007"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.colorwheel" title="Link to this definition">#</a></dt>
<dd><p>Color Wheel.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>colorwheel</strong><span class="classifier">(370, 371, 3) uint8 image</span></dt><dd><p>A colorwheel.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_general_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_general.html#sphx-glr-auto-examples-data-plot-general-py"><span class="std std-ref">General-purpose images</span></a></p>
  <div class="sphx-glr-thumbnail-title">General-purpose images</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.download_all">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">download_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L242-L299"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.download_all" title="Link to this definition">#</a></dt>
<dd><p>Download all datasets for use with scikit-image offline.</p>
<p>Scikit-image datasets are no longer shipped with the library by default.
This allows us to use higher quality datasets, while keeping the
library download size small.</p>
<p>This function requires the installation of an optional dependency, pooch,
to download the full dataset. Follow installation instruction found at</p>
<blockquote>
<div><p><a class="reference external" href="https://scikit-image.org/docs/stable/user_guide/install.html">https://scikit-image.org/docs/stable/user_guide/install.html</a></p>
</div></blockquote>
<p>Call this function to download all sample images making them available
offline on your machine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>directory: path-like, optional</strong></dt><dd><p>The directory where the dataset should be stored.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>ModuleNotFoundError:</dt><dd><p>If pooch is not install, this error will be raised.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>scikit-image will only search for images stored in the default directory.
Only specify the directory if you wish to download the images to your own
folder for a particular reason. You can access the location of the default
data directory by inspecting the variable <code class="docutils literal notranslate"><span class="pre">skimage.data.data_dir</span></code>.</p>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.eagle">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">eagle</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L364-L379"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.eagle" title="Link to this definition">#</a></dt>
<dd><p>A golden eagle.</p>
<p>Suitable for examples on segmentation, Hough transforms, and corner
detection.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>eagle</strong><span class="classifier">(2019, 1826) uint8 ndarray</span></dt><dd><p>Eagle image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>No copyright restrictions. CC0 by the photographer (Dayane Machado).</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The watershed is a classical algorithm used for segmentation, that is, for separating different objects in an image."><img alt="" src="../_images/sphx_glr_plot_marked_watershed_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_marked_watershed.html#sphx-glr-auto-examples-segmentation-plot-marked-watershed-py"><span class="std std-ref">Markers for watershed transform</span></a></p>
  <div class="sphx-glr-thumbnail-title">Markers for watershed transform</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.file_hash">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">file_hash</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fname</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sha256'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/../pooch/hashes.py#L43-L87"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.file_hash" title="Link to this definition">#</a></dt>
<dd><p>Calculate the hash of a given file.</p>
<p>Useful for checking if a file has changed or been corrupted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>fname</strong><span class="classifier">str</span></dt><dd><p>The name of the file.</p>
</dd>
<dt><strong>alg</strong><span class="classifier">str</span></dt><dd><p>The type of the hashing algorithm</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>hash</strong><span class="classifier">str</span></dt><dd><p>The hash of the file.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fname</span> <span class="o">=</span> <span class="s2">&quot;test-file-for-hash.txt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">__</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;content of the file&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">file_hash</span><span class="p">(</span><span class="n">fname</span><span class="p">))</span>
<span class="go">0fc74468e6a9a829f103d069aeb2bb4f8646bad58bf146bb0e3379b759ec4a00</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">os</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.grass">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">grass</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L470-L515"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.grass" title="Link to this definition">#</a></dt>
<dd><p>Grass.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>grass</strong><span class="classifier">(512, 512) uint8 image</span></dt><dd><p>Some grass.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The original image was downloaded from
<a class="reference external" href="https://www.deviantart.com/linolafett/art/Grass-01-434853879">DeviantArt</a>
and licensed under the Creative Commons CC0 License.</p>
<p>The downloaded image was cropped to include a region of <code class="docutils literal notranslate"><span class="pre">(512,</span> <span class="pre">512)</span></code>
pixels around the top left corner, converted to grayscale, then to uint8
prior to saving the result in PNG format.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on Gabor filter banks. Frequency and orientation representations of the Gabor filter are similar to those of the human visual system."><img alt="" src="../_images/sphx_glr_plot_gabor_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_gabor.html#sphx-glr-auto-examples-features-detection-plot-gabor-py"><span class="std std-ref">Gabor filter banks for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gabor filter banks for texture classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on LBP (Local Binary Pattern). LBP looks at points surrounding a central point and tests whether the surrounding points are greater than or less than the central point (i.e. gives a binary result)."><img alt="" src="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-local-binary-pattern-py"><span class="std std-ref">Local Binary Pattern for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Local Binary Pattern for texture classification</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.gravel">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">gravel</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L518-L570"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.gravel" title="Link to this definition">#</a></dt>
<dd><p>Gravel</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>gravel</strong><span class="classifier">(512, 512) uint8 image</span></dt><dd><p>Grayscale gravel sample.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The original image was downloaded from
<a class="reference external" href="https://cc0textures.com/view.php?tex=Gravel04">CC0Textures</a> and
licensed under the Creative Commons CC0 License.</p>
<p>The downloaded image was then rescaled to <code class="docutils literal notranslate"><span class="pre">(1024,</span> <span class="pre">1024)</span></code>, then the
top left <code class="docutils literal notranslate"><span class="pre">(512,</span> <span class="pre">512)</span></code> pixel region  was cropped prior to converting the
image to grayscale and uint8 data type. The result was saved using the
PNG format.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Band-pass filters attenuate signal frequencies outside of a range (band) of interest. In image analysis, they can be used to denoise images while at the same time reducing low-frequency artifacts such a uneven illumination. Band-pass filters can be used to find image features such as blobs and edges."><img alt="" src="../_images/sphx_glr_plot_dog_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_dog.html#sphx-glr-auto-examples-filters-plot-dog-py"><span class="std std-ref">Band-pass filtering by Difference of Gaussians</span></a></p>
  <div class="sphx-glr-thumbnail-title">Band-pass filtering by Difference of Gaussians</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on Gabor filter banks. Frequency and orientation representations of the Gabor filter are similar to those of the human visual system."><img alt="" src="../_images/sphx_glr_plot_gabor_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_gabor.html#sphx-glr-auto-examples-features-detection-plot-gabor-py"><span class="std std-ref">Gabor filter banks for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gabor filter banks for texture classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to classify textures based on LBP (Local Binary Pattern). LBP looks at points surrounding a central point and tests whether the surrounding points are greater than or less than the central point (i.e. gives a binary result)."><img alt="" src="../_images/sphx_glr_plot_local_binary_pattern_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_local_binary_pattern.html#sphx-glr-auto-examples-features-detection-plot-local-binary-pattern-py"><span class="std std-ref">Local Binary Pattern for texture classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Local Binary Pattern for texture classification</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.horse">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">horse</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L837-L850"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.horse" title="Link to this definition">#</a></dt>
<dd><p>Black and white silhouette of a horse.</p>
<p>This image was downloaded from
<code class="xref py py-obj docutils literal notranslate"><span class="pre">openclipart</span></code></p>
<p>No copyright restrictions. CC0 given by owner (Andreas Preuss (marauder)).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>horse</strong><span class="classifier">(328, 400) bool ndarray</span></dt><dd><p>Horse image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The convex hull of a binary image is the set of pixels included in the smallest convex polygon that surround all white pixels in the input."><img alt="" src="../_images/sphx_glr_plot_convex_hull_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_convex_hull.html#sphx-glr-auto-examples-edges-plot-convex-hull-py"><span class="std std-ref">Convex Hull</span></a></p>
  <div class="sphx-glr-thumbnail-title">Convex Hull</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Skeletonization reduces binary objects to 1 pixel wide representations. This can be useful for feature extraction, and/or representing an object&#x27;s topology."><img alt="" src="../_images/sphx_glr_plot_skeleton_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_skeleton.html#sphx-glr-auto-examples-edges-plot-skeleton-py"><span class="std std-ref">Skeletonize</span></a></p>
  <div class="sphx-glr-thumbnail-title">Skeletonize</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Morphological image processing is a collection of non-linear operations related to the shape or morphology of features in an image, such as boundaries, skeletons, etc. In any given technique, we probe an image with a small shape or template called a structuring element, which defines the region of interest or neighborhood around a pixel."><img alt="" src="../_images/sphx_glr_plot_morphology_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_morphology.html#sphx-glr-auto-examples-applications-plot-morphology-py"><span class="std std-ref">Morphological Filtering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Filtering</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.hubble_deep_field">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">hubble_deep_field</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L931-L952"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.hubble_deep_field" title="Link to this definition">#</a></dt>
<dd><p>Hubble eXtreme Deep Field.</p>
<p>This photograph contains the Hubble Telescope’s farthest ever view of
the universe. It can be useful as an example for multi-scale
detection.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>hubble_deep_field</strong><span class="classifier">(872, 1000, 3) uint8 ndarray</span></dt><dd><p>Hubble deep field image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was downloaded from
<a class="reference external" href="http://hubblesite.org/newscenter/archive/releases/2012/37/image/a/">HubbleSite</a>.</p>
<p>The image was captured by NASA and <a class="reference external" href="http://www.nasa.gov/audience/formedia/features/MP_Photo_Guidelines.html">may be freely used in the public domain</a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to remove small objects from grayscale images. The top-hat transform [1]_ is an operation that extracts small elements and details from given images. Here we use a white top-hat transform, which is defined as the difference between the input image and its (mathematical morphology) opening."><img alt="" src="../_images/sphx_glr_plot_tophat_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_tophat.html#sphx-glr-auto-examples-filters-plot-tophat-py"><span class="std std-ref">Removing small objects in grayscale images with a top hat filter</span></a></p>
  <div class="sphx-glr-thumbnail-title">Removing small objects in grayscale images with a top hat filter</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to find an optimally calibrated version of any denoising algorithm."><img alt="" src="../_images/sphx_glr_plot_j_invariant_tutorial_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_j_invariant_tutorial.html#sphx-glr-auto-examples-filters-plot-j-invariant-tutorial-py"><span class="std std-ref">Full tutorial on calibrating Denoisers Using J-Invariance</span></a></p>
  <div class="sphx-glr-thumbnail-title">Full tutorial on calibrating Denoisers Using J-Invariance</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="scikit-image has several ways of removing objects from N-dimensional images. Here, &quot;objects&quot; (and &quot;holes&quot;) are defined as groups of samples with the same label value which distinct from the background and other objects."><img alt="" src="../_images/sphx_glr_plot_remove_objects_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_remove_objects.html#sphx-glr-auto-examples-features-detection-plot-remove-objects-py"><span class="std std-ref">Removing objects</span></a></p>
  <div class="sphx-glr-thumbnail-title">Removing objects</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Blobs are bright on dark or dark on bright regions in an image. In this example, blobs are detected using 3 algorithms. The image used in this case is the Hubble eXtreme Deep Field. Each bright dot in the image is a star or a galaxy."><img alt="" src="../_images/sphx_glr_plot_blob_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_blob.html#sphx-glr-auto-examples-features-detection-plot-blob-py"><span class="std std-ref">Blob Detection</span></a></p>
  <div class="sphx-glr-thumbnail-title">Blob Detection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We detect local maxima in a galaxy image. The image is corrupted by noise, generating many local maxima. To keep only those maxima with sufficient local contrast, we use h-maxima."><img alt="" src="../_images/sphx_glr_plot_extrema_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_extrema.html#sphx-glr-auto-examples-segmentation-plot-extrema-py"><span class="std std-ref">Extrema</span></a></p>
  <div class="sphx-glr-thumbnail-title">Extrema</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.human_mitosis">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">human_mitosis</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L636-L662"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.human_mitosis" title="Link to this definition">#</a></dt>
<dd><p>Image of human cells undergoing mitosis.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>human_mitosis: (512, 512) uint8 ndarray</dt><dd><p>Data of human cells undergoing mitosis taken during the preparation
of the manuscript in <a class="reference internal" href="#r2b0a1772c690-1" id="id7">[1]</a>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Copyright David Root. Licensed under CC-0 <a class="reference internal" href="#r2b0a1772c690-2" id="id8">[2]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r2b0a1772c690-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">1</a><span class="fn-bracket">]</span></span>
<p>Moffat J, Grueneberg DA, Yang X, Kim SY, Kloepfer AM, Hinkle G,
Piqani B, Eisenhaure TM, Luo B, Grenier JK, Carpenter AE, Foo SY,
Stewart SA, Stockwell BR, Hacohen N, Hahn WC, Lander ES,
Sabatini DM, Root DE (2006) A lentiviral RNAi library for human and
mouse genes applied to an arrayed viral high-content screen. Cell,
124(6):1283-98 / :DOI: <code class="xref py py-obj docutils literal notranslate"><span class="pre">10.1016/j.cell.2006.01.040</span></code> PMID 16564017</p>
</div>
<div class="citation" id="r2b0a1772c690-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">2</a><span class="fn-bracket">]</span></span>
<p>GitHub licensing discussion
<a class="github reference external" href="https://github.com/CellProfiler/examples/issues/41">CellProfiler/examples#41</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we analyze a microscopy image of human cells. We use data provided by Jason Moffat [1]_ through CellProfiler."><img alt="" src="../_images/sphx_glr_plot_human_mitosis_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_human_mitosis.html#sphx-glr-auto-examples-applications-plot-human-mitosis-py"><span class="std std-ref">Segment human cells (in mitosis)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Segment human cells (in mitosis)</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.immunohistochemistry">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">immunohistochemistry</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L870-L887"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.immunohistochemistry" title="Link to this definition">#</a></dt>
<dd><p>Immunohistochemical (IHC) staining with hematoxylin counterstaining.</p>
<p>This picture shows colonic glands where the IHC expression of FHL2 protein
is revealed with DAB. Hematoxylin counterstaining is applied to enhance the
negative parts of the tissue.</p>
<p>This image was acquired at the Center for Microscopy And Molecular Imaging
(CMMI).</p>
<p>No known copyright restrictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>immunohistochemistry</strong><span class="classifier">(512, 512, 3) uint8 ndarray</span></dt><dd><p>Immunohistochemistry image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Color deconvolution consists in the separation of features by their colors."><img alt="" src="../_images/sphx_glr_plot_ihc_color_separation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_ihc_color_separation.html#sphx-glr-auto-examples-color-exposure-plot-ihc-color-separation-py"><span class="std std-ref">Separate colors in immunohistochemical staining</span></a></p>
  <div class="sphx-glr-thumbnail-title">Separate colors in immunohistochemical staining</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example is about comparing the segmentations obtained using the plain SLIC method [1]_ and its masked version maskSLIC [2]_."><img alt="" src="../_images/sphx_glr_plot_mask_slic_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_mask_slic.html#sphx-glr-auto-examples-segmentation-plot-mask-slic-py"><span class="std std-ref">Apply maskSLIC vs SLIC</span></a></p>
  <div class="sphx-glr-thumbnail-title">Apply maskSLIC vs SLIC</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.kidney">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">kidney</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L721-L743"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.kidney" title="Link to this definition">#</a></dt>
<dd><p>Mouse kidney tissue.</p>
<p>This biological tissue on a pre-prepared slide was imaged with confocal
fluorescence microscopy (Nikon C1 inverted microscope).
Image shape is (16, 512, 512, 3). That is 512x512 pixels in X-Y,
16 image slices in Z, and 3 color channels
(emission wavelengths 450nm, 515nm, and 605nm, respectively).
Real-space voxel size is 1.24 microns in X-Y, and 1.25 microns in Z.
Data type is unsigned 16-bit integers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>kidney</strong><span class="classifier">(16, 512, 512, 3) uint16 ndarray</span></dt><dd><p>Kidney 3D multichannel image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was acquired by Genevieve Buckley at Monasoh Micro Imaging in
2018.
License: CC0</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we explore interactively a biomedical image which has three spatial dimensions and three color dimensions (channels). For a general introduction to 3D image processing, please refer to sphx_glr_auto_examples_applications_plot_3d_image_processing.py. The data we use here correspond to kidney tissue which was imaged with confocal fluorescence microscopy (more details at [1]_ under kidney-tissue-fluorescence.tif)."><img alt="" src="../_images/sphx_glr_plot_3d_interaction_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_3d_interaction.html#sphx-glr-auto-examples-applications-plot-3d-interaction-py"><span class="std std-ref">Interact with 3D images (of kidney tissue)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Interact with 3D images (of kidney tissue)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we compute the structure tensor of a 3D image. For a general introduction to 3D image processing, please refer to sphx_glr_auto_examples_applications_plot_3d_image_processing.py. The data we use here are sampled from an image of kidney tissue obtained by confocal fluorescence microscopy (more details at [1]_ under kidney-tissue-fluorescence.tif)."><img alt="" src="../_images/sphx_glr_plot_3d_structure_tensor_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_3d_structure_tensor.html#sphx-glr-auto-examples-applications-plot-3d-structure-tensor-py"><span class="std std-ref">Estimate anisotropy in a 3D microscopy image</span></a></p>
  <div class="sphx-glr-thumbnail-title">Estimate anisotropy in a 3D microscopy image</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.lbp_frontal_face_cascade_filename">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">lbp_frontal_face_cascade_filename</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L302-L314"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.lbp_frontal_face_cascade_filename" title="Link to this definition">#</a></dt>
<dd><p>Return the path to the XML file containing the weak classifier cascade.</p>
<p>These classifiers were trained using LBP features. The file is part
of the OpenCV repository <a class="reference internal" href="#rde45415ad1b5-1" id="id11">[1]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rde45415ad1b5-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">1</a><span class="fn-bracket">]</span></span>
<p>OpenCV lbpcascade trained files
<a class="github reference external" href="https://github.com/opencv/opencv/tree/master/data/lbpcascades">opencv/opencv</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This computer vision example shows how to detect faces on an image using object detection framework based on machine learning."><img alt="" src="../_images/sphx_glr_plot_face_detection_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_face_detection.html#sphx-glr-auto-examples-applications-plot-face-detection-py"><span class="std std-ref">Face detection using a cascade classifier</span></a></p>
  <div class="sphx-glr-thumbnail-title">Face detection using a cascade classifier</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.lfw_subset">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">lfw_subset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1114-L1143"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.lfw_subset" title="Link to this definition">#</a></dt>
<dd><p>Subset of data from the LFW dataset.</p>
<p>This database is a subset of the LFW database containing:</p>
<ul class="simple">
<li><p>100 faces</p></li>
<li><p>100 non-faces</p></li>
</ul>
<p>The full dataset is available at <a class="reference internal" href="#r9c6d6b06eb8d-2" id="id13">[2]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>images</strong><span class="classifier">(200, 25, 25) uint8 ndarray</span></dt><dd><p>100 first images are faces and subsequent 100 are non-faces.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The faces were randomly selected from the LFW dataset and the non-faces
were extracted from the background of the same dataset. The cropped ROIs
have been resized to a 25 x 25 pixels.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r9c6d6b06eb8d-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Huang, G., Mattar, M., Lee, H., &amp; Learned-Miller, E. G. (2012).
Learning to align from scratch. In Advances in Neural Information
Processing Systems (pp. 764-772).</p>
</div>
<div class="citation" id="r9c6d6b06eb8d-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Specific images"><img alt="" src="../_images/sphx_glr_plot_specific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_specific.html#sphx-glr-auto-examples-data-plot-specific-py"><span class="std std-ref">Specific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Specific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Haar-like feature descriptors were successfully used to implement the first real-time face detector [1]_. Inspired by this application, we propose an example illustrating the extraction, selection, and classification of Haar-like features to detect faces vs. non-faces."><img alt="" src="../_images/sphx_glr_plot_haar_extraction_selection_classification_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_haar_extraction_selection_classification.html#sphx-glr-auto-examples-applications-plot-haar-extraction-selection-classification-py"><span class="std std-ref">Face classification using Haar-like feature descriptor</span></a></p>
  <div class="sphx-glr-thumbnail-title">Face classification using Haar-like feature descriptor</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.lily">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">lily</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L746-L767"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.lily" title="Link to this definition">#</a></dt>
<dd><p>Lily of the valley plant stem.</p>
<p>This plant stem on a pre-prepared slide was imaged with confocal
fluorescence microscopy (Nikon C1 inverted microscope).
Image shape is (922, 922, 4). That is 922x922 pixels in X-Y,
with 4 color channels.
Real-space voxel size is 1.24 microns in X-Y.
Data type is unsigned 16-bit integers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>lily</strong><span class="classifier">(922, 922, 4) uint16 ndarray</span></dt><dd><p>Lily 2D multichannel image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was acquired by Genevieve Buckley at Monasoh Micro Imaging in
2018.
License: CC0</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.logo">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">logo</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L770-L778"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.logo" title="Link to this definition">#</a></dt>
<dd><p>Scikit-image logo, a RGBA image.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>logo</strong><span class="classifier">(500, 500, 4) uint8 ndarray</span></dt><dd><p>Logo image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.microaneurysms">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">microaneurysms</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L781-L806"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.microaneurysms" title="Link to this definition">#</a></dt>
<dd><p>Gray-level “microaneurysms” image.</p>
<p>Detail from an image of the retina (green channel).
The image is a crop of image 07_dr.JPG from the
High-Resolution Fundus (HRF) Image Database:
<a class="reference external" href="https://www5.cs.fau.de/research/data/fundus-images/">https://www5.cs.fau.de/research/data/fundus-images/</a></p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>microaneurysms</strong><span class="classifier">(102, 102) uint8 ndarray</span></dt><dd><p>Retina image with lesions.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>No copyright restrictions. CC0 given by owner (Andreas Maier).</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r54c0fe547e59-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Budai, A., Bock, R, Maier, A., Hornegger, J.,
Michelson, G. (2013).  Robust Vessel Segmentation in Fundus
Images. International Journal of Biomedical Imaging, vol. 2013,
2013.
<a class="reference external" href="https://doi.org/10.1155/2013/154860">DOI:10.1155/2013/154860</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Attribute operators (or connected operators) [1]_ is a family of contour preserving filtering operations in mathematical morphology. They can be implemented by max-trees [2]_, a compact hierarchical representation of the image."><img alt="" src="../_images/sphx_glr_plot_attribute_operators_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_attribute_operators.html#sphx-glr-auto-examples-filters-plot-attribute-operators-py"><span class="std std-ref">Attribute operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Attribute operators</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.moon">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">moon</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L809-L820"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.moon" title="Link to this definition">#</a></dt>
<dd><p>Surface of the moon.</p>
<p>This low-contrast image of the surface of the moon is useful for
illustrating histogram equalization and contrast stretching.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>moon</strong><span class="classifier">(512, 512) uint8 ndarray</span></dt><dd><p>Moon image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example adjusts image contrast by performing a Gamma and a Logarithmic correction on the input image."><img alt="" src="../_images/sphx_glr_plot_log_gamma_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_log_gamma.html#sphx-glr-auto-examples-color-exposure-plot-log-gamma-py"><span class="std std-ref">Gamma and log contrast adjustment</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gamma and log contrast adjustment</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This examples enhances an image with low contrast, using a method called histogram equalization, which &quot;spreads out the most frequent intensity values&quot; in an image [1]_. The equalized image has a roughly linear cumulative distribution function."><img alt="" src="../_images/sphx_glr_plot_equalize_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_equalize.html#sphx-glr-auto-examples-color-exposure-plot-equalize-py"><span class="std std-ref">Histogram Equalization</span></a></p>
  <div class="sphx-glr-thumbnail-title">Histogram Equalization</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example enhances an image with low contrast, using a method called local histogram equalization, which spreads out the most frequent intensity values in an image."><img alt="" src="../_images/sphx_glr_plot_local_equalize_thumb.png" />
<p><a class="reference internal" href="../auto_examples/color_exposure/plot_local_equalize.html#sphx-glr-auto-examples-color-exposure-plot-local-equalize-py"><span class="std std-ref">Local Histogram Equalization</span></a></p>
  <div class="sphx-glr-thumbnail-title">Local Histogram Equalization</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how a set of images can be assembled under the hypothesis of rigid body motions."><img alt="" src="../_images/sphx_glr_plot_stitching_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_stitching.html#sphx-glr-auto-examples-registration-plot-stitching-py"><span class="std std-ref">Assemble images with simple image stitching</span></a></p>
  <div class="sphx-glr-thumbnail-title">Assemble images with simple image stitching</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Unsharp masking is a linear image processing technique which sharpens the image. The sharp details are identified as a difference between the original image and its blurred version. These details are then scaled, and added back to the original image:"><img alt="" src="../_images/sphx_glr_plot_unsharp_mask_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_unsharp_mask.html#sphx-glr-auto-examples-filters-plot-unsharp-mask-py"><span class="std std-ref">Unsharp masking</span></a></p>
  <div class="sphx-glr-thumbnail-title">Unsharp masking</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We fill holes (i.e. isolated, dark spots) in an image using morphological reconstruction by erosion. Erosion expands the minimal values of the seed image until it encounters a mask image. Thus, the seed image and mask image represent the maximum and minimum possible values of the reconstructed image."><img alt="" src="../_images/sphx_glr_plot_holes_and_peaks_thumb.png" />
<p><a class="reference internal" href="../auto_examples/features_detection/plot_holes_and_peaks.html#sphx-glr-auto-examples-features-detection-plot-holes-and-peaks-py"><span class="std std-ref">Filling holes and finding peaks</span></a></p>
  <div class="sphx-glr-thumbnail-title">Filling holes and finding peaks</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.nickel_solidification">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">nickel_solidification</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1170-L1184"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.nickel_solidification" title="Link to this definition">#</a></dt>
<dd><p>Image sequence of synchrotron x-radiographs showing the rapid
solidification of a nickel alloy sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>nickel_solidification: (11, 384, 512) uint16 ndarray</dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See info under <code class="xref py py-obj docutils literal notranslate"><span class="pre">nickel_solidification.tif</span></code> at
<a class="gitlab reference external" href="https://gitlab.com/scikit-image/data/-/blob/master/README.md#data">scikit-image/data/-/blob/master/README.md#data</a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we identify and track the solid-liquid (S-L) interface in a nickel-based alloy undergoing solidification. Tracking the solidification over time enables the calculation of the solidification velocity. This is important to characterize the solidified structure of the sample and will be used to inform research into additive manufacturing of metals. The image sequence was obtained by the Center for Advanced Non-Ferrous Structural Alloys (CANFSA) using synchrotron x-radiography at the Advanced Photon Source (APS) at Argonne National Laboratory (ANL). This analysis was first presented at a conference [1]_."><img alt="" src="../_images/sphx_glr_plot_solidification_tracking_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_solidification_tracking.html#sphx-glr-auto-examples-applications-plot-solidification-tracking-py"><span class="std std-ref">Track solidification of a metallic alloy</span></a></p>
  <div class="sphx-glr-thumbnail-title">Track solidification of a metallic alloy</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.page">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">page</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L823-L834"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.page" title="Link to this definition">#</a></dt>
<dd><p>Scanned page.</p>
<p>This image of printed text is useful for demonstrations requiring uneven
background illumination.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>page</strong><span class="classifier">(191, 384) uint8 ndarray</span></dt><dd><p>Page image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Attribute operators (or connected operators) [1]_ is a family of contour preserving filtering operations in mathematical morphology. They can be implemented by max-trees [2]_, a compact hierarchical representation of the image."><img alt="" src="../_images/sphx_glr_plot_attribute_operators_thumb.png" />
<p><a class="reference internal" href="../auto_examples/filters/plot_attribute_operators.html#sphx-glr-auto-examples-filters-plot-attribute-operators-py"><span class="std std-ref">Attribute operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Attribute operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_."><img alt="" src="../_images/sphx_glr_plot_thresholding_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_thresholding.html#sphx-glr-auto-examples-segmentation-plot-thresholding-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Niblack and Sauvola thresholds are local thresholding techniques that are useful for images where the background is not uniform, especially for text recognition [1]_, [2]_. Instead of calculating a single global threshold for the entire image, several thresholds are calculated for every pixel by using specific formulae that take into account the mean and standard deviation of the local neighborhood (defined by a window centered around the pixel)."><img alt="" src="../_images/sphx_glr_plot_niblack_sauvola_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_niblack_sauvola.html#sphx-glr-auto-examples-segmentation-plot-niblack-sauvola-py"><span class="std std-ref">Niblack and Sauvola Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Niblack and Sauvola Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The rolling-ball algorithm estimates the background intensity of a grayscale image in case of uneven exposure. It is frequently used in biomedical image processing and was first proposed by Stanley R. Sternberg in 1983 [1]_."><img alt="" src="../_images/sphx_glr_plot_rolling_ball_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_rolling_ball.html#sphx-glr-auto-examples-segmentation-plot-rolling-ball-py"><span class="std std-ref">Use rolling-ball algorithm for estimating background intensity</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use rolling-ball algorithm for estimating background intensity</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Thresholding is used to create a binary image from a grayscale image [1]_. It is the simplest way to segment objects from a background."><img alt="" src="../_images/sphx_glr_plot_thresholding_guide_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_thresholding_guide.html#sphx-glr-auto-examples-applications-plot-thresholding-guide-py"><span class="std std-ref">Thresholding</span></a></p>
  <div class="sphx-glr-thumbnail-title">Thresholding</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Rank filters are non-linear filters using local gray-level ordering to compute the filtered value. This ensemble of filters share a common base: the local gray-level histogram is computed on the neighborhood of a pixel (defined by a 2D structuring element). If the filtered value is taken as the middle value of the histogram, we get the classical median filter."><img alt="" src="../_images/sphx_glr_plot_rank_filters_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_rank_filters.html#sphx-glr-auto-examples-applications-plot-rank-filters-py"><span class="std std-ref">Rank filters</span></a></p>
  <div class="sphx-glr-thumbnail-title">Rank filters</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.palisades_of_vogt">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">palisades_of_vogt</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1010-L1029"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.palisades_of_vogt" title="Link to this definition">#</a></dt>
<dd><p>Return image sequence of in-vivo tissue showing the palisades of Vogt.</p>
<p>In the human eye, the palisades of Vogt are normal features of the corneal
limbus, which is the border between the cornea and the sclera (i.e., the
white of the eye).
In the image sequence, there are some dark spots due to the presence of
dust on the reference mirror.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>palisades_of_vogt: (60, 1440, 1440) uint16 ndarray</dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See info under <code class="xref py py-obj docutils literal notranslate"><span class="pre">in-vivo-cornea-spots.tif</span></code> at
<a class="gitlab reference external" href="https://gitlab.com/scikit-image/data/-/blob/master/README.md#data">scikit-image/data/-/blob/master/README.md#data</a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Optical coherence tomography (OCT) is a non-invasive imaging technique used by ophthalmologists to take pictures of the back of a patient&#x27;s eye [1]_. When performing OCT, dust may stick to the reference mirror of the equipment, causing dark spots to appear on the images. The problem is that these dirt spots cover areas of in-vivo tissue, hence hiding data of interest. Our goal here is to restore (reconstruct) the hidden areas based on the pixels near their boundaries."><img alt="" src="../_images/sphx_glr_plot_cornea_spot_inpainting_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_cornea_spot_inpainting.html#sphx-glr-auto-examples-applications-plot-cornea-spot-inpainting-py"><span class="std std-ref">Restore spotted cornea image with inpainting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Restore spotted cornea image with inpainting</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.protein_transport">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">protein_transport</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1187-L1201"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.protein_transport" title="Link to this definition">#</a></dt>
<dd><p>Microscopy image sequence with fluorescence tagging of proteins
re-localizing from the cytoplasmic area to the nuclear envelope.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>protein_transport: (15, 2, 180, 183) uint8 ndarray</dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>See info under <code class="xref py py-obj docutils literal notranslate"><span class="pre">NPCsingleNucleus.tif</span></code> at
<a class="gitlab reference external" href="https://gitlab.com/scikit-image/data/-/blob/master/README.md#data">scikit-image/data/-/blob/master/README.md#data</a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate the use of different metrics to assess the colocalization of two different image channels."><img alt="" src="../_images/sphx_glr_plot_colocalization_metrics_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_colocalization_metrics.html#sphx-glr-auto-examples-applications-plot-colocalization-metrics-py"><span class="std std-ref">Colocalization metrics</span></a></p>
  <div class="sphx-glr-thumbnail-title">Colocalization metrics</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example reproduces a well-established workflow in bioimage data analysis for measuring the fluorescence intensity localized to the nuclear envelope, in a time sequence of cell images (each with two channels and two spatial dimensions) which shows a process of protein re-localization from the cytoplasmic area to the nuclear envelope. This biological application was first presented by Andrea Boni and collaborators in [1]_; it was used in a textbook by Kota Miura [2]_ as well as in other works ([3]_, [4]_). In other words, we port this workflow from ImageJ Macro to Python with scikit-image."><img alt="" src="../_images/sphx_glr_plot_fluorescence_nuclear_envelope_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_fluorescence_nuclear_envelope.html#sphx-glr-auto-examples-applications-plot-fluorescence-nuclear-envelope-py"><span class="std std-ref">Measure fluorescence intensity at the nuclear envelope</span></a></p>
  <div class="sphx-glr-thumbnail-title">Measure fluorescence intensity at the nuclear envelope</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.retina">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">retina</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L955-L979"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.retina" title="Link to this definition">#</a></dt>
<dd><p>Human retina.</p>
<p>This image of a retina is useful for demonstrations requiring circular
images.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>retina</strong><span class="classifier">(1411, 1411, 3) uint8 ndarray</span></dt><dd><p>Retina image in RGB.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was downloaded from
<code class="xref py py-obj docutils literal notranslate"><span class="pre">wikimedia</span></code>.
This file is made available under the Creative Commons CC0 1.0 Universal
Public Domain Dedication.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r037717dd9553-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Häggström, Mikael (2014). “Medical gallery of Mikael Häggström 2014”.
WikiJournal of Medicine 1 (2). <a class="reference external" href="https://doi.org/10.15347/wjm/2014.008">DOI:10.15347/wjm/2014.008</a>.
ISSN 2002-4436. Public Domain</p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Ridge filters can be used to detect ridge-like structures, such as neurites [1]_, tubes [2]_, vessels [3]_, wrinkles [4]_ or rivers."><img alt="" src="../_images/sphx_glr_plot_ridge_filter_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_ridge_filter.html#sphx-glr-auto-examples-edges-plot-ridge-filter-py"><span class="std std-ref">Ridge operators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Ridge operators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Phase correlation (``registration.phase_cross_correlation``) is an efficient method for determining translation offset between pairs of similar images. However this approach relies on a near absence of rotation/scaling differences between the images, which are typical in real-world examples."><img alt="" src="../_images/sphx_glr_plot_register_rotation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_register_rotation.html#sphx-glr-auto-examples-registration-plot-register-rotation-py"><span class="std std-ref">Using Polar and Log-Polar Transformations for Registration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using Polar and Log-Polar Transformations for Registration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In various image analysis situations, it is useful to think of the pixels of an image, or of a region of an image, as a network or graph, in which each pixel is connected to its neighbors (with or without diagonals). One such situation is finding the geodesic center of an object, which is the point closest to all other points if you are only allowed to travel on the pixels of the object, rather than in a straight line. This point is the one with maximal closeness centrality [1]_ in the network."><img alt="" src="../_images/sphx_glr_plot_pixel_graphs_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_pixel_graphs.html#sphx-glr-auto-examples-applications-plot-pixel-graphs-py"><span class="std std-ref">Use pixel graphs to find an object’s geodesic center</span></a></p>
  <div class="sphx-glr-thumbnail-title">Use pixel graphs to find an object's geodesic center</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.rocket">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">rocket</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1032-L1052"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.rocket" title="Link to this definition">#</a></dt>
<dd><p>Launch photo of DSCOVR on Falcon 9 by SpaceX.</p>
<p>This is the launch photo of Falcon 9 carrying DSCOVR lifted off from
SpaceX’s Launch Complex 40 at Cape Canaveral Air Force Station, FL.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>rocket</strong><span class="classifier">(427, 640, 3) uint8 ndarray</span></dt><dd><p>Rocket image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was downloaded from
<a class="reference external" href="https://www.flickr.com/photos/spacexphotos/16511594820/in/photostream/">SpaceX Photos</a>.</p>
<p>The image was captured by SpaceX and <a class="reference external" href="http://arstechnica.com/tech-policy/2015/03/elon-musk-puts-spacex-photos-into-the-public-domain/">released in the public domain</a>.</p>
</dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.shepp_logan_phantom">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">shepp_logan_phantom</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L982-L996"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.shepp_logan_phantom" title="Link to this definition">#</a></dt>
<dd><p>Shepp Logan Phantom.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>phantom</strong><span class="classifier">(400, 400) float64 image</span></dt><dd><p>Image of the Shepp-Logan phantom in grayscale.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r423cf3021993-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>L. A. Shepp and B. F. Logan, “The Fourier reconstruction of a head
section,” in IEEE Transactions on Nuclear Science, vol. 21,
no. 3, pp. 21-43, June 1974. <a class="reference external" href="https://doi.org/10.1109/TNS.1974.6499235">DOI:10.1109/TNS.1974.6499235</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In computed tomography, the tomography reconstruction problem is to obtain a tomographic slice image from a set of projections [1]_. A projection is formed by drawing a set of parallel rays through the 2D object of interest, assigning the integral of the object&#x27;s contrast along each ray to a single pixel in the projection. A single projection of a 2D object is one dimensional. To enable computed tomography reconstruction of the object, several projections must be acquired, each of them corresponding to a different angle between the rays with respect to the object. A collection of projections at several angles is called a sinogram, which is a linear transform of the original image."><img alt="" src="../_images/sphx_glr_plot_radon_transform_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_radon_transform.html#sphx-glr-auto-examples-transform-plot-radon-transform-py"><span class="std std-ref">Radon transform</span></a></p>
  <div class="sphx-glr-thumbnail-title">Radon transform</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Morphological image processing is a collection of non-linear operations related to the shape or morphology of features in an image, such as boundaries, skeletons, etc. In any given technique, we probe an image with a small shape or template called a structuring element, which defines the region of interest or neighborhood around a pixel."><img alt="" src="../_images/sphx_glr_plot_morphology_thumb.png" />
<p><a class="reference internal" href="../auto_examples/applications/plot_morphology.html#sphx-glr-auto-examples-applications-plot-morphology-py"><span class="std std-ref">Morphological Filtering</span></a></p>
  <div class="sphx-glr-thumbnail-title">Morphological Filtering</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.skin">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">skin</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1146-L1167"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.skin" title="Link to this definition">#</a></dt>
<dd><p>Microscopy image of dermis and epidermis (skin layers).</p>
<p>Hematoxylin and eosin stained slide at 10x of normal epidermis and dermis
with a benign intradermal nevus.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>skin</strong><span class="classifier">(960, 1280, 3) RGB image of uint8</span></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image requires an Internet connection the first time it is called,
and to have the <code class="docutils literal notranslate"><span class="pre">pooch</span></code> package installed, in order to fetch the image
file from the scikit-image datasets repository.</p>
<p>The source of this image is
<a class="reference external" href="https://en.wikipedia.org/wiki/File:Normal_Epidermis_and_Dermis_with_Intradermal_Nevus_10x.JPG">https://en.wikipedia.org/wiki/File:Normal_Epidermis_and_Dermis_with_Intradermal_Nevus_10x.JPG</a></p>
<p>The image was released in the public domain by its author Kilbad.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The title of each image indicates the name of the function."><img alt="" src="../_images/sphx_glr_plot_scientific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_scientific.html#sphx-glr-auto-examples-data-plot-scientific-py"><span class="std std-ref">Scientific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scientific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A pixel-based segmentation is computed here using local features based on local intensity, edges and textures at different scales. A user-provided mask is used to identify different regions. The pixels of the mask are used to train a random-forest classifier [1]_ from scikit-learn. Unlabeled pixels are then labeled from the prediction of the classifier."><img alt="" src="../_images/sphx_glr_plot_trainable_segmentation_thumb.png" />
<p><a class="reference internal" href="../auto_examples/segmentation/plot_trainable_segmentation.html#sphx-glr-auto-examples-segmentation-plot-trainable-segmentation-py"><span class="std std-ref">Trainable segmentation using local features and random forests</span></a></p>
  <div class="sphx-glr-thumbnail-title">Trainable segmentation using local features and random forests</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.stereo_motorcycle">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">stereo_motorcycle</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1055-L1111"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.stereo_motorcycle" title="Link to this definition">#</a></dt>
<dd><p>Rectified stereo image pair with ground-truth disparities.</p>
<p>The two images are rectified such that every pixel in the left image has
its corresponding pixel on the same scanline in the right image. That means
that both images are warped such that they have the same orientation but a
horizontal spatial offset (baseline). The ground-truth pixel offset in
column direction is specified by the included disparity map.</p>
<p>The two images are part of the Middlebury 2014 stereo benchmark. The
dataset was created by Nera Nesic, Porter Westling, Xi Wang, York Kitajima,
Greg Krathwohl, and Daniel Scharstein at Middlebury College. A detailed
description of the acquisition process can be found in <a class="reference internal" href="#re12479cea6aa-1" id="id19">[1]</a>.</p>
<p>The images included here are down-sampled versions of the default exposure
images in the benchmark. The images are down-sampled by a factor of 4 using
the function <a class="reference internal" href="skimage.transform.html#skimage.transform.downscale_local_mean" title="skimage.transform.downscale_local_mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skimage.transform.downscale_local_mean</span></code></a>. The calibration data
in the following and the included ground-truth disparity map are valid for
the down-sampled images:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Focal</span> <span class="n">length</span><span class="p">:</span>           <span class="mf">994.978</span><span class="n">px</span>
<span class="n">Principal</span> <span class="n">point</span> <span class="n">x</span><span class="p">:</span>      <span class="mf">311.193</span><span class="n">px</span>
<span class="n">Principal</span> <span class="n">point</span> <span class="n">y</span><span class="p">:</span>      <span class="mf">254.877</span><span class="n">px</span>
<span class="n">Principal</span> <span class="n">point</span> <span class="n">dx</span><span class="p">:</span>      <span class="mf">31.086</span><span class="n">px</span>
<span class="n">Baseline</span><span class="p">:</span>               <span class="mf">193.001</span><span class="n">mm</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>img_left</strong><span class="classifier">(500, 741, 3) uint8 ndarray</span></dt><dd><p>Left stereo image.</p>
</dd>
<dt><strong>img_right</strong><span class="classifier">(500, 741, 3) uint8 ndarray</span></dt><dd><p>Right stereo image.</p>
</dd>
<dt><strong>disp</strong><span class="classifier">(500, 741, 3) float ndarray</span></dt><dd><p>Ground-truth disparity map, where each value describes the offset in
column direction between corresponding pixels in the left and the right
stereo images. E.g. the corresponding pixel of
<code class="docutils literal notranslate"><span class="pre">img_left[10,</span> <span class="pre">10</span> <span class="pre">+</span> <span class="pre">disp[10,</span> <span class="pre">10]]</span></code> is <code class="docutils literal notranslate"><span class="pre">img_right[10,</span> <span class="pre">10]</span></code>.
NaNs denote pixels in the left image that do not have ground-truth.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The original resolution images, images with different exposure and
lighting, and ground-truth depth maps can be found at the Middlebury
website <a class="reference internal" href="#re12479cea6aa-2" id="id20">[2]</a>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="re12479cea6aa-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">1</a><span class="fn-bracket">]</span></span>
<p>D. Scharstein, H. Hirschmueller, Y. Kitajima, G. Krathwohl, N.
Nesic, X. Wang, and P. Westling. High-resolution stereo datasets
with subpixel-accurate ground truth. In German Conference on Pattern
Recognition (GCPR 2014), Muenster, Germany, September 2014.</p>
</div>
<div class="citation" id="re12479cea6aa-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://vision.middlebury.edu/stereo/data/scenes2014/">http://vision.middlebury.edu/stereo/data/scenes2014/</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Specific images"><img alt="" src="../_images/sphx_glr_plot_specific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_specific.html#sphx-glr-auto-examples-data-plot-specific-py"><span class="std std-ref">Specific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Specific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates how to robustly estimate epipolar geometry &lt;https://en.wikipedia.org/wiki/Epipolar_geometry&gt; (the geometry of stereo vision) between two views using sparse ORB feature correspondences."><img alt="" src="../_images/sphx_glr_plot_fundamental_matrix_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_fundamental_matrix.html#sphx-glr-auto-examples-transform-plot-fundamental-matrix-py"><span class="std std-ref">Fundamental matrix estimation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Fundamental matrix estimation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstration of image registration using optical flow."><img alt="" src="../_images/sphx_glr_plot_opticalflow_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py"><span class="std std-ref">Registration using optical flow</span></a></p>
  <div class="sphx-glr-thumbnail-title">Registration using optical flow</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.text">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">text</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L573-L589"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.text" title="Link to this definition">#</a></dt>
<dd><p>Gray-level “text” image used for corner detection.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>text</strong><span class="classifier">(172, 448) uint8 ndarray</span></dt><dd><p>Text image.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was downloaded from Wikipedia
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/File:Corner.png">https://en.wikipedia.org/wiki/File:Corner.png</a>&gt;`__.</p>
<p>No known copyright restrictions, released into the public domain.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The active contour model is a method to fit open or closed splines to lines or edges in an image [1]_. It works by minimising an energy that is in part defined by the image and part by the spline&#x27;s shape: length and smoothness. The minimization is done implicitly in the shape energy and explicitly in the image energy."><img alt="" src="../_images/sphx_glr_plot_active_contours_thumb.png" />
<p><a class="reference internal" href="../auto_examples/edges/plot_active_contours.html#sphx-glr-auto-examples-edges-plot-active-contours-py"><span class="std std-ref">Active Contour Model</span></a></p>
  <div class="sphx-glr-thumbnail-title">Active Contour Model</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will see how to use geometric transformations in the context of image processing."><img alt="" src="../_images/sphx_glr_plot_geometric_thumb.png" />
<p><a class="reference internal" href="../auto_examples/transform/plot_geometric.html#sphx-glr-auto-examples-transform-plot-geometric-py"><span class="std std-ref">Using geometric transformations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using geometric transformations</div>
</div></div></dd></dl>

<hr class="docutils" />
<dl class="py function">
<dt class="sig sig-object py" id="skimage.data.vortex">
<span class="sig-prename descclassname"><span class="pre">skimage.data.</span></span><span class="sig-name descname"><span class="pre">vortex</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-image/scikit-image/blob/v0.25.0rc0/skimage/data/_fetchers.py#L1226-L1248"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#skimage.data.vortex" title="Link to this definition">#</a></dt>
<dd><p>Case B1 image pair from the first PIV challenge.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image0, image1</strong><span class="classifier">(512, 512) grayscale images</span></dt><dd><p>A pair of images featuring synthetic moving particles.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This image was licensed as CC0 by its author, Prof. Koji Okamoto, with
thanks to Prof. Jun Sakakibara, who maintains the PIV Challenge site.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rf2123a4dc245-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Particle Image Velocimetry (PIV) Challenge site
<a class="reference external" href="http://pivchallenge.org">http://pivchallenge.org</a></p>
</div>
<div class="citation" id="rf2123a4dc245-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>1st PIV challenge Case B: <a class="reference external" href="http://pivchallenge.org/pub/index.html#b">http://pivchallenge.org/pub/index.html#b</a></p>
</div>
</div>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Specific images"><img alt="" src="../_images/sphx_glr_plot_specific_thumb.png" />
<p><a class="reference internal" href="../auto_examples/data/plot_specific.html#sphx-glr-auto-examples-data-plot-specific-py"><span class="std std-ref">Specific images</span></a></p>
  <div class="sphx-glr-thumbnail-title">Specific images</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstration of image registration using optical flow."><img alt="" src="../_images/sphx_glr_plot_opticalflow_thumb.png" />
<p><a class="reference internal" href="../auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py"><span class="std std-ref">Registration using optical flow</span></a></p>
  <div class="sphx-glr-thumbnail-title">Registration using optical flow</div>
</div></div></dd></dl>

</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.astronaut"><code class="docutils literal notranslate"><span class="pre">astronaut()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.binary_blobs"><code class="docutils literal notranslate"><span class="pre">binary_blobs()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.brain"><code class="docutils literal notranslate"><span class="pre">brain()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.brick"><code class="docutils literal notranslate"><span class="pre">brick()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.camera"><code class="docutils literal notranslate"><span class="pre">camera()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.cat"><code class="docutils literal notranslate"><span class="pre">cat()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.cell"><code class="docutils literal notranslate"><span class="pre">cell()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.cells3d"><code class="docutils literal notranslate"><span class="pre">cells3d()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.checkerboard"><code class="docutils literal notranslate"><span class="pre">checkerboard()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.chelsea"><code class="docutils literal notranslate"><span class="pre">chelsea()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.clock"><code class="docutils literal notranslate"><span class="pre">clock()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.coffee"><code class="docutils literal notranslate"><span class="pre">coffee()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.coins"><code class="docutils literal notranslate"><span class="pre">coins()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.colorwheel"><code class="docutils literal notranslate"><span class="pre">colorwheel()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.download_all"><code class="docutils literal notranslate"><span class="pre">download_all()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.eagle"><code class="docutils literal notranslate"><span class="pre">eagle()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.file_hash"><code class="docutils literal notranslate"><span class="pre">file_hash()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.grass"><code class="docutils literal notranslate"><span class="pre">grass()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.gravel"><code class="docutils literal notranslate"><span class="pre">gravel()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.horse"><code class="docutils literal notranslate"><span class="pre">horse()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.hubble_deep_field"><code class="docutils literal notranslate"><span class="pre">hubble_deep_field()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.human_mitosis"><code class="docutils literal notranslate"><span class="pre">human_mitosis()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.immunohistochemistry"><code class="docutils literal notranslate"><span class="pre">immunohistochemistry()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.kidney"><code class="docutils literal notranslate"><span class="pre">kidney()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.lbp_frontal_face_cascade_filename"><code class="docutils literal notranslate"><span class="pre">lbp_frontal_face_cascade_filename()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.lfw_subset"><code class="docutils literal notranslate"><span class="pre">lfw_subset()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.lily"><code class="docutils literal notranslate"><span class="pre">lily()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.logo"><code class="docutils literal notranslate"><span class="pre">logo()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.microaneurysms"><code class="docutils literal notranslate"><span class="pre">microaneurysms()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.moon"><code class="docutils literal notranslate"><span class="pre">moon()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.nickel_solidification"><code class="docutils literal notranslate"><span class="pre">nickel_solidification()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.page"><code class="docutils literal notranslate"><span class="pre">page()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.palisades_of_vogt"><code class="docutils literal notranslate"><span class="pre">palisades_of_vogt()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.protein_transport"><code class="docutils literal notranslate"><span class="pre">protein_transport()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.retina"><code class="docutils literal notranslate"><span class="pre">retina()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.rocket"><code class="docutils literal notranslate"><span class="pre">rocket()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.shepp_logan_phantom"><code class="docutils literal notranslate"><span class="pre">shepp_logan_phantom()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.skin"><code class="docutils literal notranslate"><span class="pre">skin()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.stereo_motorcycle"><code class="docutils literal notranslate"><span class="pre">stereo_motorcycle()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.text"><code class="docutils literal notranslate"><span class="pre">text()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skimage.data.vortex"><code class="docutils literal notranslate"><span class="pre">vortex()</span></code></a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/api/skimage.data.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2013-2024, the scikit-image team.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.0.2.
    <br/>
  </p>
</div>
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>